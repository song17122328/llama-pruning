{
  "model_name": "剪枝后模型",
  "total_params": 6092492032,
  "embedding_params": 544997376,
  "lm_head_params": 544997376,
  "layers": [
    {
      "layer_idx": 0,
      "total": 189651968,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 53426688,
        "up_proj": 53426688,
        "down_proj": 53426688,
        "total": 160280064,
        "intermediate_size": 14907
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": 150170624,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 40266240,
        "up_proj": 40266240,
        "down_proj": 40266240,
        "total": 120798720,
        "intermediate_size": 11235
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": 188609024,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 53079040,
        "up_proj": 53079040,
        "down_proj": 53079040,
        "total": 159237120,
        "intermediate_size": 14810
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": 232713728,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 67780608,
        "up_proj": 67780608,
        "down_proj": 67780608,
        "total": 203341824,
        "intermediate_size": 18912
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": 233047040,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 67891712,
        "up_proj": 67891712,
        "down_proj": 67891712,
        "total": 203675136,
        "intermediate_size": 18943
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": 231724544,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 67450880,
        "up_proj": 67450880,
        "down_proj": 67450880,
        "total": 202352640,
        "intermediate_size": 18820
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": 226574336,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 65734144,
        "up_proj": 65734144,
        "down_proj": 65734144,
        "total": 197202432,
        "intermediate_size": 18341
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": 207812096,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 59480064,
        "up_proj": 59480064,
        "down_proj": 59480064,
        "total": 178440192,
        "intermediate_size": 16596
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": 191823872,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 54150656,
        "up_proj": 54150656,
        "down_proj": 54150656,
        "total": 162451968,
        "intermediate_size": 15109
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": 229305344,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 66644480,
        "up_proj": 66644480,
        "down_proj": 66644480,
        "total": 199933440,
        "intermediate_size": 18595
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": 183310720,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 9636480,
        "k_proj": 1376640,
        "v_proj": 1376640,
        "o_proj": 9633792,
        "total": 22023552,
        "num_heads": 21,
        "num_kv_heads": 3
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 53760000,
        "up_proj": 53760000,
        "down_proj": 53760000,
        "total": 161280000,
        "intermediate_size": 15000
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": 200360960,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56996352,
        "up_proj": 56996352,
        "down_proj": 56996352,
        "total": 170989056,
        "intermediate_size": 15903
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": 180233216,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 50287104,
        "up_proj": 50287104,
        "down_proj": 50287104,
        "total": 150861312,
        "intermediate_size": 14031
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": 155664896,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 42097664,
        "up_proj": 42097664,
        "down_proj": 42097664,
        "total": 126292992,
        "intermediate_size": 11746
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": 170201600,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 46943232,
        "up_proj": 46943232,
        "down_proj": 46943232,
        "total": 140829696,
        "intermediate_size": 13098
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": 148579328,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 39735808,
        "up_proj": 39735808,
        "down_proj": 39735808,
        "total": 119207424,
        "intermediate_size": 11087
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": 138676736,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 36434944,
        "up_proj": 36434944,
        "down_proj": 36434944,
        "total": 109304832,
        "intermediate_size": 10166
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": 130257920,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 33628672,
        "up_proj": 33628672,
        "down_proj": 33628672,
        "total": 100886016,
        "intermediate_size": 9383
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": 120925184,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 30517760,
        "up_proj": 30517760,
        "down_proj": 30517760,
        "total": 91553280,
        "intermediate_size": 8515
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": 118495232,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 29707776,
        "up_proj": 29707776,
        "down_proj": 29707776,
        "total": 89123328,
        "intermediate_size": 8289
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": 135475072,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 9636480,
        "k_proj": 1376640,
        "v_proj": 1376640,
        "o_proj": 9633792,
        "total": 22023552,
        "num_heads": 21,
        "num_kv_heads": 3
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 37814784,
        "up_proj": 37814784,
        "down_proj": 37814784,
        "total": 113444352,
        "intermediate_size": 10551
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": 155191808,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 41939968,
        "up_proj": 41939968,
        "down_proj": 41939968,
        "total": 125819904,
        "intermediate_size": 11702
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": 198952448,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56526848,
        "up_proj": 56526848,
        "down_proj": 56526848,
        "total": 169580544,
        "intermediate_size": 15772
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": 186514816,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 9636480,
        "k_proj": 1376640,
        "v_proj": 1376640,
        "o_proj": 9633792,
        "total": 22023552,
        "num_heads": 21,
        "num_kv_heads": 3
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 54828032,
        "up_proj": 54828032,
        "down_proj": 54828032,
        "total": 164484096,
        "intermediate_size": 15298
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": 168905472,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 6424320,
        "k_proj": 917760,
        "v_proj": 917760,
        "o_proj": 6422528,
        "total": 14682368,
        "num_heads": 14,
        "num_kv_heads": 2
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 51405312,
        "up_proj": 51405312,
        "down_proj": 51405312,
        "total": 154215936,
        "intermediate_size": 14343
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": 170795392,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 9636480,
        "k_proj": 1376640,
        "v_proj": 1376640,
        "o_proj": 9633792,
        "total": 22023552,
        "num_heads": 21,
        "num_kv_heads": 3
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 49588224,
        "up_proj": 49588224,
        "down_proj": 49588224,
        "total": 148764672,
        "intermediate_size": 13836
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": 143998976,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 38209024,
        "up_proj": 38209024,
        "down_proj": 38209024,
        "total": 114627072,
        "intermediate_size": 10661
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": 214521344,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 61716480,
        "up_proj": 61716480,
        "down_proj": 61716480,
        "total": 185149440,
        "intermediate_size": 17220
      },
      "norm": 7168,
      "is_zero_layer": false
    }
  ],
  "layer_summary": {
    "num_layers": 28,
    "total_layer_params": 5002493696
  }
}