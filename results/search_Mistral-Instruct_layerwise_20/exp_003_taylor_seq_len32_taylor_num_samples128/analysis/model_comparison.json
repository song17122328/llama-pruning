{
  "original_name": "原始模型",
  "pruned_name": "剪枝后模型",
  "total_params": {
    "original": 7248023552,
    "pruned": 5798428672,
    "reduced": 1449594880,
    "reduction_ratio": 0.19999864371301646
  },
  "layer_params": {
    "original": 6979584000,
    "pruned": 5529989120,
    "reduced": 1449594880,
    "reduction_ratio": 0.2076907276995305
  },
  "layers": [
    {
      "layer_idx": 0,
      "total": {
        "original": 218112000,
        "pruned": 218062848,
        "reduced": 49152,
        "reduction_ratio": 0.00022535211267605634
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176111616,
        "reduced": 49152,
        "reduction_ratio": 0.00027901785714285713,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14332
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": {
        "original": 218112000,
        "pruned": 218112000,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176160768,
        "reduced": 0,
        "reduction_ratio": 0.0,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14336
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": {
        "original": 218112000,
        "pruned": 212377600,
        "reduced": 5734400,
        "reduction_ratio": 0.02629107981220657
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175669248,
        "reduced": 491520,
        "reduction_ratio": 0.0027901785714285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14296
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": {
        "original": 218112000,
        "pruned": 217792512,
        "reduced": 319488,
        "reduction_ratio": 0.0014647887323943661
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175841280,
        "reduced": 319488,
        "reduction_ratio": 0.0018136160714285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14310
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": {
        "original": 218112000,
        "pruned": 212353024,
        "reduced": 5758976,
        "reduction_ratio": 0.026403755868544602
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175644672,
        "reduced": 516096,
        "reduction_ratio": 0.0029296875,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14294
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": {
        "original": 218112000,
        "pruned": 217792512,
        "reduced": 319488,
        "reduction_ratio": 0.0014647887323943661
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175841280,
        "reduced": 319488,
        "reduction_ratio": 0.0018136160714285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14310
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": {
        "original": 218112000,
        "pruned": 204566528,
        "reduced": 13545472,
        "reduction_ratio": 0.062103286384976523
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173101056,
        "reduced": 3059712,
        "reduction_ratio": 0.017368861607142856,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14087
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": {
        "original": 218112000,
        "pruned": 207794176,
        "reduced": 10317824,
        "reduction_ratio": 0.047305164319248826
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 171085824,
        "reduced": 5074944,
        "reduction_ratio": 0.02880859375,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13923
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": {
        "original": 218112000,
        "pruned": 209596416,
        "reduced": 8515584,
        "reduction_ratio": 0.03904225352112676
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 167645184,
        "reduced": 8515584,
        "reduction_ratio": 0.04833984375,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13643
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": {
        "original": 218112000,
        "pruned": 180219904,
        "reduced": 37892096,
        "reduction_ratio": 0.17372769953051642
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 143511552,
        "reduced": 32649216,
        "reduction_ratio": 0.18533761160714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11679
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": {
        "original": 218112000,
        "pruned": 143736832,
        "reduced": 74375168,
        "reduction_ratio": 0.34099530516431925
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 107028480,
        "reduced": 69132288,
        "reduction_ratio": 0.39243861607142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8710
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": {
        "original": 218112000,
        "pruned": 112308224,
        "reduced": 105803776,
        "reduction_ratio": 0.48508920187793425
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 80842752,
        "reduced": 95318016,
        "reduction_ratio": 0.5410853794642857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6579
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": {
        "original": 218112000,
        "pruned": 106004480,
        "reduced": 112107520,
        "reduction_ratio": 0.5139906103286385
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 74539008,
        "reduced": 101621760,
        "reduction_ratio": 0.5768694196428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6066
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": {
        "original": 218112000,
        "pruned": 111955968,
        "reduced": 106156032,
        "reduction_ratio": 0.48670422535211266
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 70004736,
        "reduced": 106156032,
        "reduction_ratio": 0.6026088169642857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 5697
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": {
        "original": 218112000,
        "pruned": 97882112,
        "reduced": 120229888,
        "reduction_ratio": 0.5512300469483568
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 66416640,
        "reduced": 109744128,
        "reduction_ratio": 0.6229771205357143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 5405
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": {
        "original": 218112000,
        "pruned": 110157824,
        "reduced": 107954176,
        "reduction_ratio": 0.49494835680751176
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 78692352,
        "reduced": 97468416,
        "reduction_ratio": 0.5532924107142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6404
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": {
        "original": 218112000,
        "pruned": 130404352,
        "reduced": 87707648,
        "reduction_ratio": 0.40212206572769954
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 93696000,
        "reduced": 82464768,
        "reduction_ratio": 0.46812220982142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7625
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": {
        "original": 218112000,
        "pruned": 146714624,
        "reduced": 71397376,
        "reduction_ratio": 0.32734272300469486
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 115249152,
        "reduced": 60911616,
        "reduction_ratio": 0.3457728794642857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9379
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": {
        "original": 218112000,
        "pruned": 156659712,
        "reduced": 61452288,
        "reduction_ratio": 0.28174647887323945
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 130437120,
        "reduced": 45723648,
        "reduction_ratio": 0.25955636160714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10615
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": {
        "original": 218112000,
        "pruned": 205557760,
        "reduced": 12554240,
        "reduction_ratio": 0.05755868544600939
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 168849408,
        "reduced": 7311360,
        "reduction_ratio": 0.04150390625,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13741
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": {
        "original": 218112000,
        "pruned": 192552960,
        "reduced": 25559040,
        "reduction_ratio": 0.1171830985915493
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 166330368,
        "reduced": 9830400,
        "reduction_ratio": 0.05580357142857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13536
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": {
        "original": 218112000,
        "pruned": 208506880,
        "reduced": 9605120,
        "reduction_ratio": 0.04403755868544601
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 171798528,
        "reduced": 4362240,
        "reduction_ratio": 0.024762834821428572,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13981
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": {
        "original": 218112000,
        "pruned": 194412544,
        "reduced": 23699456,
        "reduction_ratio": 0.10865727699530517
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173432832,
        "reduced": 2727936,
        "reduction_ratio": 0.015485491071428572,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14114
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": {
        "original": 218112000,
        "pruned": 183791616,
        "reduced": 34320384,
        "reduction_ratio": 0.15735211267605634
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173297664,
        "reduced": 2863104,
        "reduction_ratio": 0.016252790178571428,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14103
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": {
        "original": 218112000,
        "pruned": 171769856,
        "reduced": 46342144,
        "reduction_ratio": 0.21246948356807513
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 171761664,
        "reduced": 4399104,
        "reduction_ratio": 0.024972098214285716,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13978
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": {
        "original": 218112000,
        "pruned": 176300032,
        "reduced": 41811968,
        "reduction_ratio": 0.19169953051643193
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 171048960,
        "reduced": 5111808,
        "reduction_ratio": 0.029017857142857144,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13920
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": {
        "original": 218112000,
        "pruned": 173916160,
        "reduced": 44195840,
        "reduction_ratio": 0.20262910798122066
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 168665088,
        "reduced": 7495680,
        "reduction_ratio": 0.04255022321428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13726
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": {
        "original": 218112000,
        "pruned": 172568576,
        "reduced": 45543424,
        "reduction_ratio": 0.2088075117370892
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 156831744,
        "reduced": 19329024,
        "reduction_ratio": 0.10972377232142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12763
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": {
        "original": 218112000,
        "pruned": 154128384,
        "reduced": 63983616,
        "reduction_ratio": 0.2933521126760563
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 143634432,
        "reduced": 32526336,
        "reduction_ratio": 0.18464006696428573,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11689
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": {
        "original": 218112000,
        "pruned": 173121536,
        "reduced": 44990464,
        "reduction_ratio": 0.20627230046948355
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 141656064,
        "reduced": 34504704,
        "reduction_ratio": 0.19587053571428573,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11528
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": {
        "original": 218112000,
        "pruned": 144592896,
        "reduced": 73519104,
        "reduction_ratio": 0.33707042253521124
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 134098944,
        "reduced": 42061824,
        "reduction_ratio": 0.23876953125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10913
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": {
        "original": 218112000,
        "pruned": 164278272,
        "reduced": 53833728,
        "reduction_ratio": 0.2468169014084507
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 122327040,
        "reduced": 53833728,
        "reduction_ratio": 0.3055943080357143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9955
        }
      },
      "is_zero_layer": false
    }
  ]
}