python /data/home/yuanxiaosong/LLM-Pruner_baseline/llama3.py --pruning_ratio 0.28 --device cuda --eval_device cuda --base_model /newdata/LLMs/Llama-3-8B-Instruct --block_wise --block_mlp_layer_start 4 --block_mlp_layer_end 30 --block_attention_layer_start 4 --block_attention_layer_end 30 --save_ckpt_log_name Llama-Instruct--128_128 --pruner_type taylor --taylor param_first --calibration_seq_len 128 --save_model --num_examples 128 --calibration_dataset c4 --calibration_batch_size 8