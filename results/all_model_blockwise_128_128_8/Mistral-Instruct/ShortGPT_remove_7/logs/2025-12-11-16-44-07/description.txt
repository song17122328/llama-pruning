- Training Parameters: 
  - base_model: /newdata/LLMs/Mistral-7B-Instruct-v0.3
  - n_remove_layers: 7
  - output_name: all_model_blockwise_128_128_8/Mistral-Instruct/ShortGPT_remove_7
  - dataset: wikitext2
  - num_samples: 128
  - seq_len: 128
  - stride: 128
  - run_evaluation: True
  - eval_metrics: ppl,zeroshot
  - finetune: False
  - device: cuda:6
