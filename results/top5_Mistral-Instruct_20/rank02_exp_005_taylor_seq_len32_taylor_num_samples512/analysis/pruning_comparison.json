{
  "original_name": "原始模型",
  "pruned_name": "剪枝后模型",
  "total_params": {
    "original": 7248023552,
    "pruned": 5798428672,
    "reduced": 1449594880,
    "reduction_ratio": 0.19999864371301646
  },
  "layer_params": {
    "original": 6979584000,
    "pruned": 5529989120,
    "reduced": 1449594880,
    "reduction_ratio": 0.2076907276995305
  },
  "layers": [
    {
      "layer_idx": 0,
      "total": {
        "original": 218112000,
        "pruned": 146165760,
        "reduced": 71946240,
        "reduction_ratio": 0.32985915492957746
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 104214528,
        "reduced": 71946240,
        "reduction_ratio": 0.40841238839285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8481
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": {
        "original": 218112000,
        "pruned": 217878528,
        "reduced": 233472,
        "reduction_ratio": 0.0010704225352112676
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175927296,
        "reduced": 233472,
        "reduction_ratio": 0.0013253348214285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14317
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": {
        "original": 218112000,
        "pruned": 212463616,
        "reduced": 5648384,
        "reduction_ratio": 0.025896713615023475
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175755264,
        "reduced": 405504,
        "reduction_ratio": 0.0023018973214285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14303
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": {
        "original": 218112000,
        "pruned": 217878528,
        "reduced": 233472,
        "reduction_ratio": 0.0010704225352112676
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175927296,
        "reduced": 233472,
        "reduction_ratio": 0.0013253348214285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14317
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": {
        "original": 218112000,
        "pruned": 217817088,
        "reduced": 294912,
        "reduction_ratio": 0.001352112676056338
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175865856,
        "reduced": 294912,
        "reduction_ratio": 0.0016741071428571428,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14312
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": {
        "original": 218112000,
        "pruned": 217976832,
        "reduced": 135168,
        "reduction_ratio": 0.0006197183098591549
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176025600,
        "reduced": 135168,
        "reduction_ratio": 0.0007672991071428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14325
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": {
        "original": 218112000,
        "pruned": 211996672,
        "reduced": 6115328,
        "reduction_ratio": 0.02803755868544601
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175288320,
        "reduced": 872448,
        "reduction_ratio": 0.004952566964285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14265
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": {
        "original": 218112000,
        "pruned": 211087360,
        "reduced": 7024640,
        "reduction_ratio": 0.03220657276995305
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174379008,
        "reduced": 1781760,
        "reduction_ratio": 0.010114397321428572,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14191
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": {
        "original": 218112000,
        "pruned": 215629824,
        "reduced": 2482176,
        "reduction_ratio": 0.011380281690140845
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173678592,
        "reduced": 2482176,
        "reduction_ratio": 0.014090401785714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14134
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": {
        "original": 218112000,
        "pruned": 208728064,
        "reduced": 9383936,
        "reduction_ratio": 0.043023474178403756
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 172019712,
        "reduced": 4141056,
        "reduction_ratio": 0.023507254464285716,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13999
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": {
        "original": 218112000,
        "pruned": 194789376,
        "reduced": 23322624,
        "reduction_ratio": 0.10692957746478873
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 152838144,
        "reduced": 23322624,
        "reduction_ratio": 0.13239397321428573,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12438
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": {
        "original": 218112000,
        "pruned": 172007424,
        "reduced": 46104576,
        "reduction_ratio": 0.21138028169014084
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 130056192,
        "reduced": 46104576,
        "reduction_ratio": 0.26171875,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10584
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": {
        "original": 218112000,
        "pruned": 147660800,
        "reduced": 70451200,
        "reduction_ratio": 0.32300469483568073
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 116195328,
        "reduced": 59965440,
        "reduction_ratio": 0.3404017857142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9456
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": {
        "original": 218112000,
        "pruned": 151240704,
        "reduced": 66871296,
        "reduction_ratio": 0.30659154929577465
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 109289472,
        "reduced": 66871296,
        "reduction_ratio": 0.37960379464285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8894
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": {
        "original": 218112000,
        "pruned": 141422592,
        "reduced": 76689408,
        "reduction_ratio": 0.3516056338028169
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 99471360,
        "reduced": 76689408,
        "reduction_ratio": 0.43533761160714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8095
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": {
        "original": 218112000,
        "pruned": 170950656,
        "reduced": 47161344,
        "reduction_ratio": 0.21622535211267604
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 128999424,
        "reduced": 47161344,
        "reduction_ratio": 0.26771763392857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10498
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": {
        "original": 218112000,
        "pruned": 173985792,
        "reduced": 44126208,
        "reduction_ratio": 0.20230985915492958
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 132034560,
        "reduced": 44126208,
        "reduction_ratio": 0.25048828125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10745
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": {
        "original": 218112000,
        "pruned": 182771712,
        "reduced": 35340288,
        "reduction_ratio": 0.1620281690140845
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 140820480,
        "reduced": 35340288,
        "reduction_ratio": 0.20061383928571427,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11460
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": {
        "original": 218112000,
        "pruned": 188465152,
        "reduced": 29646848,
        "reduction_ratio": 0.13592488262910798
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 151756800,
        "reduced": 24403968,
        "reduction_ratio": 0.13853236607142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12350
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": {
        "original": 218112000,
        "pruned": 204496896,
        "reduced": 13615104,
        "reduction_ratio": 0.06242253521126761
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 162545664,
        "reduced": 13615104,
        "reduction_ratio": 0.07728794642857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13228
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": {
        "original": 218112000,
        "pruned": 199151616,
        "reduced": 18960384,
        "reduction_ratio": 0.08692957746478873
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 172929024,
        "reduced": 3231744,
        "reduction_ratio": 0.018345424107142856,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14073
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": {
        "original": 218112000,
        "pruned": 211886080,
        "reduced": 6225920,
        "reduction_ratio": 0.028544600938967137
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175177728,
        "reduced": 983040,
        "reduction_ratio": 0.005580357142857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14256
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": {
        "original": 218112000,
        "pruned": 196440064,
        "reduced": 21671936,
        "reduction_ratio": 0.09936150234741783
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175460352,
        "reduced": 700416,
        "reduction_ratio": 0.003976004464285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14279
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": {
        "original": 218112000,
        "pruned": 185917440,
        "reduced": 32194560,
        "reduction_ratio": 0.1476056338028169
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175423488,
        "reduced": 737280,
        "reduction_ratio": 0.004185267857142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14276
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": {
        "original": 218112000,
        "pruned": 180539392,
        "reduced": 37572608,
        "reduction_ratio": 0.17226291079812206
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175288320,
        "reduced": 872448,
        "reduction_ratio": 0.004952566964285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14265
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": {
        "original": 218112000,
        "pruned": 179408896,
        "reduced": 38703104,
        "reduction_ratio": 0.17744600938967137
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174157824,
        "reduced": 2002944,
        "reduction_ratio": 0.011369977678571428,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14173
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": {
        "original": 218112000,
        "pruned": 174702592,
        "reduced": 43409408,
        "reduction_ratio": 0.19902347417840374
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 169451520,
        "reduced": 6709248,
        "reduction_ratio": 0.0380859375,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13790
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": {
        "original": 218112000,
        "pruned": 159518720,
        "reduced": 58593280,
        "reduction_ratio": 0.2686384976525822
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 143781888,
        "reduced": 32378880,
        "reduction_ratio": 0.18380301339285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11701
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": {
        "original": 218112000,
        "pruned": 85639168,
        "reduced": 132472832,
        "reduction_ratio": 0.6073615023474178
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 80388096,
        "reduced": 95772672,
        "reduction_ratio": 0.5436662946428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6542
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": {
        "original": 218112000,
        "pruned": 61952000,
        "reduced": 156160000,
        "reduction_ratio": 0.715962441314554
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 46215168,
        "reduced": 129945600,
        "reduction_ratio": 0.7376534598214286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 3761
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": {
        "original": 218112000,
        "pruned": 37892096,
        "reduced": 180219904,
        "reduction_ratio": 0.8262723004694835
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 37883904,
        "reduced": 138276864,
        "reduction_ratio": 0.7849469866071429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 3083
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": {
        "original": 218112000,
        "pruned": 51527680,
        "reduced": 166584320,
        "reduction_ratio": 0.763755868544601
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 46276608,
        "reduced": 129884160,
        "reduction_ratio": 0.7373046875,
        "intermediate_size": {
          "original": 14336,
          "pruned": 3766
        }
      },
      "is_zero_layer": false
    }
  ]
}