{
  "model_path": "results/taylor_only_2000_finetuned/pruned_model.bin",
  "timestamp": "2025-11-25T20:37:28.107630",
  "metrics": {
    "model_info": {
      "total_params": 6424211456,
      "trainable_params": 0,
      "total_params_M": 6424.211456,
      "total_params_B": 6.424211456,
      "attention_params": 1148190720,
      "mlp_params": 4225081344,
      "attention_params_M": 1148.19072,
      "mlp_params_M": 4225.081344,
      "attention_ratio": 0.17872866232129206,
      "mlp_ratio": 0.6576809267468795,
      "num_layers": 32,
      "model_size_mb": 12253.211059570312,
      "model_size_gb": 11.966026425361633
    },
    "ppl": {
      "wikitext2 (wikitext-2-raw-v1)": 29.252704620361328,
      "ptb": 47.58385467529297
    },
    "zeroshot": {
      "boolq": {
        "accuracy": 0.8480122324159022,
        "full_results": {
          "alias": "boolq",
          "acc,none": 0.8480122324159022,
          "acc_stderr,none": 0.006279107468848845
        }
      },
      "piqa": {
        "accuracy": 0.7600652883569097,
        "full_results": {
          "alias": "piqa",
          "acc,none": 0.750816104461371,
          "acc_stderr,none": 0.010091882770120146,
          "acc_norm,none": 0.7600652883569097,
          "acc_norm_stderr,none": 0.009963625892809592
        }
      },
      "hellaswag": {
        "accuracy": 0.7004580760804621,
        "full_results": {
          "alias": "hellaswag",
          "acc,none": 0.5228042222664808,
          "acc_stderr,none": 0.004984589012289199,
          "acc_norm,none": 0.7004580760804621,
          "acc_norm_stderr,none": 0.004571212360565399
        }
      },
      "winogrande": {
        "accuracy": 0.675611681136543,
        "full_results": {
          "alias": "winogrande",
          "acc,none": 0.675611681136543,
          "acc_stderr,none": 0.013157225726641568
        }
      },
      "arc_easy": {
        "accuracy": 0.6712962962962963,
        "full_results": {
          "alias": "arc_easy",
          "acc,none": 0.7462121212121212,
          "acc_stderr,none": 0.00892965706580818,
          "acc_norm,none": 0.6712962962962963,
          "acc_norm_stderr,none": 0.009638903167022173
        }
      },
      "arc_challenge": {
        "accuracy": 0.4539249146757679,
        "full_results": {
          "alias": "arc_challenge",
          "acc,none": 0.4462457337883959,
          "acc_stderr,none": 0.014526705548539947,
          "acc_norm,none": 0.4539249146757679,
          "acc_norm_stderr,none": 0.014549221105171829
        }
      },
      "openbookqa": {
        "accuracy": 0.394,
        "full_results": {
          "alias": "openbookqa",
          "acc,none": 0.306,
          "acc_stderr,none": 0.020629569998345414,
          "acc_norm,none": 0.394,
          "acc_norm_stderr,none": 0.02187429930168918
        }
      }
    },
    "avg_zeroshot_acc": 0.643338355565983,
    "efficiency": {
      "model_info": {
        "total_params": 6424211456,
        "trainable_params": 0,
        "total_params_M": 6424.211456,
        "total_params_B": 6.424211456,
        "attention_params": 1148190720,
        "mlp_params": 4225081344,
        "attention_params_M": 1148.19072,
        "mlp_params_M": 4225.081344,
        "attention_ratio": 0.17872866232129206,
        "mlp_ratio": 0.6576809267468795,
        "num_layers": 32,
        "model_size_mb": 12253.211059570312,
        "model_size_gb": 11.966026425361633
      },
      "speed": {
        "batch_size_1": {
          "throughput_tokens_per_sec": 30.189557982098037,
          "latency_ms_per_token": 33.12403582036495,
          "total_time_sec": 211.9938292503357,
          "total_tokens": 6400
        },
        "batch_size_4": {
          "throughput_tokens_per_sec": 114.17063064916329,
          "latency_ms_per_token": 8.75881997247537,
          "total_time_sec": 53.81418991088867,
          "total_tokens": 6144
        }
      },
      "memory": {
        "model_memory_mb": 12285.9541015625,
        "inference_peak_mb": 12375.9609375
      }
    }
  }
}