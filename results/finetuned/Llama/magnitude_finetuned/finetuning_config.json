{
  "model": "Llama",
  "config_type": "magnitude",
  "lora_config": {
    "lora_r": 8,
    "lora_alpha": 16,
    "lora_dropout": 0.05,
    "num_epochs": 2,
    "learning_rate": 0.0001,
    "batch_size": 64,
    "micro_batch_size": 4
  },
  "pruned_model_info": {
    "selection_criterion": "magnitude",
    "pruning_method": "magnitude",
    "model": "Llama"
  }
}