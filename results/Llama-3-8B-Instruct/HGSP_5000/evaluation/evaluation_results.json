{
  "model_path": "results/HGSP_5000/pruned_model.bin",
  "timestamp": "2025-11-22T22:57:29.119999",
  "metrics": {
    "model_info": {
      "total_params": 4015136768,
      "trainable_params": 4015136768,
      "total_params_M": 4015.136768,
      "total_params_B": 4.015136768,
      "attention_params": 723517440,
      "mlp_params": 2240679936,
      "attention_params_M": 723.51744,
      "mlp_params_M": 2240.679936,
      "attention_ratio": 0.18019745822018285,
      "mlp_ratio": 0.5580581846819919,
      "num_layers": 32,
      "model_size_mb": 7658.265869140625,
      "model_size_gb": 7.478775262832642
    },
    "ppl": {
      "wikitext2 (wikitext-2-raw-v1)": 315.2113952636719,
      "ptb": 373.31475830078125
    },
    "zeroshot": {
      "boolq": {
        "accuracy": 0.39021406727828745,
        "full_results": {
          "alias": "boolq",
          "acc,none": 0.39021406727828745,
          "acc_stderr,none": 0.008531643526263285
        }
      },
      "piqa": {
        "accuracy": 0.5625680087051143,
        "full_results": {
          "alias": "piqa",
          "acc,none": 0.5745375408052231,
          "acc_stderr,none": 0.011535468840824452,
          "acc_norm,none": 0.5625680087051143,
          "acc_norm_stderr,none": 0.011574126069682592
        }
      },
      "hellaswag": {
        "accuracy": 0.33031268671579367,
        "full_results": {
          "alias": "hellaswag",
          "acc,none": 0.2840071698864768,
          "acc_stderr,none": 0.004500186424444058,
          "acc_norm,none": 0.33031268671579367,
          "acc_norm_stderr,none": 0.004693644357202193
        }
      },
      "winogrande": {
        "accuracy": 0.48855564325177586,
        "full_results": {
          "alias": "winogrande",
          "acc,none": 0.48855564325177586,
          "acc_stderr,none": 0.014048804199859391
        }
      },
      "arc_easy": {
        "accuracy": 0.2984006734006734,
        "full_results": {
          "alias": "arc_easy",
          "acc,none": 0.30008417508417506,
          "acc_stderr,none": 0.009404000558513162,
          "acc_norm,none": 0.2984006734006734,
          "acc_norm_stderr,none": 0.009388855914040308
        }
      },
      "arc_challenge": {
        "accuracy": 0.2431740614334471,
        "full_results": {
          "alias": "arc_challenge",
          "acc,none": 0.20819112627986347,
          "acc_stderr,none": 0.011864866118448116,
          "acc_norm,none": 0.2431740614334471,
          "acc_norm_stderr,none": 0.012536554144587002
        }
      },
      "openbookqa": {
        "accuracy": 0.274,
        "full_results": {
          "alias": "openbookqa",
          "acc,none": 0.132,
          "acc_stderr,none": 0.015152927850580223,
          "acc_norm,none": 0.274,
          "acc_norm_stderr,none": 0.019966103540279518
        }
      }
    },
    "avg_zeroshot_acc": 0.36960359154072736,
    "efficiency": {
      "model_info": {
        "total_params": 4015136768,
        "trainable_params": 4015136768,
        "total_params_M": 4015.136768,
        "total_params_B": 4.015136768,
        "attention_params": 723517440,
        "mlp_params": 2240679936,
        "attention_params_M": 723.51744,
        "mlp_params_M": 2240.679936,
        "attention_ratio": 0.18019745822018285,
        "mlp_ratio": 0.5580581846819919,
        "num_layers": 32,
        "model_size_mb": 7658.265869140625,
        "model_size_gb": 7.478775262832642
      },
      "speed": {
        "batch_size_1": {
          "throughput_tokens_per_sec": 32.685079405862865,
          "latency_ms_per_token": 30.594999864697456,
          "total_time_sec": 195.80799913406372,
          "total_tokens": 6400
        },
        "batch_size_4": {
          "throughput_tokens_per_sec": 125.01817386585931,
          "latency_ms_per_token": 7.998837041668594,
          "total_time_sec": 49.14485478401184,
          "total_tokens": 6144
        }
      },
      "memory": {
        "model_memory_mb": 30662.92333984375,
        "inference_peak_mb": 30739.18017578125
      }
    }
  }
}