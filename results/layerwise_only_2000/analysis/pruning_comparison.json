{
  "original_name": "Llama-3-8B-Instruct",
  "pruned_name": "layerwise_only_2000",
  "total_params": {
    "original": 8030261248,
    "pruned": 6466154496,
    "reduced": 1564106752,
    "reduction_ratio": 0.19477657123416167
  },
  "layer_params": {
    "original": 6979584000,
    "pruned": 5415477248,
    "reduced": 1564106752,
    "reduction_ratio": 0.2240974178403756
  },
  "layers": [
    {
      "layer_idx": 0,
      "total": {
        "original": 218112000,
        "pruned": 218112000,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176160768,
        "reduced": 0,
        "reduction_ratio": 0.0,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14336
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": {
        "original": 218112000,
        "pruned": 218112000,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176160768,
        "reduced": 0,
        "reduction_ratio": 0.0,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14336
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": {
        "original": 218112000,
        "pruned": 218099712,
        "reduced": 12288,
        "reduction_ratio": 5.6338028169014086e-05
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176148480,
        "reduced": 12288,
        "reduction_ratio": 6.975446428571428e-05,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14335
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": {
        "original": 218112000,
        "pruned": 217976832,
        "reduced": 135168,
        "reduction_ratio": 0.0006197183098591549
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176025600,
        "reduced": 135168,
        "reduction_ratio": 0.0007672991071428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14325
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": {
        "original": 218112000,
        "pruned": 216035328,
        "reduced": 2076672,
        "reduction_ratio": 0.009521126760563381
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174084096,
        "reduced": 2076672,
        "reduction_ratio": 0.011788504464285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14167
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": {
        "original": 218112000,
        "pruned": 215506944,
        "reduced": 2605056,
        "reduction_ratio": 0.011943661971830987
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173555712,
        "reduced": 2605056,
        "reduction_ratio": 0.014787946428571428,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14124
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": {
        "original": 218112000,
        "pruned": 208220160,
        "reduced": 9891840,
        "reduction_ratio": 0.045352112676056336
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 166268928,
        "reduced": 9891840,
        "reduction_ratio": 0.05615234375,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13531
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": {
        "original": 218112000,
        "pruned": 174305280,
        "reduced": 43806720,
        "reduction_ratio": 0.20084507042253522
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 132354048,
        "reduced": 43806720,
        "reduction_ratio": 0.24867466517857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10771
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": {
        "original": 218112000,
        "pruned": 163295232,
        "reduced": 54816768,
        "reduction_ratio": 0.2513239436619718
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 121344000,
        "reduced": 54816768,
        "reduction_ratio": 0.31117466517857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9875
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": {
        "original": 218112000,
        "pruned": 64520192,
        "reduced": 153591808,
        "reduction_ratio": 0.70418779342723
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 48783360,
        "reduced": 127377408,
        "reduction_ratio": 0.7230747767857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 3970
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": {
        "original": 218112000,
        "pruned": 104472576,
        "reduced": 113639424,
        "reduction_ratio": 0.5210140845070422
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 78249984,
        "reduced": 97910784,
        "reduction_ratio": 0.5558035714285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6368
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": {
        "original": 218112000,
        "pruned": 68710400,
        "reduced": 149401600,
        "reduction_ratio": 0.6849765258215963
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 37244928,
        "reduced": 138915840,
        "reduction_ratio": 0.78857421875,
        "intermediate_size": {
          "original": 14336,
          "pruned": 3031
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": {
        "original": 218112000,
        "pruned": 47063040,
        "reduced": 171048960,
        "reduction_ratio": 0.7842253521126761
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 5111808,
        "reduced": 171048960,
        "reduction_ratio": 0.9709821428571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 416
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": {
        "original": 218112000,
        "pruned": 150134784,
        "reduced": 67977216,
        "reduction_ratio": 0.31166197183098593
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 108183552,
        "reduced": 67977216,
        "reduction_ratio": 0.38588169642857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8804
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": {
        "original": 218112000,
        "pruned": 177500160,
        "reduced": 40611840,
        "reduction_ratio": 0.18619718309859154
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 135548928,
        "reduced": 40611840,
        "reduction_ratio": 0.23053850446428573,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11031
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": {
        "original": 218112000,
        "pruned": 196153344,
        "reduced": 21958656,
        "reduction_ratio": 0.10067605633802817
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 154202112,
        "reduced": 21958656,
        "reduction_ratio": 0.12465122767857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12549
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": {
        "original": 218112000,
        "pruned": 203034624,
        "reduced": 15077376,
        "reduction_ratio": 0.06912676056338028
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 161083392,
        "reduced": 15077376,
        "reduction_ratio": 0.08558872767857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13109
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": {
        "original": 218112000,
        "pruned": 212434944,
        "reduced": 5677056,
        "reduction_ratio": 0.026028169014084508
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 170483712,
        "reduced": 5677056,
        "reduction_ratio": 0.0322265625,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13874
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": {
        "original": 218112000,
        "pruned": 206528512,
        "reduced": 11583488,
        "reduction_ratio": 0.053107981220657276
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 169820160,
        "reduced": 6340608,
        "reduction_ratio": 0.03599330357142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13820
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": {
        "original": 218112000,
        "pruned": 182542336,
        "reduced": 35569664,
        "reduction_ratio": 0.16307981220657278
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 145833984,
        "reduced": 30326784,
        "reduction_ratio": 0.17215401785714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11868
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": {
        "original": 218112000,
        "pruned": 184180736,
        "reduced": 33931264,
        "reduction_ratio": 0.1555680751173709
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 152715264,
        "reduced": 23445504,
        "reduction_ratio": 0.13309151785714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12428
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": {
        "original": 218112000,
        "pruned": 191782912,
        "reduced": 26329088,
        "reduction_ratio": 0.12071361502347418
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 155074560,
        "reduced": 21086208,
        "reduction_ratio": 0.11969866071428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12620
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": {
        "original": 218112000,
        "pruned": 182280192,
        "reduced": 35831808,
        "reduction_ratio": 0.16428169014084507
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 156057600,
        "reduced": 20103168,
        "reduction_ratio": 0.11411830357142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12700
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": {
        "original": 218112000,
        "pruned": 113201152,
        "reduced": 104910848,
        "reduction_ratio": 0.48099530516431926
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 107950080,
        "reduced": 68210688,
        "reduction_ratio": 0.38720703125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8785
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": {
        "original": 218112000,
        "pruned": 192372736,
        "reduced": 25739264,
        "reduction_ratio": 0.1180093896713615
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 155664384,
        "reduced": 20496384,
        "reduction_ratio": 0.11635044642857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12668
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": {
        "original": 218112000,
        "pruned": 41172992,
        "reduced": 176939008,
        "reduction_ratio": 0.8112300469483568
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 25436160,
        "reduced": 150724608,
        "reduction_ratio": 0.8556082589285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 2070
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": {
        "original": 218112000,
        "pruned": 30531584,
        "reduced": 187580416,
        "reduction_ratio": 0.860018779342723
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 14794752,
        "reduced": 161366016,
        "reduction_ratio": 0.916015625,
        "intermediate_size": {
          "original": 14336,
          "pruned": 1204
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": {
        "original": 218112000,
        "pruned": 214167552,
        "reduced": 3944448,
        "reduction_ratio": 0.01808450704225352
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 172216320,
        "reduced": 3944448,
        "reduction_ratio": 0.022391183035714284,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14015
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": {
        "original": 218112000,
        "pruned": 173678592,
        "reduced": 44433408,
        "reduction_ratio": 0.20371830985915493
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 131727360,
        "reduced": 44433408,
        "reduction_ratio": 0.25223214285714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10720
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": {
        "original": 218112000,
        "pruned": 202096640,
        "reduced": 16015360,
        "reduction_ratio": 0.07342723004694836
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 170631168,
        "reduced": 5529600,
        "reduction_ratio": 0.03138950892857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13886
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": {
        "original": 218112000,
        "pruned": 209154048,
        "reduced": 8957952,
        "reduction_ratio": 0.041070422535211266
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 167202816,
        "reduced": 8957952,
        "reduction_ratio": 0.05085100446428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13607
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": {
        "original": 218112000,
        "pruned": 218099712,
        "reduced": 12288,
        "reduction_ratio": 5.6338028169014086e-05
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176148480,
        "reduced": 12288,
        "reduction_ratio": 6.975446428571428e-05,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14335
        }
      },
      "is_zero_layer": false
    }
  ]
}