{
  "original_name": "原始模型",
  "pruned_name": "剪枝后模型",
  "total_params": {
    "original": 8030261248,
    "pruned": 4015132672,
    "reduced": 4015128576,
    "reduction_ratio": 0.4999997449647108
  },
  "layer_params": {
    "original": 6979584000,
    "pruned": 2964455424,
    "reduced": 4015128576,
    "reduction_ratio": 0.5752676056338029
  },
  "layers": [
    {
      "layer_idx": 0,
      "total": {
        "original": 218112000,
        "pruned": 216748032,
        "reduced": 1363968,
        "reduction_ratio": 0.006253521126760564
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174796800,
        "reduced": 1363968,
        "reduction_ratio": 0.007742745535714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14225
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": {
        "original": 218112000,
        "pruned": 217522176,
        "reduced": 589824,
        "reduction_ratio": 0.002704225352112676
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175570944,
        "reduced": 589824,
        "reduction_ratio": 0.0033482142857142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14288
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": {
        "original": 218112000,
        "pruned": 204988416,
        "reduced": 13123584,
        "reduction_ratio": 0.06016901408450704
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 163037184,
        "reduced": 13123584,
        "reduction_ratio": 0.07449776785714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13268
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": {
        "original": 218112000,
        "pruned": 190967808,
        "reduced": 27144192,
        "reduction_ratio": 0.12445070422535211
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 149016576,
        "reduced": 27144192,
        "reduction_ratio": 0.15408761160714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12127
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": {
        "original": 218112000,
        "pruned": 190021632,
        "reduced": 28090368,
        "reduction_ratio": 0.1287887323943662
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 148070400,
        "reduced": 28090368,
        "reduction_ratio": 0.15945870535714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12050
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": {
        "original": 218112000,
        "pruned": 169537536,
        "reduced": 48574464,
        "reduction_ratio": 0.22270422535211268
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 127586304,
        "reduced": 48574464,
        "reduction_ratio": 0.27573939732142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10383
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": {
        "original": 218112000,
        "pruned": 150896640,
        "reduced": 67215360,
        "reduction_ratio": 0.30816901408450703
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 108945408,
        "reduced": 67215360,
        "reduction_ratio": 0.38155691964285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8866
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": {
        "original": 218112000,
        "pruned": 129662976,
        "reduced": 88449024,
        "reduction_ratio": 0.4055211267605634
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 87711744,
        "reduced": 88449024,
        "reduction_ratio": 0.5020926339285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7138
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": {
        "original": 218112000,
        "pruned": 131604480,
        "reduced": 86507520,
        "reduction_ratio": 0.39661971830985915
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 89653248,
        "reduced": 86507520,
        "reduction_ratio": 0.49107142857142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7296
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": {
        "original": 218112000,
        "pruned": 129994752,
        "reduced": 88117248,
        "reduction_ratio": 0.404
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 88043520,
        "reduced": 88117248,
        "reduction_ratio": 0.5002092633928571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7165
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": {
        "original": 218112000,
        "pruned": 111087616,
        "reduced": 107024384,
        "reduction_ratio": 0.4906854460093897
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 74379264,
        "reduced": 101781504,
        "reduction_ratio": 0.5777762276785714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6053
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": {
        "original": 218112000,
        "pruned": 119894016,
        "reduced": 98217984,
        "reduction_ratio": 0.4503098591549296
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 77942784,
        "reduced": 98217984,
        "reduction_ratio": 0.5575474330357143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6343
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": {
        "original": 218112000,
        "pruned": 107237376,
        "reduced": 110874624,
        "reduction_ratio": 0.5083380281690141
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 65286144,
        "reduced": 110874624,
        "reduction_ratio": 0.62939453125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 5313
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": {
        "original": 218112000,
        "pruned": 100651008,
        "reduced": 117460992,
        "reduction_ratio": 0.5385352112676056
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 58699776,
        "reduced": 117460992,
        "reduction_ratio": 0.6667829241071429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 4777
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": {
        "original": 218112000,
        "pruned": 94412800,
        "reduced": 123699200,
        "reduction_ratio": 0.5671361502347417
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 57704448,
        "reduced": 118456320,
        "reduction_ratio": 0.6724330357142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 4696
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": {
        "original": 218112000,
        "pruned": 91611136,
        "reduced": 126500864,
        "reduction_ratio": 0.579981220657277
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 54902784,
        "reduced": 121257984,
        "reduction_ratio": 0.6883370535714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 4468
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": {
        "original": 218112000,
        "pruned": 78659584,
        "reduced": 139452416,
        "reduction_ratio": 0.6393615023474178
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 41951232,
        "reduced": 134209536,
        "reduction_ratio": 0.7618582589285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 3414
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": {
        "original": 218112000,
        "pruned": 49274880,
        "reduced": 168837120,
        "reduction_ratio": 0.7740845070422535
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 38780928,
        "reduced": 137379840,
        "reduction_ratio": 0.7798549107142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 3156
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": {
        "original": 218112000,
        "pruned": 41385984,
        "reduced": 176726016,
        "reduction_ratio": 0.8102535211267605
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 30892032,
        "reduced": 145268736,
        "reduction_ratio": 0.8246372767857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 2514
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": {
        "original": 218112000,
        "pruned": 28270592,
        "reduced": 189841408,
        "reduction_ratio": 0.8703849765258216
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 28262400,
        "reduced": 147898368,
        "reduction_ratio": 0.8395647321428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 2300
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": {
        "original": 218112000,
        "pruned": 36327424,
        "reduced": 181784576,
        "reduction_ratio": 0.8334460093896714
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 31076352,
        "reduced": 145084416,
        "reduction_ratio": 0.8235909598214286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 2529
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": {
        "original": 218112000,
        "pruned": 46837760,
        "reduced": 171274240,
        "reduction_ratio": 0.7852582159624413
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 31100928,
        "reduced": 145059840,
        "reduction_ratio": 0.8234514508928571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 2531
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": {
        "original": 218112000,
        "pruned": 38436864,
        "reduced": 179675136,
        "reduction_ratio": 0.8237746478873239
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 27942912,
        "reduced": 148217856,
        "reduction_ratio": 0.8413783482142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 2274
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": {
        "original": 218112000,
        "pruned": 25960448,
        "reduced": 192151552,
        "reduction_ratio": 0.8809765258215962
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 25952256,
        "reduced": 150208512,
        "reduction_ratio": 0.8526785714285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 2112
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": {
        "original": 218112000,
        "pruned": 37994496,
        "reduced": 180117504,
        "reduction_ratio": 0.8258028169014084
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 27500544,
        "reduced": 148660224,
        "reduction_ratio": 0.8438895089285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 2238
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": {
        "original": 218112000,
        "pruned": 33579008,
        "reduced": 184532992,
        "reduction_ratio": 0.8460469483568075
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 17842176,
        "reduced": 158318592,
        "reduction_ratio": 0.8987165178571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 1452
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": {
        "original": 218112000,
        "pruned": 29978624,
        "reduced": 188133376,
        "reduction_ratio": 0.8625539906103287
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 14241792,
        "reduced": 161918976,
        "reduction_ratio": 0.9191545758928571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 1159
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": {
        "original": 218112000,
        "pruned": 28188672,
        "reduced": 189923328,
        "reduction_ratio": 0.8707605633802817
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 17694720,
        "reduced": 158466048,
        "reduction_ratio": 0.8995535714285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 1440
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": {
        "original": 218112000,
        "pruned": 21950464,
        "reduced": 196161536,
        "reduction_ratio": 0.8993615023474179
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 16699392,
        "reduced": 159461376,
        "reduction_ratio": 0.9052036830357143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 1359
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": {
        "original": 218112000,
        "pruned": 35307520,
        "reduced": 182804480,
        "reduction_ratio": 0.8381220657276995
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 14327808,
        "reduced": 161832960,
        "reduction_ratio": 0.9186662946428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 1166
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": {
        "original": 218112000,
        "pruned": 28434432,
        "reduced": 189677568,
        "reduction_ratio": 0.8696338028169014
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 17940480,
        "reduced": 158220288,
        "reduction_ratio": 0.8981584821428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 1460
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": {
        "original": 218112000,
        "pruned": 47030272,
        "reduced": 171081728,
        "reduction_ratio": 0.7843755868544601
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 41779200,
        "reduced": 134381568,
        "reduction_ratio": 0.7628348214285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 3400
        }
      },
      "is_zero_layer": false
    }
  ]
}