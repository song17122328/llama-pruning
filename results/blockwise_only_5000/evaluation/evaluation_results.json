{
  "model_path": "results/blockwise_only_5000/pruned_model.bin",
  "timestamp": "2025-11-22T22:02:48.821737",
  "metrics": {
    "model_info": {
      "total_params": 4015132672,
      "trainable_params": 4015132672,
      "total_params_M": 4015.132672,
      "total_params_B": 4.015132672,
      "attention_params": 838860800,
      "mlp_params": 2125332480,
      "attention_params_M": 838.8608,
      "mlp_params_M": 2125.33248,
      "attention_ratio": 0.20892480237325517,
      "mlp_ratio": 0.5293305735128645,
      "num_layers": 32,
      "model_size_mb": 7658.258056640625,
      "model_size_gb": 7.47876763343811
    },
    "ppl": {
      "wikitext2 (wikitext-2-raw-v1)": 483.753173828125,
      "ptb": 656.3760986328125
    },
    "zeroshot": {
      "boolq": {
        "accuracy": 0.6217125382262997,
        "full_results": {
          "alias": "boolq",
          "acc,none": 0.6217125382262997,
          "acc_stderr,none": 0.008482001133931097
        }
      },
      "piqa": {
        "accuracy": 0.5631120783460283,
        "full_results": {
          "alias": "piqa",
          "acc,none": 0.5756256800870512,
          "acc_stderr,none": 0.011531612758871207,
          "acc_norm,none": 0.5631120783460283,
          "acc_norm_stderr,none": 0.011572517929968242
        }
      },
      "hellaswag": {
        "accuracy": 0.335291774546903,
        "full_results": {
          "alias": "hellaswag",
          "acc,none": 0.2817167894841665,
          "acc_stderr,none": 0.00448916676743026,
          "acc_norm,none": 0.335291774546903,
          "acc_norm_stderr,none": 0.004711275408138091
        }
      },
      "winogrande": {
        "accuracy": 0.5224940805051302,
        "full_results": {
          "alias": "winogrande",
          "acc,none": 0.5224940805051302,
          "acc_stderr,none": 0.014038257824059859
        }
      },
      "arc_easy": {
        "accuracy": 0.2908249158249158,
        "full_results": {
          "alias": "arc_easy",
          "acc,none": 0.2962962962962963,
          "acc_stderr,none": 0.009369711585684086,
          "acc_norm,none": 0.2908249158249158,
          "acc_norm_stderr,none": 0.00931881592117676
        }
      },
      "arc_challenge": {
        "accuracy": 0.24744027303754265,
        "full_results": {
          "alias": "arc_challenge",
          "acc,none": 0.24573378839590443,
          "acc_stderr,none": 0.012581033453730187,
          "acc_norm,none": 0.24744027303754265,
          "acc_norm_stderr,none": 0.01261035266329266
        }
      },
      "openbookqa": {
        "accuracy": 0.264,
        "full_results": {
          "alias": "openbookqa",
          "acc,none": 0.146,
          "acc_stderr,none": 0.015807205175834907,
          "acc_norm,none": 0.264,
          "acc_norm_stderr,none": 0.01973288558592215
        }
      }
    },
    "avg_zeroshot_acc": 0.40641080864097423,
    "efficiency": {
      "model_info": {
        "total_params": 4015132672,
        "trainable_params": 4015132672,
        "total_params_M": 4015.132672,
        "total_params_B": 4.015132672,
        "attention_params": 838860800,
        "mlp_params": 2125332480,
        "attention_params_M": 838.8608,
        "mlp_params_M": 2125.33248,
        "attention_ratio": 0.20892480237325517,
        "mlp_ratio": 0.5293305735128645,
        "num_layers": 32,
        "model_size_mb": 7658.258056640625,
        "model_size_gb": 7.47876763343811
      },
      "speed": {
        "batch_size_1": {
          "throughput_tokens_per_sec": 29.94764142372413,
          "latency_ms_per_token": 33.391611240804195,
          "total_time_sec": 213.70631194114685,
          "total_tokens": 6400
        },
        "batch_size_4": {
          "throughput_tokens_per_sec": 114.02684692951372,
          "latency_ms_per_token": 8.769864526887735,
          "total_time_sec": 53.88204765319824,
          "total_tokens": 6144
        }
      },
      "memory": {
        "model_memory_mb": 30677.48583984375,
        "inference_peak_mb": 30745.76123046875
      }
    }
  }
}