{
  "original_name": "原始模型",
  "pruned_name": "剪枝后模型",
  "total_params": {
    "original": 7248023552,
    "pruned": 5798424576,
    "reduced": 1449598976,
    "reduction_ratio": 0.19999920883259292
  },
  "layer_params": {
    "original": 6979584000,
    "pruned": 5529985024,
    "reduced": 1449598976,
    "reduction_ratio": 0.20769131455399062
  },
  "layers": [
    {
      "layer_idx": 0,
      "total": {
        "original": 218112000,
        "pruned": 202174464,
        "reduced": 15937536,
        "reduction_ratio": 0.07307042253521127
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175951872,
        "reduced": 208896,
        "reduction_ratio": 0.0011858258928571428,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14319
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": {
        "original": 218112000,
        "pruned": 218112000,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176160768,
        "reduced": 0,
        "reduction_ratio": 0.0,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14336
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": {
        "original": 218112000,
        "pruned": 211443712,
        "reduced": 6668288,
        "reduction_ratio": 0.030572769953051644
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174735360,
        "reduced": 1425408,
        "reduction_ratio": 0.008091517857142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14220
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": {
        "original": 218112000,
        "pruned": 217190400,
        "reduced": 921600,
        "reduction_ratio": 0.004225352112676056
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175239168,
        "reduced": 921600,
        "reduction_ratio": 0.005231584821428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14261
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": {
        "original": 218112000,
        "pruned": 210952192,
        "reduced": 7159808,
        "reduction_ratio": 0.032826291079812206
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174243840,
        "reduced": 1916928,
        "reduction_ratio": 0.010881696428571428,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14180
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": {
        "original": 218112000,
        "pruned": 210903040,
        "reduced": 7208960,
        "reduction_ratio": 0.03305164319248826
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174194688,
        "reduced": 1966080,
        "reduction_ratio": 0.011160714285714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14176
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": {
        "original": 218112000,
        "pruned": 190783488,
        "reduced": 27328512,
        "reduction_ratio": 0.12529577464788733
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 164560896,
        "reduced": 11599872,
        "reduction_ratio": 0.06584821428571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13392
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": {
        "original": 218112000,
        "pruned": 194043904,
        "reduced": 24068096,
        "reduction_ratio": 0.11034741784037559
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 157335552,
        "reduced": 18825216,
        "reduction_ratio": 0.10686383928571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12804
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": {
        "original": 218112000,
        "pruned": 186114048,
        "reduced": 31997952,
        "reduction_ratio": 0.14670422535211267
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 144162816,
        "reduced": 31997952,
        "reduction_ratio": 0.181640625,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11732
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": {
        "original": 218112000,
        "pruned": 138850304,
        "reduced": 79261696,
        "reduction_ratio": 0.36339906103286385
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 107384832,
        "reduced": 68775936,
        "reduction_ratio": 0.39041573660714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8739
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": {
        "original": 218112000,
        "pruned": 110608384,
        "reduced": 107503616,
        "reduction_ratio": 0.4928826291079812
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 73900032,
        "reduced": 102260736,
        "reduction_ratio": 0.5804966517857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6014
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": {
        "original": 218112000,
        "pruned": 85426176,
        "reduced": 132685824,
        "reduction_ratio": 0.6083380281690141
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 59203584,
        "reduced": 116957184,
        "reduction_ratio": 0.6639229910714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 4818
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": {
        "original": 218112000,
        "pruned": 78286848,
        "reduced": 139825152,
        "reduction_ratio": 0.6410704225352113
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 52064256,
        "reduced": 124096512,
        "reduction_ratio": 0.7044503348214286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 4237
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": {
        "original": 218112000,
        "pruned": 95367168,
        "reduced": 122744832,
        "reduction_ratio": 0.5627605633802817
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 53415936,
        "reduced": 122744832,
        "reduction_ratio": 0.69677734375,
        "intermediate_size": {
          "original": 14336,
          "pruned": 4347
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": {
        "original": 218112000,
        "pruned": 90669056,
        "reduced": 127442944,
        "reduction_ratio": 0.5843004694835681
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 59203584,
        "reduced": 116957184,
        "reduction_ratio": 0.6639229910714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 4818
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": {
        "original": 218112000,
        "pruned": 108032000,
        "reduced": 110080000,
        "reduction_ratio": 0.5046948356807511
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 76566528,
        "reduced": 99594240,
        "reduction_ratio": 0.5653599330357143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6231
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": {
        "original": 218112000,
        "pruned": 133402624,
        "reduced": 84709376,
        "reduction_ratio": 0.3883755868544601
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 96694272,
        "reduced": 79466496,
        "reduction_ratio": 0.4511021205357143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7869
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": {
        "original": 218112000,
        "pruned": 161013760,
        "reduced": 57098240,
        "reduction_ratio": 0.26178403755868546
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 124305408,
        "reduced": 51855360,
        "reduction_ratio": 0.2943638392857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10116
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": {
        "original": 218112000,
        "pruned": 180285440,
        "reduced": 37826560,
        "reduction_ratio": 0.17342723004694835
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 148819968,
        "reduced": 27340800,
        "reduction_ratio": 0.15520368303571427,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12111
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": {
        "original": 218112000,
        "pruned": 205852672,
        "reduced": 12259328,
        "reduction_ratio": 0.05620657276995305
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 169144320,
        "reduced": 7016448,
        "reduction_ratio": 0.039829799107142856,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13765
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": {
        "original": 218112000,
        "pruned": 200269824,
        "reduced": 17842176,
        "reduction_ratio": 0.08180281690140845
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174047232,
        "reduced": 2113536,
        "reduction_ratio": 0.011997767857142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14164
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": {
        "original": 218112000,
        "pruned": 212107264,
        "reduced": 6004736,
        "reduction_ratio": 0.027530516431924883
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175398912,
        "reduced": 761856,
        "reduction_ratio": 0.004324776785714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14274
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": {
        "original": 218112000,
        "pruned": 201953280,
        "reduced": 16158720,
        "reduction_ratio": 0.07408450704225353
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175730688,
        "reduced": 430080,
        "reduction_ratio": 0.00244140625,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14301
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": {
        "original": 218112000,
        "pruned": 186200064,
        "reduced": 31911936,
        "reduction_ratio": 0.14630985915492958
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175706112,
        "reduced": 454656,
        "reduction_ratio": 0.0025809151785714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14299
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": {
        "original": 218112000,
        "pruned": 175652864,
        "reduced": 42459136,
        "reduction_ratio": 0.19466666666666665
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175644672,
        "reduced": 516096,
        "reduction_ratio": 0.0029296875,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14294
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": {
        "original": 218112000,
        "pruned": 175431680,
        "reduced": 42680320,
        "reduction_ratio": 0.19568075117370892
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175423488,
        "reduced": 737280,
        "reduction_ratio": 0.004185267857142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14276
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": {
        "original": 218112000,
        "pruned": 180047872,
        "reduced": 38064128,
        "reduction_ratio": 0.17451643192488264
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174796800,
        "reduced": 1363968,
        "reduction_ratio": 0.007742745535714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14225
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": {
        "original": 218112000,
        "pruned": 187596800,
        "reduced": 30515200,
        "reduction_ratio": 0.13990610328638498
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 171859968,
        "reduced": 4300800,
        "reduction_ratio": 0.0244140625,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13986
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": {
        "original": 218112000,
        "pruned": 180191232,
        "reduced": 37920768,
        "reduction_ratio": 0.17385915492957746
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 169697280,
        "reduced": 6463488,
        "reduction_ratio": 0.03669084821428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13810
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": {
        "original": 218112000,
        "pruned": 201285632,
        "reduced": 16826368,
        "reduction_ratio": 0.07714553990610329
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 169820160,
        "reduced": 6340608,
        "reduction_ratio": 0.03599330357142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13820
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": {
        "original": 218112000,
        "pruned": 187691008,
        "reduced": 30420992,
        "reduction_ratio": 0.13947417840375587
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 166711296,
        "reduced": 9449472,
        "reduction_ratio": 0.05364118303571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13567
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": {
        "original": 218112000,
        "pruned": 212045824,
        "reduced": 6066176,
        "reduction_ratio": 0.027812206572769952
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175337472,
        "reduced": 823296,
        "reduction_ratio": 0.004673549107142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14269
        }
      },
      "is_zero_layer": false
    }
  ]
}