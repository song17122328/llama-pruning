{
  "original_name": "原始模型",
  "pruned_name": "剪枝后模型",
  "total_params": {
    "original": 8030261248,
    "pruned": 6424211456,
    "reduced": 1606049792,
    "reduction_ratio": 0.1999996939576529
  },
  "layer_params": {
    "original": 6979584000,
    "pruned": 5373534208,
    "reduced": 1606049792,
    "reduction_ratio": 0.2301068075117371
  },
  "layers": [
    {
      "layer_idx": 0,
      "total": {
        "original": 218112000,
        "pruned": 214351872,
        "reduced": 3760128,
        "reduction_ratio": 0.017239436619718308
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 172400640,
        "reduced": 3760128,
        "reduction_ratio": 0.021344866071428572,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14030
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": {
        "original": 218112000,
        "pruned": 208723968,
        "reduced": 9388032,
        "reduction_ratio": 0.04304225352112676
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 166772736,
        "reduced": 9388032,
        "reduction_ratio": 0.05329241071428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13572
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": {
        "original": 218112000,
        "pruned": 207298560,
        "reduced": 10813440,
        "reduction_ratio": 0.049577464788732394
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 165347328,
        "reduced": 10813440,
        "reduction_ratio": 0.06138392857142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13456
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": {
        "original": 218112000,
        "pruned": 203526144,
        "reduced": 14585856,
        "reduction_ratio": 0.06687323943661971
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 161574912,
        "reduced": 14585856,
        "reduction_ratio": 0.08279854910714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13149
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": {
        "original": 218112000,
        "pruned": 206241792,
        "reduced": 11870208,
        "reduction_ratio": 0.05442253521126761
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 164290560,
        "reduced": 11870208,
        "reduction_ratio": 0.0673828125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13370
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": {
        "original": 218112000,
        "pruned": 204865536,
        "reduced": 13246464,
        "reduction_ratio": 0.060732394366197186
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 162914304,
        "reduced": 13246464,
        "reduction_ratio": 0.0751953125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13258
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": {
        "original": 218112000,
        "pruned": 200503296,
        "reduced": 17608704,
        "reduction_ratio": 0.08073239436619718
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 158552064,
        "reduced": 17608704,
        "reduction_ratio": 0.09995814732142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12903
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": {
        "original": 218112000,
        "pruned": 194113536,
        "reduced": 23998464,
        "reduction_ratio": 0.1100281690140845
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 152162304,
        "reduced": 23998464,
        "reduction_ratio": 0.13623046875,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12383
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": {
        "original": 218112000,
        "pruned": 190525440,
        "reduced": 27586560,
        "reduction_ratio": 0.12647887323943663
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 148574208,
        "reduced": 27586560,
        "reduction_ratio": 0.15659877232142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12091
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": {
        "original": 218112000,
        "pruned": 190193664,
        "reduced": 27918336,
        "reduction_ratio": 0.128
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 148242432,
        "reduced": 27918336,
        "reduction_ratio": 0.15848214285714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12064
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": {
        "original": 218112000,
        "pruned": 186163200,
        "reduced": 31948800,
        "reduction_ratio": 0.14647887323943662
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 144211968,
        "reduced": 31948800,
        "reduction_ratio": 0.18136160714285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11736
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": {
        "original": 218112000,
        "pruned": 186458112,
        "reduced": 31653888,
        "reduction_ratio": 0.14512676056338028
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 144506880,
        "reduced": 31653888,
        "reduction_ratio": 0.1796875,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11760
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": {
        "original": 218112000,
        "pruned": 180965376,
        "reduced": 37146624,
        "reduction_ratio": 0.17030985915492958
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 139014144,
        "reduced": 37146624,
        "reduction_ratio": 0.21086774553571427,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11313
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": {
        "original": 218112000,
        "pruned": 176517120,
        "reduced": 41594880,
        "reduction_ratio": 0.19070422535211268
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 134565888,
        "reduced": 41594880,
        "reduction_ratio": 0.23611886160714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10951
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": {
        "original": 218112000,
        "pruned": 182095872,
        "reduced": 36016128,
        "reduction_ratio": 0.16512676056338027
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 140144640,
        "reduced": 36016128,
        "reduction_ratio": 0.20445033482142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11405
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": {
        "original": 218112000,
        "pruned": 173285376,
        "reduced": 44826624,
        "reduction_ratio": 0.2055211267605634
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 131334144,
        "reduced": 44826624,
        "reduction_ratio": 0.2544642857142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10688
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": {
        "original": 218112000,
        "pruned": 163700736,
        "reduced": 54411264,
        "reduction_ratio": 0.24946478873239436
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 121749504,
        "reduced": 54411264,
        "reduction_ratio": 0.30887276785714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9908
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": {
        "original": 218112000,
        "pruned": 163368960,
        "reduced": 54743040,
        "reduction_ratio": 0.25098591549295773
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 121417728,
        "reduced": 54743040,
        "reduction_ratio": 0.31075613839285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9881
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": {
        "original": 218112000,
        "pruned": 141729792,
        "reduced": 76382208,
        "reduction_ratio": 0.35019718309859155
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 115507200,
        "reduced": 60653568,
        "reduction_ratio": 0.3443080357142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9400
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": {
        "original": 218112000,
        "pruned": 147742720,
        "reduced": 70369280,
        "reduction_ratio": 0.32262910798122063
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 111034368,
        "reduced": 65126400,
        "reduction_ratio": 0.3696986607142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9036
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": {
        "original": 218112000,
        "pruned": 150323200,
        "reduced": 67788800,
        "reduction_ratio": 0.3107981220657277
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 113614848,
        "reduced": 62545920,
        "reduction_ratio": 0.3550502232142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9246
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": {
        "original": 218112000,
        "pruned": 156020736,
        "reduced": 62091264,
        "reduction_ratio": 0.28467605633802817
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 114069504,
        "reduced": 62091264,
        "reduction_ratio": 0.3524693080357143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9283
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": {
        "original": 218112000,
        "pruned": 149069824,
        "reduced": 69042176,
        "reduction_ratio": 0.31654460093896714
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 112361472,
        "reduced": 63799296,
        "reduction_ratio": 0.36216517857142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9144
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": {
        "original": 218112000,
        "pruned": 117362688,
        "reduced": 100749312,
        "reduction_ratio": 0.4619154929577465
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 106868736,
        "reduced": 69292032,
        "reduction_ratio": 0.39334542410714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8697
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": {
        "original": 218112000,
        "pruned": 146841600,
        "reduced": 71270400,
        "reduction_ratio": 0.3267605633802817
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 104890368,
        "reduced": 71270400,
        "reduction_ratio": 0.40457589285714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8536
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": {
        "original": 218112000,
        "pruned": 133222400,
        "reduced": 84889600,
        "reduction_ratio": 0.3892018779342723
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 101756928,
        "reduced": 74403840,
        "reduction_ratio": 0.42236328125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8281
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": {
        "original": 218112000,
        "pruned": 130088960,
        "reduced": 88023040,
        "reduction_ratio": 0.4035680751173709
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 98623488,
        "reduced": 77537280,
        "reduction_ratio": 0.44015066964285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8026
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": {
        "original": 218112000,
        "pruned": 126414848,
        "reduced": 91697152,
        "reduction_ratio": 0.4204131455399061
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 94949376,
        "reduced": 81211392,
        "reduction_ratio": 0.4610072544642857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7727
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": {
        "original": 218112000,
        "pruned": 139259904,
        "reduced": 78852096,
        "reduction_ratio": 0.36152112676056336
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 97308672,
        "reduced": 78852096,
        "reduction_ratio": 0.44761439732142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7919
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": {
        "original": 218112000,
        "pruned": 119672832,
        "reduced": 98439168,
        "reduction_ratio": 0.4513239436619718
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 93450240,
        "reduced": 82710528,
        "reduction_ratio": 0.46951729910714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7605
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": {
        "original": 218112000,
        "pruned": 134344704,
        "reduced": 83767296,
        "reduction_ratio": 0.384056338028169
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 92393472,
        "reduced": 83767296,
        "reduction_ratio": 0.4755161830357143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7519
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": {
        "original": 218112000,
        "pruned": 148541440,
        "reduced": 69570560,
        "reduction_ratio": 0.31896713615023475
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 111833088,
        "reduced": 64327680,
        "reduction_ratio": 0.3651646205357143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9101
        }
      },
      "is_zero_layer": false
    }
  ]
}