python run_global_pruning.py --base_model /newdata/LLMs/Mistral-7B-Instruct-v0.3 --output_name search_Mistral-Instruct_blockwise_20/exp_018_taylor_seq_len256_taylor_num_samples128 --pruning_ratio 0.2 --taylor_seq_len 256 --taylor_num_samples 128 --layer_importance_seq_len 256 --layer_importance_num_samples 25 --block_importance_seq_len 256 --block_importance_num_samples 25 --dataset c4 --temperature 1.0 --tau -100 --importance_method taylor --gradient_batch_size 4 --run_evaluation ppl,zeroshot --eval_ppl_datasets wikitext2,ptb --eval_zeroshot_tasks boolq,piqa,hellaswag,winogrande,arc_easy,arc_challenge,openbookqa