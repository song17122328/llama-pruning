{
  "original_name": "原始模型",
  "pruned_name": "剪枝后模型",
  "total_params": {
    "original": 7248023552,
    "pruned": 5798424576,
    "reduced": 1449598976,
    "reduction_ratio": 0.19999920883259292
  },
  "layer_params": {
    "original": 6979584000,
    "pruned": 5529985024,
    "reduced": 1449598976,
    "reduction_ratio": 0.20769131455399062
  },
  "layers": [
    {
      "layer_idx": 0,
      "total": {
        "original": 218112000,
        "pruned": 73187328,
        "reduced": 144924672,
        "reduction_ratio": 0.6644507042253521
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 46964736,
        "reduced": 129196032,
        "reduction_ratio": 0.7333984375,
        "intermediate_size": {
          "original": 14336,
          "pruned": 3822
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": {
        "original": 218112000,
        "pruned": 210509824,
        "reduced": 7602176,
        "reduction_ratio": 0.034854460093896714
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173801472,
        "reduced": 2359296,
        "reduction_ratio": 0.013392857142857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14144
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": {
        "original": 218112000,
        "pruned": 210681856,
        "reduced": 7430144,
        "reduction_ratio": 0.034065727699530514
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173973504,
        "reduced": 2187264,
        "reduction_ratio": 0.012416294642857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14158
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": {
        "original": 218112000,
        "pruned": 217620480,
        "reduced": 491520,
        "reduction_ratio": 0.0022535211267605635
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175669248,
        "reduced": 491520,
        "reduction_ratio": 0.0027901785714285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14296
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": {
        "original": 218112000,
        "pruned": 212205568,
        "reduced": 5906432,
        "reduction_ratio": 0.02707981220657277
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175497216,
        "reduced": 663552,
        "reduction_ratio": 0.0037667410714285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14282
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": {
        "original": 218112000,
        "pruned": 217804800,
        "reduced": 307200,
        "reduction_ratio": 0.0014084507042253522
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175853568,
        "reduced": 307200,
        "reduction_ratio": 0.0017438616071428572,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14311
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": {
        "original": 218112000,
        "pruned": 211333120,
        "reduced": 6778880,
        "reduction_ratio": 0.03107981220657277
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174624768,
        "reduced": 1536000,
        "reduction_ratio": 0.008719308035714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14211
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": {
        "original": 218112000,
        "pruned": 210104320,
        "reduced": 8007680,
        "reduction_ratio": 0.03671361502347418
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173395968,
        "reduced": 2764800,
        "reduction_ratio": 0.015694754464285716,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14111
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": {
        "original": 218112000,
        "pruned": 212987904,
        "reduced": 5124096,
        "reduction_ratio": 0.023492957746478874
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 171036672,
        "reduced": 5124096,
        "reduction_ratio": 0.029087611607142856,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13919
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": {
        "original": 218112000,
        "pruned": 209289216,
        "reduced": 8822784,
        "reduction_ratio": 0.040450704225352116
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 167337984,
        "reduced": 8822784,
        "reduction_ratio": 0.050083705357142856,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13618
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": {
        "original": 218112000,
        "pruned": 199360512,
        "reduced": 18751488,
        "reduction_ratio": 0.08597183098591549
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 157409280,
        "reduced": 18751488,
        "reduction_ratio": 0.1064453125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12810
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": {
        "original": 218112000,
        "pruned": 189677568,
        "reduced": 28434432,
        "reduction_ratio": 0.13036619718309858
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 147726336,
        "reduced": 28434432,
        "reduction_ratio": 0.16141183035714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12022
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": {
        "original": 218112000,
        "pruned": 182325248,
        "reduced": 35786752,
        "reduction_ratio": 0.16407511737089203
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 150859776,
        "reduced": 25300992,
        "reduction_ratio": 0.14362444196428573,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12277
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": {
        "original": 218112000,
        "pruned": 191336448,
        "reduced": 26775552,
        "reduction_ratio": 0.12276056338028168
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 149385216,
        "reduced": 26775552,
        "reduction_ratio": 0.15199497767857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12157
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": {
        "original": 218112000,
        "pruned": 180670464,
        "reduced": 37441536,
        "reduction_ratio": 0.17166197183098592
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 138719232,
        "reduced": 37441536,
        "reduction_ratio": 0.21254185267857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11289
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": {
        "original": 218112000,
        "pruned": 179580928,
        "reduced": 38531072,
        "reduction_ratio": 0.17665727699530517
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 142872576,
        "reduced": 33288192,
        "reduction_ratio": 0.18896484375,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11627
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": {
        "original": 218112000,
        "pruned": 194654208,
        "reduced": 23457792,
        "reduction_ratio": 0.10754929577464789
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 152702976,
        "reduced": 23457792,
        "reduction_ratio": 0.13316127232142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12427
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": {
        "original": 218112000,
        "pruned": 190009344,
        "reduced": 28102656,
        "reduction_ratio": 0.1288450704225352
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 148058112,
        "reduced": 28102656,
        "reduction_ratio": 0.15952845982142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12049
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": {
        "original": 218112000,
        "pruned": 182226944,
        "reduced": 35885056,
        "reduction_ratio": 0.16452582159624413
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 150761472,
        "reduced": 25399296,
        "reduction_ratio": 0.14418247767857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12269
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": {
        "original": 218112000,
        "pruned": 190418944,
        "reduced": 27693056,
        "reduction_ratio": 0.12696713615023475
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 153710592,
        "reduced": 22450176,
        "reduction_ratio": 0.12744140625,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12509
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": {
        "original": 218112000,
        "pruned": 194490368,
        "reduced": 23621632,
        "reduction_ratio": 0.10830046948356807
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 163024896,
        "reduced": 13135872,
        "reduction_ratio": 0.07456752232142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13267
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": {
        "original": 218112000,
        "pruned": 207093760,
        "reduced": 11018240,
        "reduction_ratio": 0.05051643192488263
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 170385408,
        "reduced": 5775360,
        "reduction_ratio": 0.03278459821428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13866
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": {
        "original": 218112000,
        "pruned": 192679936,
        "reduced": 25432064,
        "reduction_ratio": 0.11660093896713615
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 171700224,
        "reduced": 4460544,
        "reduction_ratio": 0.025320870535714284,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13973
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": {
        "original": 218112000,
        "pruned": 201666560,
        "reduced": 16445440,
        "reduction_ratio": 0.07539906103286385
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 170201088,
        "reduced": 5959680,
        "reduction_ratio": 0.03383091517857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13851
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": {
        "original": 218112000,
        "pruned": 179023872,
        "reduced": 39088128,
        "reduction_ratio": 0.1792112676056338
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 168529920,
        "reduced": 7630848,
        "reduction_ratio": 0.04331752232142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13715
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": {
        "original": 218112000,
        "pruned": 175902720,
        "reduced": 42209280,
        "reduction_ratio": 0.19352112676056338
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 165408768,
        "reduced": 10752000,
        "reduction_ratio": 0.06103515625,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13461
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": {
        "original": 218112000,
        "pruned": 166735872,
        "reduced": 51376128,
        "reduction_ratio": 0.2355492957746479
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 156241920,
        "reduced": 19918848,
        "reduction_ratio": 0.11307198660714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12715
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": {
        "original": 218112000,
        "pruned": 146042880,
        "reduced": 72069120,
        "reduction_ratio": 0.33042253521126763
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 135548928,
        "reduced": 40611840,
        "reduction_ratio": 0.23053850446428573,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11031
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": {
        "original": 218112000,
        "pruned": 100163584,
        "reduced": 117948416,
        "reduction_ratio": 0.5407699530516432
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 94912512,
        "reduced": 81248256,
        "reduction_ratio": 0.46121651785714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7724
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": {
        "original": 218112000,
        "pruned": 75231232,
        "reduced": 142880768,
        "reduction_ratio": 0.6550798122065727
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 54251520,
        "reduced": 121909248,
        "reduction_ratio": 0.6920340401785714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 4415
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": {
        "original": 218112000,
        "pruned": 16412672,
        "reduced": 201699328,
        "reduction_ratio": 0.9247511737089202
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 16404480,
        "reduced": 159756288,
        "reduction_ratio": 0.9068777901785714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 1335
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": {
        "original": 218112000,
        "pruned": 8556544,
        "reduced": 209555456,
        "reduction_ratio": 0.9607699530516431
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 3305472,
        "reduced": 172855296,
        "reduction_ratio": 0.9812360491071429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 269
        }
      },
      "is_zero_layer": false
    }
  ]
}