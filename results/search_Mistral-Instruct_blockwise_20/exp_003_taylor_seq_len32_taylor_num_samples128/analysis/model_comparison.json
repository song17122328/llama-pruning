{
  "original_name": "原始模型",
  "pruned_name": "剪枝后模型",
  "total_params": {
    "original": 7248023552,
    "pruned": 5798428672,
    "reduced": 1449594880,
    "reduction_ratio": 0.19999864371301646
  },
  "layer_params": {
    "original": 6979584000,
    "pruned": 5529989120,
    "reduced": 1449594880,
    "reduction_ratio": 0.2076907276995305
  },
  "layers": [
    {
      "layer_idx": 0,
      "total": {
        "original": 218112000,
        "pruned": 142442496,
        "reduced": 75669504,
        "reduction_ratio": 0.34692957746478875
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 100491264,
        "reduced": 75669504,
        "reduction_ratio": 0.42954799107142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8178
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": {
        "original": 218112000,
        "pruned": 218038272,
        "reduced": 73728,
        "reduction_ratio": 0.0003380281690140845
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176087040,
        "reduced": 73728,
        "reduction_ratio": 0.0004185267857142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14330
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": {
        "original": 218112000,
        "pruned": 212684800,
        "reduced": 5427200,
        "reduction_ratio": 0.02488262910798122
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175976448,
        "reduced": 184320,
        "reduction_ratio": 0.0010463169642857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14321
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": {
        "original": 218112000,
        "pruned": 218062848,
        "reduced": 49152,
        "reduction_ratio": 0.00022535211267605634
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176111616,
        "reduced": 49152,
        "reduction_ratio": 0.00027901785714285713,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14332
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": {
        "original": 218112000,
        "pruned": 217939968,
        "reduced": 172032,
        "reduction_ratio": 0.0007887323943661971
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175988736,
        "reduced": 172032,
        "reduction_ratio": 0.0009765625,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14322
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": {
        "original": 218112000,
        "pruned": 218025984,
        "reduced": 86016,
        "reduction_ratio": 0.00039436619718309857
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176074752,
        "reduced": 86016,
        "reduction_ratio": 0.00048828125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14329
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": {
        "original": 218112000,
        "pruned": 217657344,
        "reduced": 454656,
        "reduction_ratio": 0.002084507042253521
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175706112,
        "reduced": 454656,
        "reduction_ratio": 0.0025809151785714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14299
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": {
        "original": 218112000,
        "pruned": 211763200,
        "reduced": 6348800,
        "reduction_ratio": 0.02910798122065728
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175054848,
        "reduced": 1105920,
        "reduction_ratio": 0.006277901785714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14246
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": {
        "original": 218112000,
        "pruned": 216674304,
        "reduced": 1437696,
        "reduction_ratio": 0.006591549295774648
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174723072,
        "reduced": 1437696,
        "reduction_ratio": 0.008161272321428572,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14219
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": {
        "original": 218112000,
        "pruned": 215961600,
        "reduced": 2150400,
        "reduction_ratio": 0.009859154929577466
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174010368,
        "reduced": 2150400,
        "reduction_ratio": 0.01220703125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14161
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": {
        "original": 218112000,
        "pruned": 204386304,
        "reduced": 13725696,
        "reduction_ratio": 0.06292957746478874
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 162435072,
        "reduced": 13725696,
        "reduction_ratio": 0.07791573660714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13219
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": {
        "original": 218112000,
        "pruned": 185167872,
        "reduced": 32944128,
        "reduction_ratio": 0.15104225352112677
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 143216640,
        "reduced": 32944128,
        "reduction_ratio": 0.18701171875,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11655
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": {
        "original": 218112000,
        "pruned": 162480128,
        "reduced": 55631872,
        "reduction_ratio": 0.2550610328638498
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 131014656,
        "reduced": 45146112,
        "reduction_ratio": 0.2562779017857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10662
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": {
        "original": 218112000,
        "pruned": 162717696,
        "reduced": 55394304,
        "reduction_ratio": 0.25397183098591547
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 120766464,
        "reduced": 55394304,
        "reduction_ratio": 0.314453125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9828
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": {
        "original": 218112000,
        "pruned": 149962752,
        "reduced": 68149248,
        "reduction_ratio": 0.3124507042253521
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 108011520,
        "reduced": 68149248,
        "reduction_ratio": 0.38685825892857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8790
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": {
        "original": 218112000,
        "pruned": 152170496,
        "reduced": 65941504,
        "reduction_ratio": 0.30232863849765257
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 120705024,
        "reduced": 55455744,
        "reduction_ratio": 0.31480189732142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9823
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": {
        "original": 218112000,
        "pruned": 176664576,
        "reduced": 41447424,
        "reduction_ratio": 0.1900281690140845
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 134713344,
        "reduced": 41447424,
        "reduction_ratio": 0.23528180803571427,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10963
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": {
        "original": 218112000,
        "pruned": 180461568,
        "reduced": 37650432,
        "reduction_ratio": 0.17261971830985914
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 138510336,
        "reduced": 37650432,
        "reduction_ratio": 0.21372767857142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11272
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": {
        "original": 218112000,
        "pruned": 186314752,
        "reduced": 31797248,
        "reduction_ratio": 0.14578403755868544
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 149606400,
        "reduced": 26554368,
        "reduction_ratio": 0.15073939732142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12175
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": {
        "original": 218112000,
        "pruned": 196317184,
        "reduced": 21794816,
        "reduction_ratio": 0.09992488262910798
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 159608832,
        "reduced": 16551936,
        "reduction_ratio": 0.09395926339285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12989
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": {
        "original": 218112000,
        "pruned": 198168576,
        "reduced": 19943424,
        "reduction_ratio": 0.09143661971830985
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 171945984,
        "reduced": 4214784,
        "reduction_ratio": 0.02392578125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13993
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": {
        "original": 218112000,
        "pruned": 211677184,
        "reduced": 6434816,
        "reduction_ratio": 0.029502347417840375
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174968832,
        "reduced": 1191936,
        "reduction_ratio": 0.006766183035714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14239
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": {
        "original": 218112000,
        "pruned": 185769984,
        "reduced": 32342016,
        "reduction_ratio": 0.14828169014084508
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175276032,
        "reduced": 884736,
        "reduction_ratio": 0.005022321428571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14264
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": {
        "original": 218112000,
        "pruned": 180711424,
        "reduced": 37400576,
        "reduction_ratio": 0.17147417840375587
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175460352,
        "reduced": 700416,
        "reduction_ratio": 0.003976004464285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14279
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": {
        "original": 218112000,
        "pruned": 174927872,
        "reduced": 43184128,
        "reduction_ratio": 0.1979906103286385
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174919680,
        "reduced": 1241088,
        "reduction_ratio": 0.007045200892857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14235
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": {
        "original": 218112000,
        "pruned": 173809664,
        "reduced": 44302336,
        "reduction_ratio": 0.20311737089201878
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173801472,
        "reduced": 2359296,
        "reduction_ratio": 0.013392857142857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14144
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": {
        "original": 218112000,
        "pruned": 168919040,
        "reduced": 49192960,
        "reduction_ratio": 0.2255399061032864
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 168910848,
        "reduced": 7249920,
        "reduction_ratio": 0.04115513392857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13746
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": {
        "original": 218112000,
        "pruned": 158158848,
        "reduced": 59953152,
        "reduction_ratio": 0.27487323943661973
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 147664896,
        "reduced": 28495872,
        "reduction_ratio": 0.16176060267857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12017
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": {
        "original": 218112000,
        "pruned": 97116160,
        "reduced": 120995840,
        "reduction_ratio": 0.5547417840375587
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 91865088,
        "reduced": 84295680,
        "reduction_ratio": 0.478515625,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7476
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": {
        "original": 218112000,
        "pruned": 63946752,
        "reduced": 154165248,
        "reduction_ratio": 0.7068169014084507
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 53452800,
        "reduced": 122707968,
        "reduction_ratio": 0.6965680803571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 4350
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": {
        "original": 218112000,
        "pruned": 33222656,
        "reduced": 184889344,
        "reduction_ratio": 0.8476807511737089
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 33214464,
        "reduced": 142946304,
        "reduction_ratio": 0.8114536830357143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 2703
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": {
        "original": 218112000,
        "pruned": 37666816,
        "reduced": 180445184,
        "reduction_ratio": 0.8273051643192488
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 32415744,
        "reduced": 143745024,
        "reduction_ratio": 0.8159877232142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 2638
        }
      },
      "is_zero_layer": false
    }
  ]
}