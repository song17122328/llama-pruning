{
  "original_name": "原始模型",
  "pruned_name": "剪枝后模型",
  "total_params": {
    "original": 7248023552,
    "pruned": 5798424576,
    "reduced": 1449598976,
    "reduction_ratio": 0.19999920883259292
  },
  "layer_params": {
    "original": 6979584000,
    "pruned": 5529985024,
    "reduced": 1449598976,
    "reduction_ratio": 0.20769131455399062
  },
  "layers": [
    {
      "layer_idx": 0,
      "total": {
        "original": 218112000,
        "pruned": 201510912,
        "reduced": 16601088,
        "reduction_ratio": 0.07611267605633802
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175288320,
        "reduced": 872448,
        "reduction_ratio": 0.004952566964285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14265
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": {
        "original": 218112000,
        "pruned": 218112000,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176160768,
        "reduced": 0,
        "reduction_ratio": 0.0,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14336
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": {
        "original": 218112000,
        "pruned": 196284416,
        "reduced": 21827584,
        "reduction_ratio": 0.10007511737089202
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 164818944,
        "reduced": 11341824,
        "reduction_ratio": 0.06438337053571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13413
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": {
        "original": 218112000,
        "pruned": 212385792,
        "reduced": 5726208,
        "reduction_ratio": 0.026253521126760562
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 170434560,
        "reduced": 5726208,
        "reduction_ratio": 0.032505580357142856,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13870
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": {
        "original": 218112000,
        "pruned": 197226496,
        "reduced": 20885504,
        "reduction_ratio": 0.09575586854460094
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 160518144,
        "reduced": 15642624,
        "reduction_ratio": 0.08879743303571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13063
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": {
        "original": 218112000,
        "pruned": 198266880,
        "reduced": 19845120,
        "reduction_ratio": 0.09098591549295774
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 156315648,
        "reduced": 19845120,
        "reduction_ratio": 0.11265345982142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12721
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": {
        "original": 218112000,
        "pruned": 146632704,
        "reduced": 71479296,
        "reduction_ratio": 0.32771830985915495
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 120410112,
        "reduced": 55750656,
        "reduction_ratio": 0.3164760044642857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9799
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": {
        "original": 218112000,
        "pruned": 147791872,
        "reduced": 70320128,
        "reduction_ratio": 0.3224037558685446
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 111083520,
        "reduced": 65077248,
        "reduction_ratio": 0.36941964285714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9040
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": {
        "original": 218112000,
        "pruned": 155713536,
        "reduced": 62398464,
        "reduction_ratio": 0.2860845070422535
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 113762304,
        "reduced": 62398464,
        "reduction_ratio": 0.35421316964285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9258
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": {
        "original": 218112000,
        "pruned": 128270336,
        "reduced": 89841664,
        "reduction_ratio": 0.411906103286385
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 96804864,
        "reduced": 79355904,
        "reduction_ratio": 0.45047433035714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7878
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": {
        "original": 218112000,
        "pruned": 126308352,
        "reduced": 91803648,
        "reduction_ratio": 0.42090140845070423
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 84357120,
        "reduced": 91803648,
        "reduction_ratio": 0.5211356026785714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6865
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": {
        "original": 218112000,
        "pruned": 105943040,
        "reduced": 112168960,
        "reduction_ratio": 0.5142723004694836
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 74477568,
        "reduced": 101683200,
        "reduction_ratio": 0.5772181919642857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6061
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": {
        "original": 218112000,
        "pruned": 112455680,
        "reduced": 105656320,
        "reduction_ratio": 0.4844131455399061
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 80990208,
        "reduced": 95170560,
        "reduction_ratio": 0.5402483258928571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6591
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": {
        "original": 218112000,
        "pruned": 121294848,
        "reduced": 96817152,
        "reduction_ratio": 0.443887323943662
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 79343616,
        "reduced": 96817152,
        "reduction_ratio": 0.5495954241071429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6457
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": {
        "original": 218112000,
        "pruned": 122716160,
        "reduced": 95395840,
        "reduction_ratio": 0.4373708920187793
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 91250688,
        "reduced": 84910080,
        "reduction_ratio": 0.4820033482142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7426
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": {
        "original": 218112000,
        "pruned": 133283840,
        "reduced": 84828160,
        "reduction_ratio": 0.38892018779342724
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 101818368,
        "reduced": 74342400,
        "reduction_ratio": 0.42201450892857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8286
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": {
        "original": 218112000,
        "pruned": 149962752,
        "reduced": 68149248,
        "reduction_ratio": 0.3124507042253521
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 108011520,
        "reduced": 68149248,
        "reduction_ratio": 0.38685825892857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8790
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": {
        "original": 218112000,
        "pruned": 159096832,
        "reduced": 59015168,
        "reduction_ratio": 0.27057276995305163
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 122388480,
        "reduced": 53772288,
        "reduction_ratio": 0.3052455357142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9960
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": {
        "original": 218112000,
        "pruned": 178872320,
        "reduced": 39239680,
        "reduction_ratio": 0.17990610328638498
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 147406848,
        "reduced": 28753920,
        "reduction_ratio": 0.16322544642857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11996
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": {
        "original": 218112000,
        "pruned": 198037504,
        "reduced": 20074496,
        "reduction_ratio": 0.09203755868544601
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 161329152,
        "reduced": 14831616,
        "reduction_ratio": 0.08419363839285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13129
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": {
        "original": 218112000,
        "pruned": 194703360,
        "reduced": 23408640,
        "reduction_ratio": 0.10732394366197183
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 168480768,
        "reduced": 7680000,
        "reduction_ratio": 0.04359654017857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13711
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": {
        "original": 218112000,
        "pruned": 199761920,
        "reduced": 18350080,
        "reduction_ratio": 0.08413145539906103
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 168296448,
        "reduced": 7864320,
        "reduction_ratio": 0.044642857142857144,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13696
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": {
        "original": 218112000,
        "pruned": 182390784,
        "reduced": 35721216,
        "reduction_ratio": 0.16377464788732393
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 171896832,
        "reduced": 4263936,
        "reduction_ratio": 0.024204799107142856,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13989
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": {
        "original": 218112000,
        "pruned": 203571200,
        "reduced": 14540800,
        "reduction_ratio": 0.06666666666666667
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 172105728,
        "reduced": 4055040,
        "reduction_ratio": 0.023018973214285716,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14006
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": {
        "original": 218112000,
        "pruned": 183791616,
        "reduced": 34320384,
        "reduction_ratio": 0.15735211267605634
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173297664,
        "reduced": 2863104,
        "reduction_ratio": 0.016252790178571428,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14103
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": {
        "original": 218112000,
        "pruned": 179101696,
        "reduced": 39010304,
        "reduction_ratio": 0.17885446009389672
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173850624,
        "reduced": 2310144,
        "reduction_ratio": 0.013113839285714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14148
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": {
        "original": 218112000,
        "pruned": 183300096,
        "reduced": 34811904,
        "reduction_ratio": 0.1596056338028169
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 172806144,
        "reduced": 3354624,
        "reduction_ratio": 0.01904296875,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14063
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": {
        "original": 218112000,
        "pruned": 198660096,
        "reduced": 19451904,
        "reduction_ratio": 0.0891830985915493
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 172437504,
        "reduced": 3723264,
        "reduction_ratio": 0.021135602678571428,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14033
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": {
        "original": 218112000,
        "pruned": 182784000,
        "reduced": 35328000,
        "reduction_ratio": 0.1619718309859155
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 172290048,
        "reduced": 3870720,
        "reduction_ratio": 0.02197265625,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14021
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": {
        "original": 218112000,
        "pruned": 207671296,
        "reduced": 10440704,
        "reduction_ratio": 0.047868544600938964
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 170962944,
        "reduced": 5197824,
        "reduction_ratio": 0.029506138392857144,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13913
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": {
        "original": 218112000,
        "pruned": 193388544,
        "reduced": 24723456,
        "reduction_ratio": 0.11335211267605634
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 167165952,
        "reduced": 8994816,
        "reduction_ratio": 0.051060267857142856,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13604
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": {
        "original": 218112000,
        "pruned": 210694144,
        "reduced": 7417856,
        "reduction_ratio": 0.0340093896713615
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173985792,
        "reduced": 2174976,
        "reduction_ratio": 0.012346540178571428,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14159
        }
      },
      "is_zero_layer": false
    }
  ]
}