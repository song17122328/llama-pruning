{
  "model_name": "剪枝后模型",
  "total_params": 6092498944,
  "embedding_params": 544997376,
  "lm_head_params": 544997376,
  "layers": [
    {
      "layer_idx": 0,
      "total": 146633216,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 39087104,
        "up_proj": 39087104,
        "down_proj": 39087104,
        "total": 117261312,
        "intermediate_size": 10906
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": 104087552,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 24905216,
        "up_proj": 24905216,
        "down_proj": 24905216,
        "total": 74715648,
        "intermediate_size": 6949
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": 141160448,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 37262848,
        "up_proj": 37262848,
        "down_proj": 37262848,
        "total": 111788544,
        "intermediate_size": 10397
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": 183329792,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 51319296,
        "up_proj": 51319296,
        "down_proj": 51319296,
        "total": 153957888,
        "intermediate_size": 14319
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": 200715776,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 57114624,
        "up_proj": 57114624,
        "down_proj": 57114624,
        "total": 171343872,
        "intermediate_size": 15936
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": 164417024,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 45015040,
        "up_proj": 45015040,
        "down_proj": 45015040,
        "total": 135045120,
        "intermediate_size": 12560
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": 198726656,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56451584,
        "up_proj": 56451584,
        "down_proj": 56451584,
        "total": 169354752,
        "intermediate_size": 15751
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": 206812160,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 59146752,
        "up_proj": 59146752,
        "down_proj": 59146752,
        "total": 177440256,
        "intermediate_size": 16503
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": 205005824,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58544640,
        "up_proj": 58544640,
        "down_proj": 58544640,
        "total": 175633920,
        "intermediate_size": 16335
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": 211209728,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 60612608,
        "up_proj": 60612608,
        "down_proj": 60612608,
        "total": 181837824,
        "intermediate_size": 16912
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": 203833856,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58153984,
        "up_proj": 58153984,
        "down_proj": 58153984,
        "total": 174461952,
        "intermediate_size": 16226
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": 204898304,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58508800,
        "up_proj": 58508800,
        "down_proj": 58508800,
        "total": 175526400,
        "intermediate_size": 16325
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": 198887936,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56505344,
        "up_proj": 56505344,
        "down_proj": 56505344,
        "total": 169516032,
        "intermediate_size": 15766
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": 204909056,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58512384,
        "up_proj": 58512384,
        "down_proj": 58512384,
        "total": 175537152,
        "intermediate_size": 16326
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": 212854784,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 61160960,
        "up_proj": 61160960,
        "down_proj": 61160960,
        "total": 183482880,
        "intermediate_size": 17065
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": 214736384,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 61788160,
        "up_proj": 61788160,
        "down_proj": 61788160,
        "total": 185364480,
        "intermediate_size": 17240
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": 215037440,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 61888512,
        "up_proj": 61888512,
        "down_proj": 61888512,
        "total": 185665536,
        "intermediate_size": 17268
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": 206016512,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58881536,
        "up_proj": 58881536,
        "down_proj": 58881536,
        "total": 176644608,
        "intermediate_size": 16429
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": 193436672,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 54688256,
        "up_proj": 54688256,
        "down_proj": 54688256,
        "total": 164064768,
        "intermediate_size": 15259
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": 189791744,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 53473280,
        "up_proj": 53473280,
        "down_proj": 53473280,
        "total": 160419840,
        "intermediate_size": 14920
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": 180760064,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 50462720,
        "up_proj": 50462720,
        "down_proj": 50462720,
        "total": 151388160,
        "intermediate_size": 14080
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": 174964736,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 48530944,
        "up_proj": 48530944,
        "down_proj": 48530944,
        "total": 145592832,
        "intermediate_size": 13541
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": 184351232,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 51659776,
        "up_proj": 51659776,
        "down_proj": 51659776,
        "total": 154979328,
        "intermediate_size": 14414
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": 175394816,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 48674304,
        "up_proj": 48674304,
        "down_proj": 48674304,
        "total": 146022912,
        "intermediate_size": 13581
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": 160933376,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 43853824,
        "up_proj": 43853824,
        "down_proj": 43853824,
        "total": 131561472,
        "intermediate_size": 12236
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": 137214464,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 35947520,
        "up_proj": 35947520,
        "down_proj": 35947520,
        "total": 107842560,
        "intermediate_size": 10030
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": 81347072,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 17325056,
        "up_proj": 17325056,
        "down_proj": 17325056,
        "total": 51975168,
        "intermediate_size": 4834
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": 101033984,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 23887360,
        "up_proj": 23887360,
        "down_proj": 23887360,
        "total": 71662080,
        "intermediate_size": 6665
      },
      "norm": 7168,
      "is_zero_layer": false
    }
  ],
  "layer_summary": {
    "num_layers": 28,
    "total_layer_params": 5002500608
  }
}