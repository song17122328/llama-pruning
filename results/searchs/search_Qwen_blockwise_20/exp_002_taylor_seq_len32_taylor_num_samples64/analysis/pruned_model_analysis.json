{
  "model_name": "剪枝后模型",
  "total_params": 6092480640,
  "embedding_params": 544997376,
  "lm_head_params": 544997376,
  "layers": [
    {
      "layer_idx": 0,
      "total": 180276224,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 50301440,
        "up_proj": 50301440,
        "down_proj": 50301440,
        "total": 150904320,
        "intermediate_size": 14035
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": 127387136,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 32671744,
        "up_proj": 32671744,
        "down_proj": 32671744,
        "total": 98015232,
        "intermediate_size": 9116
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": 174771200,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 48466432,
        "up_proj": 48466432,
        "down_proj": 48466432,
        "total": 145399296,
        "intermediate_size": 13523
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": 228907520,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 66511872,
        "up_proj": 66511872,
        "down_proj": 66511872,
        "total": 199535616,
        "intermediate_size": 18558
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": 223727488,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 9636480,
        "k_proj": 1376640,
        "v_proj": 1376640,
        "o_proj": 9633792,
        "total": 22023552,
        "num_heads": 21,
        "num_kv_heads": 3
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 67232256,
        "up_proj": 67232256,
        "down_proj": 67232256,
        "total": 201696768,
        "intermediate_size": 18759
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": 217899904,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 9636480,
        "k_proj": 1376640,
        "v_proj": 1376640,
        "o_proj": 9633792,
        "total": 22023552,
        "num_heads": 21,
        "num_kv_heads": 3
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 65289728,
        "up_proj": 65289728,
        "down_proj": 65289728,
        "total": 195869184,
        "intermediate_size": 18217
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": 224576896,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 9636480,
        "k_proj": 1376640,
        "v_proj": 1376640,
        "o_proj": 9633792,
        "total": 22023552,
        "num_heads": 21,
        "num_kv_heads": 3
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 67515392,
        "up_proj": 67515392,
        "down_proj": 67515392,
        "total": 202546176,
        "intermediate_size": 18838
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": 231574016,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 67400704,
        "up_proj": 67400704,
        "down_proj": 67400704,
        "total": 202202112,
        "intermediate_size": 18806
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": 222652288,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 9636480,
        "k_proj": 1376640,
        "v_proj": 1376640,
        "o_proj": 9633792,
        "total": 22023552,
        "num_heads": 21,
        "num_kv_heads": 3
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 66873856,
        "up_proj": 66873856,
        "down_proj": 66873856,
        "total": 200621568,
        "intermediate_size": 18659
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": 226230272,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 65619456,
        "up_proj": 65619456,
        "down_proj": 65619456,
        "total": 196858368,
        "intermediate_size": 18309
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": 226692608,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 65773568,
        "up_proj": 65773568,
        "down_proj": 65773568,
        "total": 197320704,
        "intermediate_size": 18352
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": 224187392,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 64938496,
        "up_proj": 64938496,
        "down_proj": 64938496,
        "total": 194815488,
        "intermediate_size": 18119
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": 191780864,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 54136320,
        "up_proj": 54136320,
        "down_proj": 54136320,
        "total": 162408960,
        "intermediate_size": 15105
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": 145385984,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 38671360,
        "up_proj": 38671360,
        "down_proj": 38671360,
        "total": 116014080,
        "intermediate_size": 10790
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": 99665024,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 3212160,
        "k_proj": 458880,
        "v_proj": 458880,
        "o_proj": 3211264,
        "total": 7341184,
        "num_heads": 7,
        "num_kv_heads": 1
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 30772224,
        "up_proj": 30772224,
        "down_proj": 30772224,
        "total": 92316672,
        "intermediate_size": 8586
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": 97466752,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 9636480,
        "k_proj": 1376640,
        "v_proj": 1376640,
        "o_proj": 9633792,
        "total": 22023552,
        "num_heads": 21,
        "num_kv_heads": 3
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 25145344,
        "up_proj": 25145344,
        "down_proj": 25145344,
        "total": 75436032,
        "intermediate_size": 7016
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": 73610496,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 6424320,
        "k_proj": 917760,
        "v_proj": 917760,
        "o_proj": 6422528,
        "total": 14682368,
        "num_heads": 14,
        "num_kv_heads": 2
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 19640320,
        "up_proj": 19640320,
        "down_proj": 19640320,
        "total": 58920960,
        "intermediate_size": 5480
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": 93208960,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 9636480,
        "k_proj": 1376640,
        "v_proj": 1376640,
        "o_proj": 9633792,
        "total": 22023552,
        "num_heads": 21,
        "num_kv_heads": 3
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 23726080,
        "up_proj": 23726080,
        "down_proj": 23726080,
        "total": 71178240,
        "intermediate_size": 6620
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": 110280704,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 26969600,
        "up_proj": 26969600,
        "down_proj": 26969600,
        "total": 80908800,
        "intermediate_size": 7525
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": 132193280,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 34273792,
        "up_proj": 34273792,
        "down_proj": 34273792,
        "total": 102821376,
        "intermediate_size": 9563
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": 159976448,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 43534848,
        "up_proj": 43534848,
        "down_proj": 43534848,
        "total": 130604544,
        "intermediate_size": 12147
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": 167148032,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 45925376,
        "up_proj": 45925376,
        "down_proj": 45925376,
        "total": 137776128,
        "intermediate_size": 12814
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": 176765184,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 6424320,
        "k_proj": 917760,
        "v_proj": 917760,
        "o_proj": 6422528,
        "total": 14682368,
        "num_heads": 14,
        "num_kv_heads": 2
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 54025216,
        "up_proj": 54025216,
        "down_proj": 54025216,
        "total": 162075648,
        "intermediate_size": 15074
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": 186039296,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 52222464,
        "up_proj": 52222464,
        "down_proj": 52222464,
        "total": 156667392,
        "intermediate_size": 14571
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": 203645184,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 6424320,
        "k_proj": 917760,
        "v_proj": 917760,
        "o_proj": 6422528,
        "total": 14682368,
        "num_heads": 14,
        "num_kv_heads": 2
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 62985216,
        "up_proj": 62985216,
        "down_proj": 62985216,
        "total": 188955648,
        "intermediate_size": 17574
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": 217921408,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 9636480,
        "k_proj": 1376640,
        "v_proj": 1376640,
        "o_proj": 9633792,
        "total": 22023552,
        "num_heads": 21,
        "num_kv_heads": 3
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 65296896,
        "up_proj": 65296896,
        "down_proj": 65296896,
        "total": 195890688,
        "intermediate_size": 18219
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": 208668800,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 3212160,
        "k_proj": 458880,
        "v_proj": 458880,
        "o_proj": 3211264,
        "total": 7341184,
        "num_heads": 7,
        "num_kv_heads": 1
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 67106816,
        "up_proj": 67106816,
        "down_proj": 67106816,
        "total": 201320448,
        "intermediate_size": 18724
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": 229842944,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 66823680,
        "up_proj": 66823680,
        "down_proj": 66823680,
        "total": 200471040,
        "intermediate_size": 18645
      },
      "norm": 7168,
      "is_zero_layer": false
    }
  ],
  "layer_summary": {
    "num_layers": 28,
    "total_layer_params": 5002482304
  }
}