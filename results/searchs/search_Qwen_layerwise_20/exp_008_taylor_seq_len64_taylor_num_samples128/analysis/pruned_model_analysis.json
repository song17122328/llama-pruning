{
  "model_name": "剪枝后模型",
  "total_params": 6092501376,
  "embedding_params": 544997376,
  "lm_head_params": 544997376,
  "layers": [
    {
      "layer_idx": 0,
      "total": 190393856,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 53673984,
        "up_proj": 53673984,
        "down_proj": 53673984,
        "total": 161021952,
        "intermediate_size": 14976
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": 53133824,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 7920640,
        "up_proj": 7920640,
        "down_proj": 7920640,
        "total": 23761920,
        "intermediate_size": 2210
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": 77777408,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 16135168,
        "up_proj": 16135168,
        "down_proj": 16135168,
        "total": 48405504,
        "intermediate_size": 4502
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": 142042112,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 37556736,
        "up_proj": 37556736,
        "down_proj": 37556736,
        "total": 112670208,
        "intermediate_size": 10479
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": 176168960,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 48932352,
        "up_proj": 48932352,
        "down_proj": 48932352,
        "total": 146797056,
        "intermediate_size": 13653
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": 116226560,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 28951552,
        "up_proj": 28951552,
        "down_proj": 28951552,
        "total": 86854656,
        "intermediate_size": 8078
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": 223660544,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 64762880,
        "up_proj": 64762880,
        "down_proj": 64762880,
        "total": 194288640,
        "intermediate_size": 18070
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": 225359360,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 65329152,
        "up_proj": 65329152,
        "down_proj": 65329152,
        "total": 195987456,
        "intermediate_size": 18228
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": 224456192,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 65028096,
        "up_proj": 65028096,
        "down_proj": 65028096,
        "total": 195084288,
        "intermediate_size": 18144
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": 219994112,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 63540736,
        "up_proj": 63540736,
        "down_proj": 63540736,
        "total": 190622208,
        "intermediate_size": 17729
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": 219811328,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 63479808,
        "up_proj": 63479808,
        "down_proj": 63479808,
        "total": 190439424,
        "intermediate_size": 17712
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": 217671680,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 62766592,
        "up_proj": 62766592,
        "down_proj": 62766592,
        "total": 188299776,
        "intermediate_size": 17513
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": 205941248,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58856448,
        "up_proj": 58856448,
        "down_proj": 58856448,
        "total": 176569344,
        "intermediate_size": 16422
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": 199920128,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56849408,
        "up_proj": 56849408,
        "down_proj": 56849408,
        "total": 170548224,
        "intermediate_size": 15862
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": 203156480,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 57928192,
        "up_proj": 57928192,
        "down_proj": 57928192,
        "total": 173784576,
        "intermediate_size": 16163
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": 198092288,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56240128,
        "up_proj": 56240128,
        "down_proj": 56240128,
        "total": 168720384,
        "intermediate_size": 15692
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": 196597760,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 55741952,
        "up_proj": 55741952,
        "down_proj": 55741952,
        "total": 167225856,
        "intermediate_size": 15553
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": 171954176,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 47527424,
        "up_proj": 47527424,
        "down_proj": 47527424,
        "total": 142582272,
        "intermediate_size": 13261
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": 156234752,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 42287616,
        "up_proj": 42287616,
        "down_proj": 42287616,
        "total": 126862848,
        "intermediate_size": 11799
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": 166621184,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 45749760,
        "up_proj": 45749760,
        "down_proj": 45749760,
        "total": 137249280,
        "intermediate_size": 12765
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": 164438528,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 45022208,
        "up_proj": 45022208,
        "down_proj": 45022208,
        "total": 135066624,
        "intermediate_size": 12562
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": 157933568,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 42853888,
        "up_proj": 42853888,
        "down_proj": 42853888,
        "total": 128561664,
        "intermediate_size": 11957
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": 168803840,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 46477312,
        "up_proj": 46477312,
        "down_proj": 46477312,
        "total": 139431936,
        "intermediate_size": 12968
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": 163040768,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 44556288,
        "up_proj": 44556288,
        "down_proj": 44556288,
        "total": 133668864,
        "intermediate_size": 12432
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": 167010688,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 9636480,
        "k_proj": 1376640,
        "v_proj": 1376640,
        "o_proj": 9633792,
        "total": 22023552,
        "num_heads": 21,
        "num_kv_heads": 3
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 48326656,
        "up_proj": 48326656,
        "down_proj": 48326656,
        "total": 144979968,
        "intermediate_size": 13484
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": 179846144,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 50158080,
        "up_proj": 50158080,
        "down_proj": 50158080,
        "total": 150474240,
        "intermediate_size": 13995
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": 192770048,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 54466048,
        "up_proj": 54466048,
        "down_proj": 54466048,
        "total": 163398144,
        "intermediate_size": 15197
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": 223445504,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 64691200,
        "up_proj": 64691200,
        "down_proj": 64691200,
        "total": 194073600,
        "intermediate_size": 18050
      },
      "norm": 7168,
      "is_zero_layer": false
    }
  ],
  "layer_summary": {
    "num_layers": 28,
    "total_layer_params": 5002503040
  }
}