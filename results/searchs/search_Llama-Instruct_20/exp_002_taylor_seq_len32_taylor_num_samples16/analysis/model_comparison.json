{
  "original_name": "原始模型",
  "pruned_name": "剪枝后模型",
  "total_params": {
    "original": 8030261248,
    "pruned": 6424215552,
    "reduced": 1606045696,
    "reduction_ratio": 0.19999918388707447
  },
  "layer_params": {
    "original": 6979584000,
    "pruned": 5373538304,
    "reduced": 1606045696,
    "reduction_ratio": 0.23010622065727698
  },
  "layers": [
    {
      "layer_idx": 0,
      "total": {
        "original": 218112000,
        "pruned": 196390912,
        "reduced": 21721088,
        "reduction_ratio": 0.0995868544600939
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175411200,
        "reduced": 749568,
        "reduction_ratio": 0.004255022321428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14275
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": {
        "original": 218112000,
        "pruned": 217681920,
        "reduced": 430080,
        "reduction_ratio": 0.001971830985915493
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175730688,
        "reduced": 430080,
        "reduction_ratio": 0.00244140625,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14301
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": {
        "original": 218112000,
        "pruned": 207368192,
        "reduced": 10743808,
        "reduction_ratio": 0.049258215962441315
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175902720,
        "reduced": 258048,
        "reduction_ratio": 0.00146484375,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14315
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": {
        "original": 218112000,
        "pruned": 217718784,
        "reduced": 393216,
        "reduction_ratio": 0.0018028169014084508
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175767552,
        "reduced": 393216,
        "reduction_ratio": 0.002232142857142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14304
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": {
        "original": 218112000,
        "pruned": 215900160,
        "reduced": 2211840,
        "reduction_ratio": 0.010140845070422535
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173948928,
        "reduced": 2211840,
        "reduction_ratio": 0.012555803571428572,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14156
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": {
        "original": 218112000,
        "pruned": 200769536,
        "reduced": 17342464,
        "reduction_ratio": 0.07951173708920188
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 169304064,
        "reduced": 6856704,
        "reduction_ratio": 0.03892299107142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13778
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": {
        "original": 218112000,
        "pruned": 193720320,
        "reduced": 24391680,
        "reduction_ratio": 0.11183098591549295
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 151769088,
        "reduced": 24391680,
        "reduction_ratio": 0.13846261160714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12351
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": {
        "original": 218112000,
        "pruned": 160473088,
        "reduced": 57638912,
        "reduction_ratio": 0.2642629107981221
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 123764736,
        "reduced": 52396032,
        "reduction_ratio": 0.2974330357142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10072
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": {
        "original": 218112000,
        "pruned": 131674112,
        "reduced": 86437888,
        "reduction_ratio": 0.39630046948356806
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 100208640,
        "reduced": 75952128,
        "reduction_ratio": 0.43115234375,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8155
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": {
        "original": 218112000,
        "pruned": 127410176,
        "reduced": 90701824,
        "reduction_ratio": 0.415849765258216
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 95944704,
        "reduced": 80216064,
        "reduction_ratio": 0.45535714285714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7808
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": {
        "original": 218112000,
        "pruned": 106233856,
        "reduced": 111878144,
        "reduction_ratio": 0.5129389671361503
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 85254144,
        "reduced": 90906624,
        "reduction_ratio": 0.5160435267857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6938
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": {
        "original": 218112000,
        "pruned": 121049088,
        "reduced": 97062912,
        "reduction_ratio": 0.4450140845070423
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 79097856,
        "reduced": 97062912,
        "reduction_ratio": 0.5509905133928571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6437
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": {
        "original": 218112000,
        "pruned": 123617280,
        "reduced": 94494720,
        "reduction_ratio": 0.4332394366197183
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 81666048,
        "reduced": 94494720,
        "reduction_ratio": 0.5364118303571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6646
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": {
        "original": 218112000,
        "pruned": 123461632,
        "reduced": 94650368,
        "reduction_ratio": 0.4339530516431925
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 86753280,
        "reduced": 89407488,
        "reduction_ratio": 0.5075334821428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7060
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": {
        "original": 218112000,
        "pruned": 140144640,
        "reduced": 77967360,
        "reduction_ratio": 0.35746478873239435
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 98193408,
        "reduced": 77967360,
        "reduction_ratio": 0.44259207589285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7991
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": {
        "original": 218112000,
        "pruned": 156454912,
        "reduced": 61657088,
        "reduction_ratio": 0.28268544600938966
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 119746560,
        "reduced": 56414208,
        "reduction_ratio": 0.3202427455357143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9745
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": {
        "original": 218112000,
        "pruned": 168988672,
        "reduced": 49123328,
        "reduction_ratio": 0.2252206572769953
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 132280320,
        "reduced": 43880448,
        "reduction_ratio": 0.24909319196428573,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10765
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": {
        "original": 218112000,
        "pruned": 183857152,
        "reduced": 34254848,
        "reduction_ratio": 0.15705164319248827
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 147148800,
        "reduced": 29011968,
        "reduction_ratio": 0.16469029017857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11975
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": {
        "original": 218112000,
        "pruned": 173277184,
        "reduced": 44834816,
        "reduction_ratio": 0.2055586854460094
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 152297472,
        "reduced": 23863296,
        "reduction_ratio": 0.13546316964285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12394
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": {
        "original": 218112000,
        "pruned": 171958272,
        "reduced": 46153728,
        "reduction_ratio": 0.2116056338028169
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 161464320,
        "reduced": 14696448,
        "reduction_ratio": 0.08342633928571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13140
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": {
        "original": 218112000,
        "pruned": 176087040,
        "reduced": 42024960,
        "reduction_ratio": 0.19267605633802817
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 165593088,
        "reduced": 10567680,
        "reduction_ratio": 0.05998883928571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13476
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": {
        "original": 218112000,
        "pruned": 185126912,
        "reduced": 32985088,
        "reduction_ratio": 0.15123004694835682
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 169390080,
        "reduced": 6770688,
        "reduction_ratio": 0.03843470982142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13785
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": {
        "original": 218112000,
        "pruned": 189767680,
        "reduced": 28344320,
        "reduction_ratio": 0.12995305164319249
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 168787968,
        "reduced": 7372800,
        "reduction_ratio": 0.04185267857142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13736
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": {
        "original": 218112000,
        "pruned": 168452096,
        "reduced": 49659904,
        "reduction_ratio": 0.22768075117370892
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 168443904,
        "reduced": 7716864,
        "reduction_ratio": 0.04380580357142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13708
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": {
        "original": 218112000,
        "pruned": 182534144,
        "reduced": 35577856,
        "reduction_ratio": 0.16311737089201878
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 166797312,
        "reduced": 9363456,
        "reduction_ratio": 0.05315290178571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13574
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": {
        "original": 218112000,
        "pruned": 171298816,
        "reduced": 46813184,
        "reduction_ratio": 0.21462910798122065
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 166047744,
        "reduced": 10113024,
        "reduction_ratio": 0.057407924107142856,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13513
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": {
        "original": 218112000,
        "pruned": 162865152,
        "reduced": 55246848,
        "reduction_ratio": 0.25329577464788733
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 152371200,
        "reduced": 23789568,
        "reduction_ratio": 0.13504464285714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12400
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": {
        "original": 218112000,
        "pruned": 162664448,
        "reduced": 55447552,
        "reduction_ratio": 0.25421596244131456
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 146927616,
        "reduced": 29233152,
        "reduction_ratio": 0.16594587053571427,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11957
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": {
        "original": 218112000,
        "pruned": 161009664,
        "reduced": 57102336,
        "reduction_ratio": 0.26180281690140844
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 134787072,
        "reduced": 41373696,
        "reduction_ratio": 0.23486328125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10969
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": {
        "original": 218112000,
        "pruned": 148492288,
        "reduced": 69619712,
        "reduction_ratio": 0.3191924882629108
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 127512576,
        "reduced": 48648192,
        "reduction_ratio": 0.27615792410714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10377
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": {
        "original": 218112000,
        "pruned": 141332480,
        "reduced": 76779520,
        "reduction_ratio": 0.352018779342723
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 125595648,
        "reduced": 50565120,
        "reduction_ratio": 0.2870396205357143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10221
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": {
        "original": 218112000,
        "pruned": 185757696,
        "reduced": 32354304,
        "reduction_ratio": 0.1483380281690141
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 143806464,
        "reduced": 32354304,
        "reduction_ratio": 0.18366350446428573,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11703
        }
      },
      "is_zero_layer": false
    }
  ]
}