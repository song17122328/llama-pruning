{
  "original_name": "原始模型",
  "pruned_name": "剪枝后模型",
  "total_params": {
    "original": 7248023552,
    "pruned": 5798428672,
    "reduced": 1449594880,
    "reduction_ratio": 0.19999864371301646
  },
  "layer_params": {
    "original": 6979584000,
    "pruned": 5529989120,
    "reduced": 1449594880,
    "reduction_ratio": 0.2076907276995305
  },
  "layers": [
    {
      "layer_idx": 0,
      "total": {
        "original": 218112000,
        "pruned": 208371712,
        "reduced": 9740288,
        "reduction_ratio": 0.04465727699530517
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 171663360,
        "reduced": 4497408,
        "reduction_ratio": 0.025530133928571428,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13970
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": {
        "original": 218112000,
        "pruned": 218112000,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176160768,
        "reduced": 0,
        "reduction_ratio": 0.0,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14336
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": {
        "original": 218112000,
        "pruned": 192458752,
        "reduced": 25653248,
        "reduction_ratio": 0.1176150234741784
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 155750400,
        "reduced": 20410368,
        "reduction_ratio": 0.11586216517857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12675
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": {
        "original": 218112000,
        "pruned": 205410304,
        "reduced": 12701696,
        "reduction_ratio": 0.05823474178403756
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 168701952,
        "reduced": 7458816,
        "reduction_ratio": 0.04234095982142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13729
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": {
        "original": 218112000,
        "pruned": 203014144,
        "reduced": 15097856,
        "reduction_ratio": 0.0692206572769953
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 166305792,
        "reduced": 9854976,
        "reduction_ratio": 0.055943080357142856,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13534
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": {
        "original": 218112000,
        "pruned": 209104896,
        "reduced": 9007104,
        "reduction_ratio": 0.04129577464788732
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 167153664,
        "reduced": 9007104,
        "reduction_ratio": 0.05113002232142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13603
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": {
        "original": 218112000,
        "pruned": 181637120,
        "reduced": 36474880,
        "reduction_ratio": 0.1672300469483568
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 150171648,
        "reduced": 25989120,
        "reduction_ratio": 0.14753069196428573,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12221
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": {
        "original": 218112000,
        "pruned": 179027968,
        "reduced": 39084032,
        "reduction_ratio": 0.1791924882629108
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 142319616,
        "reduced": 33841152,
        "reduction_ratio": 0.19210379464285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11582
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": {
        "original": 218112000,
        "pruned": 179564544,
        "reduced": 38547456,
        "reduction_ratio": 0.17673239436619717
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 137613312,
        "reduced": 38547456,
        "reduction_ratio": 0.21881975446428573,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11199
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": {
        "original": 218112000,
        "pruned": 148459520,
        "reduced": 69652480,
        "reduction_ratio": 0.31934272300469485
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 116994048,
        "reduced": 59166720,
        "reduction_ratio": 0.3358677455357143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9521
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": {
        "original": 218112000,
        "pruned": 149348352,
        "reduced": 68763648,
        "reduction_ratio": 0.3152676056338028
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 107397120,
        "reduced": 68763648,
        "reduction_ratio": 0.39034598214285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8740
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": {
        "original": 218112000,
        "pruned": 122564608,
        "reduced": 95547392,
        "reduction_ratio": 0.4380657276995305
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 85856256,
        "reduced": 90304512,
        "reduction_ratio": 0.5126255580357143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6987
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": {
        "original": 218112000,
        "pruned": 122802176,
        "reduced": 95309824,
        "reduction_ratio": 0.43697652582159624
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 91336704,
        "reduced": 84824064,
        "reduction_ratio": 0.4815150669642857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7433
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": {
        "original": 218112000,
        "pruned": 131641344,
        "reduced": 86470656,
        "reduction_ratio": 0.3964507042253521
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 89690112,
        "reduced": 86470656,
        "reduction_ratio": 0.49086216517857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7299
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": {
        "original": 218112000,
        "pruned": 120848384,
        "reduced": 97263616,
        "reduction_ratio": 0.4459342723004695
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 89382912,
        "reduced": 86777856,
        "reduction_ratio": 0.4926060267857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7274
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": {
        "original": 218112000,
        "pruned": 129781760,
        "reduced": 88330240,
        "reduction_ratio": 0.40497652582159627
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 98316288,
        "reduced": 77844480,
        "reduction_ratio": 0.44189453125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8001
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": {
        "original": 218112000,
        "pruned": 151474176,
        "reduced": 66637824,
        "reduction_ratio": 0.30552112676056337
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 109522944,
        "reduced": 66637824,
        "reduction_ratio": 0.37827845982142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8913
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": {
        "original": 218112000,
        "pruned": 153272320,
        "reduced": 64839680,
        "reduction_ratio": 0.2972769953051643
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 116563968,
        "reduced": 59596800,
        "reduction_ratio": 0.3383091517857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9486
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": {
        "original": 218112000,
        "pruned": 171044864,
        "reduced": 47067136,
        "reduction_ratio": 0.21579342723004694
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 139579392,
        "reduced": 36581376,
        "reduction_ratio": 0.20765904017857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11359
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": {
        "original": 218112000,
        "pruned": 200151040,
        "reduced": 17960960,
        "reduction_ratio": 0.08234741784037558
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 163442688,
        "reduced": 12718080,
        "reduction_ratio": 0.07219587053571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13301
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": {
        "original": 218112000,
        "pruned": 188583936,
        "reduced": 29528064,
        "reduction_ratio": 0.13538028169014085
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 162361344,
        "reduced": 13799424,
        "reduction_ratio": 0.07833426339285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13213
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": {
        "original": 218112000,
        "pruned": 188383232,
        "reduced": 29728768,
        "reduction_ratio": 0.13630046948356808
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 156917760,
        "reduced": 19243008,
        "reduction_ratio": 0.10923549107142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12770
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": {
        "original": 218112000,
        "pruned": 174772224,
        "reduced": 43339776,
        "reduction_ratio": 0.19870422535211268
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 164278272,
        "reduced": 11882496,
        "reduction_ratio": 0.06745256696428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13369
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": {
        "original": 218112000,
        "pruned": 195313664,
        "reduced": 22798336,
        "reduction_ratio": 0.10452582159624413
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 163848192,
        "reduced": 12312576,
        "reduction_ratio": 0.06989397321428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13334
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": {
        "original": 218112000,
        "pruned": 170647552,
        "reduced": 47464448,
        "reduction_ratio": 0.2176150234741784
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 165396480,
        "reduced": 10764288,
        "reduction_ratio": 0.06110491071428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13460
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": {
        "original": 218112000,
        "pruned": 178249728,
        "reduced": 39862272,
        "reduction_ratio": 0.18276056338028168
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 167755776,
        "reduced": 8404992,
        "reduction_ratio": 0.04771205357142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13652
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": {
        "original": 218112000,
        "pruned": 173592576,
        "reduced": 44519424,
        "reduction_ratio": 0.20411267605633804
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 163098624,
        "reduced": 13062144,
        "reduction_ratio": 0.07414899553571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13273
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": {
        "original": 218112000,
        "pruned": 189112320,
        "reduced": 28999680,
        "reduction_ratio": 0.13295774647887323
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 162889728,
        "reduced": 13271040,
        "reduction_ratio": 0.07533482142857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13256
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": {
        "original": 218112000,
        "pruned": 165670912,
        "reduced": 52441088,
        "reduction_ratio": 0.2404319248826291
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 160419840,
        "reduced": 15740928,
        "reduction_ratio": 0.08935546875,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13055
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": {
        "original": 218112000,
        "pruned": 185925632,
        "reduced": 32186368,
        "reduction_ratio": 0.14756807511737088
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 154460160,
        "reduced": 21700608,
        "reduction_ratio": 0.12318638392857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12570
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": {
        "original": 218112000,
        "pruned": 157421568,
        "reduced": 60690432,
        "reduction_ratio": 0.27825352112676055
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 146927616,
        "reduced": 29233152,
        "reduction_ratio": 0.16594587053571427,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11957
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": {
        "original": 218112000,
        "pruned": 184225792,
        "reduced": 33886208,
        "reduction_ratio": 0.15536150234741783
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 147517440,
        "reduced": 28643328,
        "reduction_ratio": 0.16259765625,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12005
        }
      },
      "is_zero_layer": false
    }
  ]
}