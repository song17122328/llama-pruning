{
  "original_name": "原始模型",
  "pruned_name": "剪枝后模型",
  "total_params": {
    "original": 8030261248,
    "pruned": 6424215552,
    "reduced": 1606045696,
    "reduction_ratio": 0.19999918388707447
  },
  "layer_params": {
    "original": 6979584000,
    "pruned": 5373538304,
    "reduced": 1606045696,
    "reduction_ratio": 0.23010622065727698
  },
  "layers": [
    {
      "layer_idx": 0,
      "total": {
        "original": 218112000,
        "pruned": 207626240,
        "reduced": 10485760,
        "reduction_ratio": 0.04807511737089202
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176160768,
        "reduced": 0,
        "reduction_ratio": 0.0,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14336
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": {
        "original": 218112000,
        "pruned": 218013696,
        "reduced": 98304,
        "reduction_ratio": 0.0004507042253521127
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176062464,
        "reduced": 98304,
        "reduction_ratio": 0.0005580357142857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14328
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": {
        "original": 218112000,
        "pruned": 207515648,
        "reduced": 10596352,
        "reduction_ratio": 0.048582159624413146
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176050176,
        "reduced": 110592,
        "reduction_ratio": 0.0006277901785714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14327
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": {
        "original": 218112000,
        "pruned": 217878528,
        "reduced": 233472,
        "reduction_ratio": 0.0010704225352112676
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175927296,
        "reduced": 233472,
        "reduction_ratio": 0.0013253348214285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14317
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": {
        "original": 218112000,
        "pruned": 217030656,
        "reduced": 1081344,
        "reduction_ratio": 0.0049577464788732395
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175079424,
        "reduced": 1081344,
        "reduction_ratio": 0.006138392857142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14248
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": {
        "original": 218112000,
        "pruned": 194560000,
        "reduced": 23552000,
        "reduction_ratio": 0.107981220657277
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173580288,
        "reduced": 2580480,
        "reduction_ratio": 0.0146484375,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14126
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": {
        "original": 218112000,
        "pruned": 197132288,
        "reduced": 20979712,
        "reduction_ratio": 0.09618779342723005
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 165666816,
        "reduced": 10493952,
        "reduction_ratio": 0.0595703125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13482
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": {
        "original": 218112000,
        "pruned": 174125056,
        "reduced": 43986944,
        "reduction_ratio": 0.2016713615023474
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 137416704,
        "reduced": 38744064,
        "reduction_ratio": 0.21993582589285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11183
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": {
        "original": 218112000,
        "pruned": 146149376,
        "reduced": 71962624,
        "reduction_ratio": 0.3299342723004695
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 114683904,
        "reduced": 61476864,
        "reduction_ratio": 0.34898158482142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9333
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": {
        "original": 218112000,
        "pruned": 133787648,
        "reduced": 84324352,
        "reduction_ratio": 0.38661032863849765
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 102322176,
        "reduced": 73838592,
        "reduction_ratio": 0.41915457589285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8327
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": {
        "original": 218112000,
        "pruned": 115666944,
        "reduced": 102445056,
        "reduction_ratio": 0.46969014084507044
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 89444352,
        "reduced": 86716416,
        "reduction_ratio": 0.4922572544642857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7279
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": {
        "original": 218112000,
        "pruned": 119308288,
        "reduced": 98803712,
        "reduction_ratio": 0.45299530516431924
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 82599936,
        "reduced": 93560832,
        "reduction_ratio": 0.5311104910714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6722
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": {
        "original": 218112000,
        "pruned": 119492608,
        "reduced": 98619392,
        "reduction_ratio": 0.45215023474178406
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 82784256,
        "reduced": 93376512,
        "reduction_ratio": 0.5300641741071429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6737
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": {
        "original": 218112000,
        "pruned": 115171328,
        "reduced": 102940672,
        "reduction_ratio": 0.471962441314554
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 83705856,
        "reduced": 92454912,
        "reduction_ratio": 0.5248325892857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6812
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": {
        "original": 218112000,
        "pruned": 119058432,
        "reduced": 99053568,
        "reduction_ratio": 0.4541408450704225
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 92835840,
        "reduced": 83324928,
        "reduction_ratio": 0.47300502232142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7555
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": {
        "original": 218112000,
        "pruned": 142942208,
        "reduced": 75169792,
        "reduction_ratio": 0.34463849765258214
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 111476736,
        "reduced": 64684032,
        "reduction_ratio": 0.3671875,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9072
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": {
        "original": 218112000,
        "pruned": 152178688,
        "reduced": 65933312,
        "reduction_ratio": 0.3022910798122066
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 115470336,
        "reduced": 60690432,
        "reduction_ratio": 0.34451729910714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9397
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": {
        "original": 218112000,
        "pruned": 157396992,
        "reduced": 60715008,
        "reduction_ratio": 0.2783661971830986
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 131174400,
        "reduced": 44986368,
        "reduction_ratio": 0.25537109375,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10675
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": {
        "original": 218112000,
        "pruned": 155475968,
        "reduced": 62636032,
        "reduction_ratio": 0.2871737089201878
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 139739136,
        "reduced": 36421632,
        "reduction_ratio": 0.20675223214285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11372
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": {
        "original": 218112000,
        "pruned": 162582528,
        "reduced": 55529472,
        "reduction_ratio": 0.25459154929577466
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 152088576,
        "reduced": 24072192,
        "reduction_ratio": 0.13664899553571427,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12377
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": {
        "original": 218112000,
        "pruned": 171171840,
        "reduced": 46940160,
        "reduction_ratio": 0.2152112676056338
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 160677888,
        "reduced": 15482880,
        "reduction_ratio": 0.087890625,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13076
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": {
        "original": 218112000,
        "pruned": 194899968,
        "reduced": 23212032,
        "reduction_ratio": 0.1064225352112676
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 168677376,
        "reduced": 7483392,
        "reduction_ratio": 0.04248046875,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13727
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": {
        "original": 218112000,
        "pruned": 182964224,
        "reduced": 35147776,
        "reduction_ratio": 0.16114553990610328
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 167227392,
        "reduced": 8933376,
        "reduction_ratio": 0.05071149553571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13609
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": {
        "original": 218112000,
        "pruned": 170795008,
        "reduced": 47316992,
        "reduction_ratio": 0.21693896713615024
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 165543936,
        "reduced": 10616832,
        "reduction_ratio": 0.060267857142857144,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13472
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": {
        "original": 218112000,
        "pruned": 168779776,
        "reduced": 49332224,
        "reduction_ratio": 0.22617840375586853
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 163528704,
        "reduced": 12632064,
        "reduction_ratio": 0.07170758928571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13308
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": {
        "original": 218112000,
        "pruned": 172965888,
        "reduced": 45146112,
        "reduction_ratio": 0.20698591549295775
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 162471936,
        "reduced": 13688832,
        "reduction_ratio": 0.07770647321428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13222
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": {
        "original": 218112000,
        "pruned": 171388928,
        "reduced": 46723072,
        "reduction_ratio": 0.21421596244131455
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 155652096,
        "reduced": 20508672,
        "reduction_ratio": 0.11642020089285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12667
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": {
        "original": 218112000,
        "pruned": 172122112,
        "reduced": 45989888,
        "reduction_ratio": 0.21085446009389672
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 151142400,
        "reduced": 25018368,
        "reduction_ratio": 0.14202008928571427,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12300
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": {
        "original": 218112000,
        "pruned": 150331392,
        "reduced": 67780608,
        "reduction_ratio": 0.3107605633802817
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 139837440,
        "reduced": 36323328,
        "reduction_ratio": 0.20619419642857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11380
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": {
        "original": 218112000,
        "pruned": 160026624,
        "reduced": 58085376,
        "reduction_ratio": 0.26630985915492955
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 133804032,
        "reduced": 42356736,
        "reduction_ratio": 0.24044363839285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10889
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": {
        "original": 218112000,
        "pruned": 171372544,
        "reduced": 46739456,
        "reduction_ratio": 0.21429107981220658
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 150392832,
        "reduced": 25767936,
        "reduction_ratio": 0.14627511160714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12239
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": {
        "original": 218112000,
        "pruned": 213626880,
        "reduced": 4485120,
        "reduction_ratio": 0.02056338028169014
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 171675648,
        "reduced": 4485120,
        "reduction_ratio": 0.025460379464285716,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13971
        }
      },
      "is_zero_layer": false
    }
  ]
}