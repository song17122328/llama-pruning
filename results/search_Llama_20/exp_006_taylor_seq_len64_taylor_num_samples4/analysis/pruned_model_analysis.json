{
  "model_name": "剪枝后模型",
  "total_params": 6424215552,
  "embedding_params": 525336576,
  "lm_head_params": 525336576,
  "layers": [
    {
      "layer_idx": 0,
      "total": 201658368,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 10485760,
        "k_proj": 2621440,
        "v_proj": 2621440,
        "o_proj": 10485760,
        "total": 26214400,
        "num_heads": 20,
        "num_kv_heads": 5
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58478592,
        "up_proj": 58478592,
        "down_proj": 58478592,
        "total": 175435776,
        "intermediate_size": 14277
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": 217853952,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58634240,
        "up_proj": 58634240,
        "down_proj": 58634240,
        "total": 175902720,
        "intermediate_size": 14315
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": 207441920,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58658816,
        "up_proj": 58658816,
        "down_proj": 58658816,
        "total": 175976448,
        "intermediate_size": 14321
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": 217792512,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58613760,
        "up_proj": 58613760,
        "down_proj": 58613760,
        "total": 175841280,
        "intermediate_size": 14310
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": 216158208,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58068992,
        "up_proj": 58068992,
        "down_proj": 58068992,
        "total": 174206976,
        "intermediate_size": 14177
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": 202833920,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 57122816,
        "up_proj": 57122816,
        "down_proj": 57122816,
        "total": 171368448,
        "intermediate_size": 13946
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": 192352256,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 53628928,
        "up_proj": 53628928,
        "down_proj": 53628928,
        "total": 160886784,
        "intermediate_size": 13093
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": 174002176,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 45764608,
        "up_proj": 45764608,
        "down_proj": 45764608,
        "total": 137293824,
        "intermediate_size": 11173
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": 145018880,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 37851136,
        "up_proj": 37851136,
        "down_proj": 37851136,
        "total": 113553408,
        "intermediate_size": 9241
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": 141795328,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 35028992,
        "up_proj": 35028992,
        "down_proj": 35028992,
        "total": 105086976,
        "intermediate_size": 8552
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": 124190720,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 30908416,
        "up_proj": 30908416,
        "down_proj": 30908416,
        "total": 92725248,
        "intermediate_size": 7546
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": 118841344,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 27377664,
        "up_proj": 27377664,
        "down_proj": 27377664,
        "total": 82132992,
        "intermediate_size": 6684
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": 118407168,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 25485312,
        "up_proj": 25485312,
        "down_proj": 25485312,
        "total": 76455936,
        "intermediate_size": 6222
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": 111939584,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 26824704,
        "up_proj": 26824704,
        "down_proj": 26824704,
        "total": 80474112,
        "intermediate_size": 6549
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": 135929856,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 31326208,
        "up_proj": 31326208,
        "down_proj": 31326208,
        "total": 93978624,
        "intermediate_size": 7648
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": 140685312,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 10485760,
        "k_proj": 2621440,
        "v_proj": 2621440,
        "o_proj": 10485760,
        "total": 26214400,
        "num_heads": 20,
        "num_kv_heads": 5
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 38154240,
        "up_proj": 38154240,
        "down_proj": 38154240,
        "total": 114462720,
        "intermediate_size": 9315
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": 165388288,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 42893312,
        "up_proj": 42893312,
        "down_proj": 42893312,
        "total": 128679936,
        "intermediate_size": 10472
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": 179728384,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 47673344,
        "up_proj": 47673344,
        "down_proj": 47673344,
        "total": 143020032,
        "intermediate_size": 11639
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": 174850048,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 8388608,
        "k_proj": 2097152,
        "v_proj": 2097152,
        "o_proj": 8388608,
        "total": 20971520,
        "num_heads": 16,
        "num_kv_heads": 4
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 51290112,
        "up_proj": 51290112,
        "down_proj": 51290112,
        "total": 153870336,
        "intermediate_size": 12522
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": 173641728,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 4194304,
        "k_proj": 1048576,
        "v_proj": 1048576,
        "o_proj": 4194304,
        "total": 10485760,
        "num_heads": 8,
        "num_kv_heads": 2
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 54382592,
        "up_proj": 54382592,
        "down_proj": 54382592,
        "total": 163147776,
        "intermediate_size": 13277
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": 177401856,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 4194304,
        "k_proj": 1048576,
        "v_proj": 1048576,
        "o_proj": 4194304,
        "total": 10485760,
        "num_heads": 8,
        "num_kv_heads": 2
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 55635968,
        "up_proj": 55635968,
        "down_proj": 55635968,
        "total": 166907904,
        "intermediate_size": 13583
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": 191684608,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 8388608,
        "k_proj": 2097152,
        "v_proj": 2097152,
        "o_proj": 8388608,
        "total": 20971520,
        "num_heads": 16,
        "num_kv_heads": 4
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56901632,
        "up_proj": 56901632,
        "down_proj": 56901632,
        "total": 170704896,
        "intermediate_size": 13892
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": 179810304,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 4194304,
        "k_proj": 1048576,
        "v_proj": 1048576,
        "o_proj": 4194304,
        "total": 10485760,
        "num_heads": 8,
        "num_kv_heads": 2
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56438784,
        "up_proj": 56438784,
        "down_proj": 56438784,
        "total": 169316352,
        "intermediate_size": 13779
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": 173940736,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 2097152,
        "k_proj": 524288,
        "v_proj": 524288,
        "o_proj": 2097152,
        "total": 5242880,
        "num_heads": 4,
        "num_kv_heads": 1
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56229888,
        "up_proj": 56229888,
        "down_proj": 56229888,
        "total": 168689664,
        "intermediate_size": 13728
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": 182177792,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 6291456,
        "k_proj": 1572864,
        "v_proj": 1572864,
        "o_proj": 6291456,
        "total": 15728640,
        "num_heads": 12,
        "num_kv_heads": 3
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 55480320,
        "up_proj": 55480320,
        "down_proj": 55480320,
        "total": 166440960,
        "intermediate_size": 13545
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": 169762816,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 2097152,
        "k_proj": 524288,
        "v_proj": 524288,
        "o_proj": 2097152,
        "total": 5242880,
        "num_heads": 4,
        "num_kv_heads": 1
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 54837248,
        "up_proj": 54837248,
        "down_proj": 54837248,
        "total": 164511744,
        "intermediate_size": 13388
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": 166883328,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 4194304,
        "k_proj": 1048576,
        "v_proj": 1048576,
        "o_proj": 4194304,
        "total": 10485760,
        "num_heads": 8,
        "num_kv_heads": 2
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 52129792,
        "up_proj": 52129792,
        "down_proj": 52129792,
        "total": 156389376,
        "intermediate_size": 12727
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": 174256128,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 10485760,
        "k_proj": 2621440,
        "v_proj": 2621440,
        "o_proj": 10485760,
        "total": 26214400,
        "num_heads": 20,
        "num_kv_heads": 5
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 49344512,
        "up_proj": 49344512,
        "down_proj": 49344512,
        "total": 148033536,
        "intermediate_size": 12047
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": 160878592,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 8388608,
        "k_proj": 2097152,
        "v_proj": 2097152,
        "o_proj": 8388608,
        "total": 20971520,
        "num_heads": 16,
        "num_kv_heads": 4
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 46632960,
        "up_proj": 46632960,
        "down_proj": 46632960,
        "total": 139898880,
        "intermediate_size": 11385
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": 144781312,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 8388608,
        "k_proj": 2097152,
        "v_proj": 2097152,
        "o_proj": 8388608,
        "total": 20971520,
        "num_heads": 16,
        "num_kv_heads": 4
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 41267200,
        "up_proj": 41267200,
        "down_proj": 41267200,
        "total": 123801600,
        "intermediate_size": 10075
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": 130396160,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 6291456,
        "k_proj": 1572864,
        "v_proj": 1572864,
        "o_proj": 6291456,
        "total": 15728640,
        "num_heads": 12,
        "num_kv_heads": 3
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 38219776,
        "up_proj": 38219776,
        "down_proj": 38219776,
        "total": 114659328,
        "intermediate_size": 9331
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": 161054720,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 43196416,
        "up_proj": 43196416,
        "down_proj": 43196416,
        "total": 129589248,
        "intermediate_size": 10546
      },
      "norm": 8192,
      "is_zero_layer": false
    }
  ],
  "layer_summary": {
    "num_layers": 32,
    "total_layer_params": 5373538304
  }
}