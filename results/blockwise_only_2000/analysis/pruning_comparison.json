{
  "original_name": "Llama-3-8B-Instruct",
  "pruned_name": "blockwise_only_2000",
  "total_params": {
    "original": 8030261248,
    "pruned": 6424215552,
    "reduced": 1606045696,
    "reduction_ratio": 0.19999918388707447
  },
  "layer_params": {
    "original": 6979584000,
    "pruned": 5373538304,
    "reduced": 1606045696,
    "reduction_ratio": 0.23010622065727698
  },
  "layers": [
    {
      "layer_idx": 0,
      "total": {
        "original": 218112000,
        "pruned": 218112000,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176160768,
        "reduced": 0,
        "reduction_ratio": 0.0,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14336
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": {
        "original": 218112000,
        "pruned": 218112000,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176160768,
        "reduced": 0,
        "reduction_ratio": 0.0,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14336
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": {
        "original": 218112000,
        "pruned": 218099712,
        "reduced": 12288,
        "reduction_ratio": 5.6338028169014086e-05
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176148480,
        "reduced": 12288,
        "reduction_ratio": 6.975446428571428e-05,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14335
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": {
        "original": 218112000,
        "pruned": 217829376,
        "reduced": 282624,
        "reduction_ratio": 0.0012957746478873238
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175878144,
        "reduced": 282624,
        "reduction_ratio": 0.0016043526785714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14313
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": {
        "original": 218112000,
        "pruned": 217214976,
        "reduced": 897024,
        "reduction_ratio": 0.004112676056338028
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175263744,
        "reduced": 897024,
        "reduction_ratio": 0.005092075892857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14263
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": {
        "original": 218112000,
        "pruned": 214511616,
        "reduced": 3600384,
        "reduction_ratio": 0.016507042253521127
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 172560384,
        "reduced": 3600384,
        "reduction_ratio": 0.020438058035714284,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14043
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": {
        "original": 218112000,
        "pruned": 210604032,
        "reduced": 7507968,
        "reduction_ratio": 0.034422535211267605
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 168652800,
        "reduced": 7507968,
        "reduction_ratio": 0.04261997767857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13725
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": {
        "original": 218112000,
        "pruned": 200269824,
        "reduced": 17842176,
        "reduction_ratio": 0.08180281690140845
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 158318592,
        "reduced": 17842176,
        "reduction_ratio": 0.10128348214285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12884
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": {
        "original": 218112000,
        "pruned": 198266880,
        "reduced": 19845120,
        "reduction_ratio": 0.09098591549295774
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 156315648,
        "reduced": 19845120,
        "reduction_ratio": 0.11265345982142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12721
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": {
        "original": 218112000,
        "pruned": 199741440,
        "reduced": 18370560,
        "reduction_ratio": 0.08422535211267605
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 157790208,
        "reduced": 18370560,
        "reduction_ratio": 0.10428292410714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12841
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": {
        "original": 218112000,
        "pruned": 192270336,
        "reduced": 25841664,
        "reduction_ratio": 0.11847887323943662
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 150319104,
        "reduced": 25841664,
        "reduction_ratio": 0.14669363839285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12233
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": {
        "original": 218112000,
        "pruned": 192749568,
        "reduced": 25362432,
        "reduction_ratio": 0.11628169014084506
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 150798336,
        "reduced": 25362432,
        "reduction_ratio": 0.14397321428571427,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12272
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": {
        "original": 218112000,
        "pruned": 182415360,
        "reduced": 35696640,
        "reduction_ratio": 0.1636619718309859
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 140464128,
        "reduced": 35696640,
        "reduction_ratio": 0.20263671875,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11431
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": {
        "original": 218112000,
        "pruned": 176689152,
        "reduced": 41422848,
        "reduction_ratio": 0.18991549295774648
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 134737920,
        "reduced": 41422848,
        "reduction_ratio": 0.23514229910714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10965
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": {
        "original": 218112000,
        "pruned": 172597248,
        "reduced": 45514752,
        "reduction_ratio": 0.20867605633802816
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 130646016,
        "reduced": 45514752,
        "reduction_ratio": 0.2583705357142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10632
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": {
        "original": 218112000,
        "pruned": 176836608,
        "reduced": 41275392,
        "reduction_ratio": 0.18923943661971832
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 134885376,
        "reduced": 41275392,
        "reduction_ratio": 0.23430524553571427,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10977
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": {
        "original": 218112000,
        "pruned": 162717696,
        "reduced": 55394304,
        "reduction_ratio": 0.25397183098591547
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 120766464,
        "reduced": 55394304,
        "reduction_ratio": 0.314453125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9828
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": {
        "original": 218112000,
        "pruned": 163725312,
        "reduced": 54386688,
        "reduction_ratio": 0.24935211267605634
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 121774080,
        "reduced": 54386688,
        "reduction_ratio": 0.30873325892857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9910
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": {
        "original": 218112000,
        "pruned": 151994368,
        "reduced": 66117632,
        "reduction_ratio": 0.3031361502347418
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 115286016,
        "reduced": 60874752,
        "reduction_ratio": 0.34556361607142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9382
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": {
        "original": 218112000,
        "pruned": 152547328,
        "reduced": 65564672,
        "reduction_ratio": 0.30060093896713613
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 115838976,
        "reduced": 60321792,
        "reduction_ratio": 0.34242466517857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9427
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": {
        "original": 218112000,
        "pruned": 149250048,
        "reduced": 68861952,
        "reduction_ratio": 0.31571830985915494
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 123027456,
        "reduced": 53133312,
        "reduction_ratio": 0.30161830357142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10012
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": {
        "original": 218112000,
        "pruned": 157233152,
        "reduced": 60878848,
        "reduction_ratio": 0.27911737089201877
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 125767680,
        "reduced": 50393088,
        "reduction_ratio": 0.2860630580357143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10235
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": {
        "original": 218112000,
        "pruned": 142082048,
        "reduced": 76029952,
        "reduction_ratio": 0.34858215962441313
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 126345216,
        "reduced": 49815552,
        "reduction_ratio": 0.2827845982142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10282
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": {
        "original": 218112000,
        "pruned": 132366336,
        "reduced": 85745664,
        "reduction_ratio": 0.3931267605633803
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 121872384,
        "reduced": 54288384,
        "reduction_ratio": 0.3081752232142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9918
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": {
        "original": 218112000,
        "pruned": 154284032,
        "reduced": 63827968,
        "reduction_ratio": 0.29263849765258215
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 122818560,
        "reduced": 53342208,
        "reduction_ratio": 0.3028041294642857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9995
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": {
        "original": 218112000,
        "pruned": 124370944,
        "reduced": 93741056,
        "reduction_ratio": 0.42978403755868544
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 103391232,
        "reduced": 72769536,
        "reduction_ratio": 0.4130859375,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8414
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": {
        "original": 218112000,
        "pruned": 117112832,
        "reduced": 100999168,
        "reduction_ratio": 0.46306103286384975
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 85647360,
        "reduced": 90513408,
        "reduction_ratio": 0.5138113839285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6970
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": {
        "original": 218112000,
        "pruned": 113864704,
        "reduced": 104247296,
        "reduction_ratio": 0.47795305164319246
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 92884992,
        "reduced": 83275776,
        "reduction_ratio": 0.4727260044642857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7559
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": {
        "original": 218112000,
        "pruned": 119107584,
        "reduced": 99004416,
        "reduction_ratio": 0.45391549295774647
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 77156352,
        "reduced": 99004416,
        "reduction_ratio": 0.56201171875,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6279
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": {
        "original": 218112000,
        "pruned": 86728704,
        "reduced": 131383296,
        "reduction_ratio": 0.6023661971830986
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 60506112,
        "reduced": 115654656,
        "reduction_ratio": 0.6565290178571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 4924
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": {
        "original": 218112000,
        "pruned": 101957632,
        "reduced": 116154368,
        "reduction_ratio": 0.5325446009389672
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 65249280,
        "reduced": 110911488,
        "reduction_ratio": 0.6296037946428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 5310
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": {
        "original": 218112000,
        "pruned": 137875456,
        "reduced": 80236544,
        "reduction_ratio": 0.367868544600939
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 116895744,
        "reduced": 59265024,
        "reduction_ratio": 0.33642578125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9513
        }
      },
      "is_zero_layer": false
    }
  ]
}