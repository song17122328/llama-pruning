{
  "model_name": "剪枝后模型",
  "total_params": 6424219648,
  "embedding_params": 525336576,
  "lm_head_params": 525336576,
  "layers": [
    {
      "layer_idx": 0,
      "total": 207626240,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58720256,
        "up_proj": 58720256,
        "down_proj": 58720256,
        "total": 176160768,
        "intermediate_size": 14336
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": 218087424,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58712064,
        "up_proj": 58712064,
        "down_proj": 58712064,
        "total": 176136192,
        "intermediate_size": 14334
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": 207429632,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58654720,
        "up_proj": 58654720,
        "down_proj": 58654720,
        "total": 175964160,
        "intermediate_size": 14320
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": 217497600,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58515456,
        "up_proj": 58515456,
        "down_proj": 58515456,
        "total": 175546368,
        "intermediate_size": 14286
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": 214462464,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 57503744,
        "up_proj": 57503744,
        "down_proj": 57503744,
        "total": 172511232,
        "intermediate_size": 14039
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": 183619584,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 10485760,
        "k_proj": 2621440,
        "v_proj": 2621440,
        "o_proj": 10485760,
        "total": 26214400,
        "num_heads": 20,
        "num_kv_heads": 5
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 52465664,
        "up_proj": 52465664,
        "down_proj": 52465664,
        "total": 157396992,
        "intermediate_size": 12809
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": 152846336,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 40460288,
        "up_proj": 40460288,
        "down_proj": 40460288,
        "total": 121380864,
        "intermediate_size": 9878
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": 140480512,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 34590720,
        "up_proj": 34590720,
        "down_proj": 34590720,
        "total": 103772160,
        "intermediate_size": 8445
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": 114900992,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 27811840,
        "up_proj": 27811840,
        "down_proj": 27811840,
        "total": 83435520,
        "intermediate_size": 6790
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": 139493376,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 32514048,
        "up_proj": 32514048,
        "down_proj": 32514048,
        "total": 97542144,
        "intermediate_size": 7938
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": 120111104,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 29548544,
        "up_proj": 29548544,
        "down_proj": 29548544,
        "total": 88645632,
        "intermediate_size": 7214
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": 116133888,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 24727552,
        "up_proj": 24727552,
        "down_proj": 24727552,
        "total": 74182656,
        "intermediate_size": 6037
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": 112091136,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 23379968,
        "up_proj": 23379968,
        "down_proj": 23379968,
        "total": 70139904,
        "intermediate_size": 5708
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": 116469760,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 26587136,
        "up_proj": 26587136,
        "down_proj": 26587136,
        "total": 79761408,
        "intermediate_size": 6491
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": 128851968,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 28966912,
        "up_proj": 28966912,
        "down_proj": 28966912,
        "total": 86900736,
        "intermediate_size": 7072
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": 166453248,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 41500672,
        "up_proj": 41500672,
        "down_proj": 41500672,
        "total": 124502016,
        "intermediate_size": 10132
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": 168325120,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 43872256,
        "up_proj": 43872256,
        "down_proj": 43872256,
        "total": 131616768,
        "intermediate_size": 10711
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": 182554624,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 48615424,
        "up_proj": 48615424,
        "down_proj": 48615424,
        "total": 145846272,
        "intermediate_size": 11869
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": 169025536,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 8388608,
        "k_proj": 2097152,
        "v_proj": 2097152,
        "o_proj": 8388608,
        "total": 20971520,
        "num_heads": 16,
        "num_kv_heads": 4
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 49348608,
        "up_proj": 49348608,
        "down_proj": 49348608,
        "total": 148045824,
        "intermediate_size": 12048
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": 177717248,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 6291456,
        "k_proj": 1572864,
        "v_proj": 1572864,
        "o_proj": 6291456,
        "total": 15728640,
        "num_heads": 12,
        "num_kv_heads": 3
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 53993472,
        "up_proj": 53993472,
        "down_proj": 53993472,
        "total": 161980416,
        "intermediate_size": 13182
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": 182165504,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 6291456,
        "k_proj": 1572864,
        "v_proj": 1572864,
        "o_proj": 6291456,
        "total": 15728640,
        "num_heads": 12,
        "num_kv_heads": 3
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 55476224,
        "up_proj": 55476224,
        "down_proj": 55476224,
        "total": 166428672,
        "intermediate_size": 13544
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": 180166656,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 4194304,
        "k_proj": 1048576,
        "v_proj": 1048576,
        "o_proj": 4194304,
        "total": 10485760,
        "num_heads": 8,
        "num_kv_heads": 2
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56557568,
        "up_proj": 56557568,
        "down_proj": 56557568,
        "total": 169672704,
        "intermediate_size": 13808
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": 179871744,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 4194304,
        "k_proj": 1048576,
        "v_proj": 1048576,
        "o_proj": 4194304,
        "total": 10485760,
        "num_heads": 8,
        "num_kv_heads": 2
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56459264,
        "up_proj": 56459264,
        "down_proj": 56459264,
        "total": 169377792,
        "intermediate_size": 13784
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": 179183616,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 4194304,
        "k_proj": 1048576,
        "v_proj": 1048576,
        "o_proj": 4194304,
        "total": 10485760,
        "num_heads": 8,
        "num_kv_heads": 2
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56229888,
        "up_proj": 56229888,
        "down_proj": 56229888,
        "total": 168689664,
        "intermediate_size": 13728
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": 184315904,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 6291456,
        "k_proj": 1572864,
        "v_proj": 1572864,
        "o_proj": 6291456,
        "total": 15728640,
        "num_heads": 12,
        "num_kv_heads": 3
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56193024,
        "up_proj": 56193024,
        "down_proj": 56193024,
        "total": 168579072,
        "intermediate_size": 13719
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": 187457536,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 8388608,
        "k_proj": 2097152,
        "v_proj": 2097152,
        "o_proj": 8388608,
        "total": 20971520,
        "num_heads": 16,
        "num_kv_heads": 4
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 55492608,
        "up_proj": 55492608,
        "down_proj": 55492608,
        "total": 166477824,
        "intermediate_size": 13548
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": 167313408,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 4194304,
        "k_proj": 1048576,
        "v_proj": 1048576,
        "o_proj": 4194304,
        "total": 10485760,
        "num_heads": 8,
        "num_kv_heads": 2
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 52273152,
        "up_proj": 52273152,
        "down_proj": 52273152,
        "total": 156819456,
        "intermediate_size": 12762
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": 177983488,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 8388608,
        "k_proj": 2097152,
        "v_proj": 2097152,
        "o_proj": 8388608,
        "total": 20971520,
        "num_heads": 16,
        "num_kv_heads": 4
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 52334592,
        "up_proj": 52334592,
        "down_proj": 52334592,
        "total": 157003776,
        "intermediate_size": 12777
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": 168407040,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 10485760,
        "k_proj": 2621440,
        "v_proj": 2621440,
        "o_proj": 10485760,
        "total": 26214400,
        "num_heads": 20,
        "num_kv_heads": 5
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 47394816,
        "up_proj": 47394816,
        "down_proj": 47394816,
        "total": 142184448,
        "intermediate_size": 11571
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": 161882112,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 10485760,
        "k_proj": 2621440,
        "v_proj": 2621440,
        "o_proj": 10485760,
        "total": 26214400,
        "num_heads": 20,
        "num_kv_heads": 5
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 45219840,
        "up_proj": 45219840,
        "down_proj": 45219840,
        "total": 135659520,
        "intermediate_size": 11040
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": 162758656,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 8388608,
        "k_proj": 2097152,
        "v_proj": 2097152,
        "o_proj": 8388608,
        "total": 20971520,
        "num_heads": 16,
        "num_kv_heads": 4
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 47259648,
        "up_proj": 47259648,
        "down_proj": 47259648,
        "total": 141778944,
        "intermediate_size": 11538
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": 187858944,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 10485760,
        "k_proj": 2621440,
        "v_proj": 2621440,
        "o_proj": 10485760,
        "total": 26214400,
        "num_heads": 20,
        "num_kv_heads": 5
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 53878784,
        "up_proj": 53878784,
        "down_proj": 53878784,
        "total": 161636352,
        "intermediate_size": 13154
      },
      "norm": 8192,
      "is_zero_layer": false
    }
  ],
  "layer_summary": {
    "num_layers": 32,
    "total_layer_params": 5373542400
  }
}