{
  "original_name": "Llama-3-8B-Instruct",
  "pruned_name": "HGSP_5000",
  "total_params": {
    "original": 8030261248,
    "pruned": 4015136768,
    "reduced": 4015124480,
    "reduction_ratio": 0.4999992348941323
  },
  "layer_params": {
    "original": 6979584000,
    "pruned": 2964459520,
    "reduced": 4015124480,
    "reduction_ratio": 0.5752670187793427
  },
  "layers": [
    {
      "layer_idx": 0,
      "total": {
        "original": 218112000,
        "pruned": 218099712,
        "reduced": 12288,
        "reduction_ratio": 5.6338028169014086e-05
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176148480,
        "reduced": 12288,
        "reduction_ratio": 6.975446428571428e-05,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14335
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": {
        "original": 218112000,
        "pruned": 218112000,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176160768,
        "reduced": 0,
        "reduction_ratio": 0.0,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14336
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": {
        "original": 218112000,
        "pruned": 216465408,
        "reduced": 1646592,
        "reduction_ratio": 0.007549295774647888
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174514176,
        "reduced": 1646592,
        "reduction_ratio": 0.009347098214285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14202
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": {
        "original": 218112000,
        "pruned": 211292160,
        "reduced": 6819840,
        "reduction_ratio": 0.03126760563380282
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 169340928,
        "reduced": 6819840,
        "reduction_ratio": 0.03871372767857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13781
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": {
        "original": 218112000,
        "pruned": 208416768,
        "reduced": 9695232,
        "reduction_ratio": 0.04445070422535211
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 166465536,
        "reduced": 9695232,
        "reduction_ratio": 0.05503627232142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13547
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": {
        "original": 218112000,
        "pruned": 196743168,
        "reduced": 21368832,
        "reduction_ratio": 0.0979718309859155
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 154791936,
        "reduced": 21368832,
        "reduction_ratio": 0.12130301339285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12597
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": {
        "original": 218112000,
        "pruned": 184897536,
        "reduced": 33214464,
        "reduction_ratio": 0.15228169014084508
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 142946304,
        "reduced": 33214464,
        "reduction_ratio": 0.18854631696428573,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11633
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": {
        "original": 218112000,
        "pruned": 16003072,
        "reduced": 202108928,
        "reduction_ratio": 0.9266291079812207
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 10752000,
        "reduced": 165408768,
        "reduction_ratio": 0.93896484375,
        "intermediate_size": {
          "original": 14336,
          "pruned": 875
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": {
        "original": 218112000,
        "pruned": 12574720,
        "reduced": 205537280,
        "reduction_ratio": 0.9423474178403756
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 7323648,
        "reduced": 168837120,
        "reduction_ratio": 0.9584263392857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 596
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": {
        "original": 218112000,
        "pruned": 1187840,
        "reduced": 216924160,
        "reduction_ratio": 0.9945539906103287
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 1179648,
        "reduced": 174981120,
        "reduction_ratio": 0.9933035714285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 96
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": {
        "original": 218112000,
        "pruned": 2404352,
        "reduced": 215707648,
        "reduction_ratio": 0.9889765258215962
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 2396160,
        "reduced": 173764608,
        "reduction_ratio": 0.9863978794642857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 195
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": {
        "original": 218112000,
        "pruned": 671744,
        "reduced": 217440256,
        "reduction_ratio": 0.9969201877934273
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 663552,
        "reduced": 175497216,
        "reduction_ratio": 0.9962332589285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 54
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": {
        "original": 218112000,
        "pruned": 143360,
        "reduced": 217968640,
        "reduction_ratio": 0.9993427230046948
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 135168,
        "reduced": 176025600,
        "reduction_ratio": 0.9992327008928571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": {
        "original": 218112000,
        "pruned": 134406144,
        "reduced": 83705856,
        "reduction_ratio": 0.38377464788732396
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 92454912,
        "reduced": 83705856,
        "reduction_ratio": 0.4751674107142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7524
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": {
        "original": 218112000,
        "pruned": 130977792,
        "reduced": 87134208,
        "reduction_ratio": 0.39949295774647886
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 89026560,
        "reduced": 87134208,
        "reduction_ratio": 0.49462890625,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7245
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": {
        "original": 218112000,
        "pruned": 131727360,
        "reduced": 86384640,
        "reduction_ratio": 0.39605633802816903
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 89776128,
        "reduced": 86384640,
        "reduction_ratio": 0.49037388392857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7306
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": {
        "original": 218112000,
        "pruned": 109588480,
        "reduced": 108523520,
        "reduction_ratio": 0.4975586854460094
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 72880128,
        "reduced": 103280640,
        "reduction_ratio": 0.5862862723214286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 5931
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": {
        "original": 218112000,
        "pruned": 98217984,
        "reduced": 119894016,
        "reduction_ratio": 0.5496901408450704
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 71995392,
        "reduced": 104165376,
        "reduction_ratio": 0.59130859375,
        "intermediate_size": {
          "original": 14336,
          "pruned": 5859
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": {
        "original": 218112000,
        "pruned": 77139968,
        "reduced": 140972032,
        "reduction_ratio": 0.6463286384976525
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 61403136,
        "reduced": 114757632,
        "reduction_ratio": 0.6514369419642857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 4997
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": {
        "original": 218112000,
        "pruned": 80318464,
        "reduced": 137793536,
        "reduction_ratio": 0.631755868544601
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 59338752,
        "reduced": 116822016,
        "reduction_ratio": 0.6631556919642857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 4829
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": {
        "original": 218112000,
        "pruned": 84901888,
        "reduced": 133210112,
        "reduction_ratio": 0.6107417840375586
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 63922176,
        "reduced": 112238592,
        "reduction_ratio": 0.6371372767857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 5202
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": {
        "original": 218112000,
        "pruned": 91348992,
        "reduced": 126763008,
        "reduction_ratio": 0.5811830985915493
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 65126400,
        "reduced": 111034368,
        "reduction_ratio": 0.6303013392857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 5300
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": {
        "original": 218112000,
        "pruned": 74096640,
        "reduced": 144015360,
        "reduction_ratio": 0.660281690140845
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 63602688,
        "reduced": 112558080,
        "reduction_ratio": 0.6389508928571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 5176
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": {
        "original": 218112000,
        "pruned": 59297792,
        "reduced": 158814208,
        "reduction_ratio": 0.728131455399061
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 59289600,
        "reduced": 116871168,
        "reduction_ratio": 0.6634347098214286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 4825
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": {
        "original": 218112000,
        "pruned": 82382848,
        "reduced": 135729152,
        "reduction_ratio": 0.6222910798122065
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 61403136,
        "reduced": 114757632,
        "reduction_ratio": 0.6514369419642857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 4997
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": {
        "original": 218112000,
        "pruned": 352256,
        "reduced": 217759744,
        "reduction_ratio": 0.9983849765258216
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 344064,
        "reduced": 175816704,
        "reduction_ratio": 0.998046875,
        "intermediate_size": {
          "original": 14336,
          "pruned": 28
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": {
        "original": 218112000,
        "pruned": 339968,
        "reduced": 217772032,
        "reduction_ratio": 0.9984413145539907
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 331776,
        "reduced": 175828992,
        "reduction_ratio": 0.9981166294642857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 27
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": {
        "original": 218112000,
        "pruned": 56999936,
        "reduced": 161112064,
        "reduction_ratio": 0.7386666666666667
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 41263104,
        "reduced": 134897664,
        "reduction_ratio": 0.7657645089285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 3358
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": {
        "original": 218112000,
        "pruned": 66375680,
        "reduced": 151736320,
        "reduction_ratio": 0.6956807511737089
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 34910208,
        "reduced": 141250560,
        "reduction_ratio": 0.8018275669642857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 2841
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": {
        "original": 218112000,
        "pruned": 48136192,
        "reduced": 169975808,
        "reduction_ratio": 0.7793051643192488
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 27156480,
        "reduced": 149004288,
        "reduction_ratio": 0.8458426339285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 2210
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": {
        "original": 218112000,
        "pruned": 64372736,
        "reduced": 153739264,
        "reduction_ratio": 0.7048638497652582
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 32907264,
        "reduced": 143253504,
        "reduction_ratio": 0.8131975446428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 2678
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": {
        "original": 218112000,
        "pruned": 86466560,
        "reduced": 131645440,
        "reduction_ratio": 0.6035680751173709
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 70729728,
        "reduced": 105431040,
        "reduction_ratio": 0.5984933035714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 5756
        }
      },
      "is_zero_layer": false
    }
  ]
}