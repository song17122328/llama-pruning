{
  "original_name": "原始模型",
  "pruned_name": "剪枝后模型",
  "total_params": {
    "original": 8030261248,
    "pruned": 6424211456,
    "reduced": 1606049792,
    "reduction_ratio": 0.1999996939576529
  },
  "layer_params": {
    "original": 6979584000,
    "pruned": 5373534208,
    "reduced": 1606049792,
    "reduction_ratio": 0.2301068075117371
  },
  "layers": [
    {
      "layer_idx": 0,
      "total": {
        "original": 218112000,
        "pruned": 212869120,
        "reduced": 5242880,
        "reduction_ratio": 0.02403755868544601
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176160768,
        "reduced": 0,
        "reduction_ratio": 0.0,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14336
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": {
        "original": 218112000,
        "pruned": 218112000,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176160768,
        "reduced": 0,
        "reduction_ratio": 0.0,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14336
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": {
        "original": 218112000,
        "pruned": 207515648,
        "reduced": 10596352,
        "reduction_ratio": 0.048582159624413146
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176050176,
        "reduced": 110592,
        "reduction_ratio": 0.0006277901785714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14327
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": {
        "original": 218112000,
        "pruned": 217804800,
        "reduced": 307200,
        "reduction_ratio": 0.0014084507042253522
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175853568,
        "reduced": 307200,
        "reduction_ratio": 0.0017438616071428572,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14311
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": {
        "original": 218112000,
        "pruned": 216662016,
        "reduced": 1449984,
        "reduction_ratio": 0.006647887323943662
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174710784,
        "reduced": 1449984,
        "reduction_ratio": 0.008231026785714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14218
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": {
        "original": 218112000,
        "pruned": 202096640,
        "reduced": 16015360,
        "reduction_ratio": 0.07342723004694836
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 170631168,
        "reduced": 5529600,
        "reduction_ratio": 0.03138950892857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13886
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": {
        "original": 218112000,
        "pruned": 189796352,
        "reduced": 28315648,
        "reduction_ratio": 0.12982159624413145
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 158330880,
        "reduced": 17829888,
        "reduction_ratio": 0.10121372767857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12885
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": {
        "original": 218112000,
        "pruned": 168435712,
        "reduced": 49676288,
        "reduction_ratio": 0.22775586854460095
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 131727360,
        "reduced": 44433408,
        "reduction_ratio": 0.25223214285714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10720
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": {
        "original": 218112000,
        "pruned": 129302528,
        "reduced": 88809472,
        "reduction_ratio": 0.4071737089201878
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 97837056,
        "reduced": 78323712,
        "reduction_ratio": 0.44461495535714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7962
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": {
        "original": 218112000,
        "pruned": 120197120,
        "reduced": 97914880,
        "reduction_ratio": 0.44892018779342724
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 88731648,
        "reduced": 87429120,
        "reduction_ratio": 0.49630301339285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7221
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": {
        "original": 218112000,
        "pruned": 96550912,
        "reduced": 121561088,
        "reduction_ratio": 0.5573333333333333
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 75571200,
        "reduced": 100589568,
        "reduction_ratio": 0.5710100446428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6150
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": {
        "original": 218112000,
        "pruned": 105410560,
        "reduced": 112701440,
        "reduction_ratio": 0.5167136150234741
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 68702208,
        "reduced": 107458560,
        "reduction_ratio": 0.6100027901785714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 5591
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": {
        "original": 218112000,
        "pruned": 104448000,
        "reduced": 113664000,
        "reduction_ratio": 0.5211267605633803
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 62496768,
        "reduced": 113664000,
        "reduction_ratio": 0.6452287946428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 5086
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": {
        "original": 218112000,
        "pruned": 104849408,
        "reduced": 113262592,
        "reduction_ratio": 0.5192863849765258
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 73383936,
        "reduced": 102776832,
        "reduction_ratio": 0.5834263392857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 5972
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": {
        "original": 218112000,
        "pruned": 115007488,
        "reduced": 103104512,
        "reduction_ratio": 0.4727136150234742
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 78299136,
        "reduced": 97861632,
        "reduction_ratio": 0.5555245535714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6372
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": {
        "original": 218112000,
        "pruned": 131788800,
        "reduced": 86323200,
        "reduction_ratio": 0.3957746478873239
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 105566208,
        "reduced": 70594560,
        "reduction_ratio": 0.40073939732142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8591
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": {
        "original": 218112000,
        "pruned": 166445056,
        "reduced": 51666944,
        "reduction_ratio": 0.23688262910798122
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 129736704,
        "reduced": 46424064,
        "reduction_ratio": 0.26353236607142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10558
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": {
        "original": 218112000,
        "pruned": 179691520,
        "reduced": 38420480,
        "reduction_ratio": 0.17615023474178404
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 142983168,
        "reduced": 33177600,
        "reduction_ratio": 0.18833705357142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11636
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": {
        "original": 218112000,
        "pruned": 182222848,
        "reduced": 35889152,
        "reduction_ratio": 0.16454460093896714
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 161243136,
        "reduced": 14917632,
        "reduction_ratio": 0.08468191964285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13122
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": {
        "original": 218112000,
        "pruned": 174649344,
        "reduced": 43462656,
        "reduction_ratio": 0.19926760563380283
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 164155392,
        "reduced": 12005376,
        "reduction_ratio": 0.06815011160714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13359
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": {
        "original": 218112000,
        "pruned": 176676864,
        "reduced": 41435136,
        "reduction_ratio": 0.1899718309859155
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 166182912,
        "reduced": 9977856,
        "reduction_ratio": 0.056640625,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13524
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": {
        "original": 218112000,
        "pruned": 190087168,
        "reduced": 28024832,
        "reduction_ratio": 0.12848826291079812
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 169107456,
        "reduced": 7053312,
        "reduction_ratio": 0.0400390625,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13762
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": {
        "original": 218112000,
        "pruned": 180338688,
        "reduced": 37773312,
        "reduction_ratio": 0.1731830985915493
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 169844736,
        "reduced": 6316032,
        "reduction_ratio": 0.035853794642857144,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13822
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": {
        "original": 218112000,
        "pruned": 171065344,
        "reduced": 47046656,
        "reduction_ratio": 0.21569953051643193
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 165814272,
        "reduced": 10346496,
        "reduction_ratio": 0.05873325892857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13494
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": {
        "original": 218112000,
        "pruned": 182976512,
        "reduced": 35135488,
        "reduction_ratio": 0.16108920187793427
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 167239680,
        "reduced": 8921088,
        "reduction_ratio": 0.05064174107142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13610
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": {
        "original": 218112000,
        "pruned": 164306944,
        "reduced": 53805056,
        "reduction_ratio": 0.24668544600938966
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 159055872,
        "reduced": 17104896,
        "reduction_ratio": 0.09709821428571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12944
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": {
        "original": 218112000,
        "pruned": 164241408,
        "reduced": 53870592,
        "reduction_ratio": 0.24698591549295776
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 153747456,
        "reduced": 22413312,
        "reduction_ratio": 0.12723214285714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12512
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": {
        "original": 218112000,
        "pruned": 176824320,
        "reduced": 41287680,
        "reduction_ratio": 0.18929577464788733
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 150601728,
        "reduced": 25559040,
        "reduction_ratio": 0.14508928571428573,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12256
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": {
        "original": 218112000,
        "pruned": 158998528,
        "reduced": 59113472,
        "reduction_ratio": 0.2710234741784038
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 138018816,
        "reduced": 38141952,
        "reduction_ratio": 0.21651785714285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11232
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": {
        "original": 218112000,
        "pruned": 168996864,
        "reduced": 49115136,
        "reduction_ratio": 0.2251830985915493
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 142774272,
        "reduced": 33386496,
        "reduction_ratio": 0.18952287946428573,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11619
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": {
        "original": 218112000,
        "pruned": 178884608,
        "reduced": 39227392,
        "reduction_ratio": 0.17984976525821597
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 147419136,
        "reduced": 28741632,
        "reduction_ratio": 0.16315569196428573,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11997
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": {
        "original": 218112000,
        "pruned": 216281088,
        "reduced": 1830912,
        "reduction_ratio": 0.008394366197183098
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174329856,
        "reduced": 1830912,
        "reduction_ratio": 0.010393415178571428,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14187
        }
      },
      "is_zero_layer": false
    }
  ]
}