{
  "original_name": "原始模型",
  "pruned_name": "剪枝后模型",
  "total_params": {
    "original": 8030261248,
    "pruned": 6424219648,
    "reduced": 1606041600,
    "reduction_ratio": 0.199998673816496
  },
  "layer_params": {
    "original": 6979584000,
    "pruned": 5373542400,
    "reduced": 1606041600,
    "reduction_ratio": 0.2301056338028169
  },
  "layers": [
    {
      "layer_idx": 0,
      "total": {
        "original": 218112000,
        "pruned": 218112000,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176160768,
        "reduced": 0,
        "reduction_ratio": 0.0,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14336
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": {
        "original": 218112000,
        "pruned": 218112000,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176160768,
        "reduced": 0,
        "reduction_ratio": 0.0,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14336
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": {
        "original": 218112000,
        "pruned": 217571328,
        "reduced": 540672,
        "reduction_ratio": 0.0024788732394366198
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175620096,
        "reduced": 540672,
        "reduction_ratio": 0.0030691964285714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14292
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": {
        "original": 218112000,
        "pruned": 215826432,
        "reduced": 2285568,
        "reduction_ratio": 0.01047887323943662
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173875200,
        "reduced": 2285568,
        "reduction_ratio": 0.012974330357142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14150
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": {
        "original": 218112000,
        "pruned": 213835776,
        "reduced": 4276224,
        "reduction_ratio": 0.0196056338028169
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 171884544,
        "reduced": 4276224,
        "reduction_ratio": 0.024274553571428572,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13988
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": {
        "original": 218112000,
        "pruned": 206831616,
        "reduced": 11280384,
        "reduction_ratio": 0.05171830985915493
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 164880384,
        "reduced": 11280384,
        "reduction_ratio": 0.06403459821428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13418
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": {
        "original": 218112000,
        "pruned": 200884224,
        "reduced": 17227776,
        "reduction_ratio": 0.07898591549295775
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 158932992,
        "reduced": 17227776,
        "reduction_ratio": 0.09779575892857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12934
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": {
        "original": 218112000,
        "pruned": 178176000,
        "reduced": 39936000,
        "reduction_ratio": 0.18309859154929578
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 136224768,
        "reduced": 39936000,
        "reduction_ratio": 0.22670200892857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11086
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": {
        "original": 218112000,
        "pruned": 129617920,
        "reduced": 88494080,
        "reduction_ratio": 0.4057276995305164
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 92909568,
        "reduced": 83251200,
        "reduction_ratio": 0.4725864955357143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7561
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": {
        "original": 218112000,
        "pruned": 88887296,
        "reduced": 129224704,
        "reduction_ratio": 0.5924694835680752
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 73150464,
        "reduced": 103010304,
        "reduction_ratio": 0.5847516741071429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 5953
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": {
        "original": 218112000,
        "pruned": 105615360,
        "reduced": 112496640,
        "reduction_ratio": 0.515774647887324
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 79392768,
        "reduced": 96768000,
        "reduction_ratio": 0.54931640625,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6461
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": {
        "original": 218112000,
        "pruned": 136228864,
        "reduced": 81883136,
        "reduction_ratio": 0.37541784037558684
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 99520512,
        "reduced": 76640256,
        "reduction_ratio": 0.43505859375,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8099
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": {
        "original": 218112000,
        "pruned": 136544256,
        "reduced": 81567744,
        "reduction_ratio": 0.37397183098591547
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 94593024,
        "reduced": 81567744,
        "reduction_ratio": 0.46303013392857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7698
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": {
        "original": 218112000,
        "pruned": 122900480,
        "reduced": 95211520,
        "reduction_ratio": 0.43652582159624415
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 91435008,
        "reduced": 84725760,
        "reduction_ratio": 0.48095703125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7441
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": {
        "original": 218112000,
        "pruned": 156848128,
        "reduced": 61263872,
        "reduction_ratio": 0.28088262910798123
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 120139776,
        "reduced": 56020992,
        "reduction_ratio": 0.31801060267857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9777
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": {
        "original": 218112000,
        "pruned": 179208192,
        "reduced": 38903808,
        "reduction_ratio": 0.1783661971830986
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 137256960,
        "reduced": 38903808,
        "reduction_ratio": 0.22084263392857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11170
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": {
        "original": 218112000,
        "pruned": 184492032,
        "reduced": 33619968,
        "reduction_ratio": 0.15414084507042253
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 142540800,
        "reduced": 33619968,
        "reduction_ratio": 0.19084821428571427,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11600
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": {
        "original": 218112000,
        "pruned": 193007616,
        "reduced": 25104384,
        "reduction_ratio": 0.11509859154929578
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 151056384,
        "reduced": 25104384,
        "reduction_ratio": 0.14250837053571427,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12293
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": {
        "original": 218112000,
        "pruned": 181018624,
        "reduced": 37093376,
        "reduction_ratio": 0.17006572769953052
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 144310272,
        "reduced": 31850496,
        "reduction_ratio": 0.18080357142857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11744
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": {
        "original": 218112000,
        "pruned": 141127680,
        "reduced": 76984320,
        "reduction_ratio": 0.35295774647887324
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 114905088,
        "reduced": 61255680,
        "reduction_ratio": 0.3477260044642857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9351
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": {
        "original": 218112000,
        "pruned": 148791296,
        "reduced": 69320704,
        "reduction_ratio": 0.3178215962441315
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 117325824,
        "reduced": 58834944,
        "reduction_ratio": 0.333984375,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9548
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": {
        "original": 218112000,
        "pruned": 180006912,
        "reduced": 38105088,
        "reduction_ratio": 0.17470422535211266
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 138055680,
        "reduced": 38105088,
        "reduction_ratio": 0.21630859375,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11235
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": {
        "original": 218112000,
        "pruned": 152539136,
        "reduced": 65572864,
        "reduction_ratio": 0.30063849765258216
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 121073664,
        "reduced": 55087104,
        "reduction_ratio": 0.31270926339285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9853
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": {
        "original": 218112000,
        "pruned": 149438464,
        "reduced": 68673536,
        "reduction_ratio": 0.3148544600938967
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 128458752,
        "reduced": 47702016,
        "reduction_ratio": 0.27078683035714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10454
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": {
        "original": 218112000,
        "pruned": 153026560,
        "reduced": 65085440,
        "reduction_ratio": 0.2984037558685446
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 116318208,
        "reduced": 59842560,
        "reduction_ratio": 0.33970424107142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9466
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": {
        "original": 218112000,
        "pruned": 127102976,
        "reduced": 91009024,
        "reduction_ratio": 0.41725821596244134
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 95637504,
        "reduced": 80523264,
        "reduction_ratio": 0.4571010044642857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7783
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": {
        "original": 218112000,
        "pruned": 128172032,
        "reduced": 89939968,
        "reduction_ratio": 0.4123568075117371
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 96706560,
        "reduced": 79454208,
        "reduction_ratio": 0.45103236607142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7870
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": {
        "original": 218112000,
        "pruned": 141795328,
        "reduced": 76316672,
        "reduction_ratio": 0.34989671361502345
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 105086976,
        "reduced": 71073792,
        "reduction_ratio": 0.40345982142857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8552
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": {
        "original": 218112000,
        "pruned": 144572416,
        "reduced": 73539584,
        "reduction_ratio": 0.3371643192488263
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 107864064,
        "reduced": 68296704,
        "reduction_ratio": 0.3876953125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8778
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": {
        "original": 218112000,
        "pruned": 191795200,
        "reduced": 26316800,
        "reduction_ratio": 0.12065727699530517
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 155086848,
        "reduced": 21073920,
        "reduction_ratio": 0.11962890625,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12621
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": {
        "original": 218112000,
        "pruned": 213344256,
        "reduced": 4767744,
        "reduction_ratio": 0.021859154929577466
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 171393024,
        "reduced": 4767744,
        "reduction_ratio": 0.027064732142857144,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13948
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": {
        "original": 218112000,
        "pruned": 218112000,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176160768,
        "reduced": 0,
        "reduction_ratio": 0.0,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14336
        }
      },
      "is_zero_layer": false
    }
  ]
}