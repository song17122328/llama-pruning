{
  "original_name": "原始模型",
  "pruned_name": "剪枝后模型",
  "total_params": {
    "original": 7248023552,
    "pruned": 5798424576,
    "reduced": 1449598976,
    "reduction_ratio": 0.19999920883259292
  },
  "layer_params": {
    "original": 6979584000,
    "pruned": 5529985024,
    "reduced": 1449598976,
    "reduction_ratio": 0.20769131455399062
  },
  "layers": [
    {
      "layer_idx": 0,
      "total": {
        "original": 218112000,
        "pruned": 95268864,
        "reduced": 122843136,
        "reduction_ratio": 0.5632112676056338
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 84774912,
        "reduced": 91385856,
        "reduction_ratio": 0.5187639508928571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6899
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": {
        "original": 218112000,
        "pruned": 212180992,
        "reduced": 5931008,
        "reduction_ratio": 0.027192488262910798
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175472640,
        "reduced": 688128,
        "reduction_ratio": 0.00390625,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14280
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": {
        "original": 218112000,
        "pruned": 212279296,
        "reduced": 5832704,
        "reduction_ratio": 0.026741784037558686
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175570944,
        "reduced": 589824,
        "reduction_ratio": 0.0033482142857142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14288
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": {
        "original": 218112000,
        "pruned": 217755648,
        "reduced": 356352,
        "reduction_ratio": 0.0016338028169014085
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175804416,
        "reduced": 356352,
        "reduction_ratio": 0.0020228794642857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14307
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": {
        "original": 218112000,
        "pruned": 212500480,
        "reduced": 5611520,
        "reduction_ratio": 0.025727699530516433
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175792128,
        "reduced": 368640,
        "reduction_ratio": 0.0020926339285714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14306
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": {
        "original": 218112000,
        "pruned": 217952256,
        "reduced": 159744,
        "reduction_ratio": 0.0007323943661971831
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176001024,
        "reduced": 159744,
        "reduction_ratio": 0.0009068080357142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14323
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": {
        "original": 218112000,
        "pruned": 211591168,
        "reduced": 6520832,
        "reduction_ratio": 0.029896713615023475
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174882816,
        "reduced": 1277952,
        "reduction_ratio": 0.007254464285714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14232
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": {
        "original": 218112000,
        "pruned": 210472960,
        "reduced": 7639040,
        "reduction_ratio": 0.035023474178403756
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173764608,
        "reduced": 2396160,
        "reduction_ratio": 0.013602120535714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14141
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": {
        "original": 218112000,
        "pruned": 214462464,
        "reduced": 3649536,
        "reduction_ratio": 0.016732394366197185
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 172511232,
        "reduced": 3649536,
        "reduction_ratio": 0.020717075892857144,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14039
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": {
        "original": 218112000,
        "pruned": 207081472,
        "reduced": 11030528,
        "reduction_ratio": 0.05057276995305164
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 170373120,
        "reduced": 5787648,
        "reduction_ratio": 0.03285435267857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13865
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": {
        "original": 218112000,
        "pruned": 189751296,
        "reduced": 28360704,
        "reduction_ratio": 0.1300281690140845
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 147800064,
        "reduced": 28360704,
        "reduction_ratio": 0.16099330357142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12028
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": {
        "original": 218112000,
        "pruned": 170557440,
        "reduced": 47554560,
        "reduction_ratio": 0.2180281690140845
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 128606208,
        "reduced": 47554560,
        "reduction_ratio": 0.2699497767857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10466
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": {
        "original": 218112000,
        "pruned": 146419712,
        "reduced": 71692288,
        "reduction_ratio": 0.3286948356807512
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 114954240,
        "reduced": 61206528,
        "reduction_ratio": 0.34744698660714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9355
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": {
        "original": 218112000,
        "pruned": 152236032,
        "reduced": 65875968,
        "reduction_ratio": 0.3020281690140845
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 110284800,
        "reduced": 65875968,
        "reduction_ratio": 0.3739536830357143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8975
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": {
        "original": 218112000,
        "pruned": 144941056,
        "reduced": 73170944,
        "reduction_ratio": 0.3354741784037559
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 108232704,
        "reduced": 67928064,
        "reduction_ratio": 0.38560267857142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8808
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": {
        "original": 218112000,
        "pruned": 163004416,
        "reduced": 55107584,
        "reduction_ratio": 0.25265727699530516
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 126296064,
        "reduced": 49864704,
        "reduction_ratio": 0.28306361607142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10278
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": {
        "original": 218112000,
        "pruned": 188829696,
        "reduced": 29282304,
        "reduction_ratio": 0.13425352112676056
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 146878464,
        "reduced": 29282304,
        "reduction_ratio": 0.16622488839285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11953
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": {
        "original": 218112000,
        "pruned": 188895232,
        "reduced": 29216768,
        "reduction_ratio": 0.1339530516431925
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 152186880,
        "reduced": 23973888,
        "reduction_ratio": 0.13609095982142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12385
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": {
        "original": 218112000,
        "pruned": 198393856,
        "reduced": 19718144,
        "reduction_ratio": 0.0904037558685446
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 161685504,
        "reduced": 14475264,
        "reduction_ratio": 0.08217075892857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13158
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": {
        "original": 218112000,
        "pruned": 206934016,
        "reduced": 11177984,
        "reduction_ratio": 0.05124882629107981
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 170225664,
        "reduced": 5935104,
        "reduction_ratio": 0.03369140625,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13853
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": {
        "original": 218112000,
        "pruned": 201056256,
        "reduced": 17055744,
        "reduction_ratio": 0.07819718309859156
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174833664,
        "reduced": 1327104,
        "reduction_ratio": 0.007533482142857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14228
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": {
        "original": 218112000,
        "pruned": 212402176,
        "reduced": 5709824,
        "reduction_ratio": 0.026178403755868544
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175693824,
        "reduced": 466944,
        "reduction_ratio": 0.002650669642857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14298
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": {
        "original": 218112000,
        "pruned": 202063872,
        "reduced": 16048128,
        "reduction_ratio": 0.0735774647887324
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175841280,
        "reduced": 319488,
        "reduction_ratio": 0.0018136160714285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14310
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": {
        "original": 218112000,
        "pruned": 186335232,
        "reduced": 31776768,
        "reduction_ratio": 0.14569014084507043
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175841280,
        "reduced": 319488,
        "reduction_ratio": 0.0018136160714285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14310
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": {
        "original": 218112000,
        "pruned": 175738880,
        "reduced": 42373120,
        "reduction_ratio": 0.19427230046948357
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175730688,
        "reduced": 430080,
        "reduction_ratio": 0.00244140625,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14301
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": {
        "original": 218112000,
        "pruned": 175345664,
        "reduced": 42766336,
        "reduction_ratio": 0.19607511737089203
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175337472,
        "reduced": 823296,
        "reduction_ratio": 0.004673549107142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14269
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": {
        "original": 218112000,
        "pruned": 173293568,
        "reduced": 44818432,
        "reduction_ratio": 0.20548356807511736
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173285376,
        "reduced": 2875392,
        "reduction_ratio": 0.016322544642857144,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14102
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": {
        "original": 218112000,
        "pruned": 164687872,
        "reduced": 53424128,
        "reduction_ratio": 0.24493896713615024
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 159436800,
        "reduced": 16723968,
        "reduction_ratio": 0.09493582589285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12975
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": {
        "original": 218112000,
        "pruned": 115499008,
        "reduced": 102612992,
        "reduction_ratio": 0.4704600938967136
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 110247936,
        "reduced": 65912832,
        "reduction_ratio": 0.37416294642857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8972
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": {
        "original": 218112000,
        "pruned": 72388608,
        "reduced": 145723392,
        "reduction_ratio": 0.6681126760563381
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 61894656,
        "reduced": 114266112,
        "reduction_ratio": 0.6486467633928571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 5037
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": {
        "original": 218112000,
        "pruned": 33161216,
        "reduced": 184950784,
        "reduction_ratio": 0.847962441314554
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 33153024,
        "reduced": 143007744,
        "reduction_ratio": 0.8118024553571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 2698
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": {
        "original": 218112000,
        "pruned": 56504320,
        "reduced": 161607680,
        "reduction_ratio": 0.7409389671361503
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 51253248,
        "reduced": 124907520,
        "reduction_ratio": 0.7090541294642857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 4171
        }
      },
      "is_zero_layer": false
    }
  ]
}