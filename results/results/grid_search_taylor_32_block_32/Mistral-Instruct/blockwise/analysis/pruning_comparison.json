{
  "original_name": "原始模型",
  "pruned_name": "剪枝后模型",
  "total_params": {
    "original": 7248023552,
    "pruned": 5798420480,
    "reduced": 1449603072,
    "reduction_ratio": 0.19999977395216942
  },
  "layer_params": {
    "original": 6979584000,
    "pruned": 5529980928,
    "reduced": 1449603072,
    "reduction_ratio": 0.2076919014084507
  },
  "layers": [
    {
      "layer_idx": 0,
      "total": {
        "original": 218112000,
        "pruned": 135204864,
        "reduced": 82907136,
        "reduction_ratio": 0.38011267605633803
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 93253632,
        "reduced": 82907136,
        "reduction_ratio": 0.4706333705357143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7589
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": {
        "original": 218112000,
        "pruned": 217952256,
        "reduced": 159744,
        "reduction_ratio": 0.0007323943661971831
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176001024,
        "reduced": 159744,
        "reduction_ratio": 0.0009068080357142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14323
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": {
        "original": 218112000,
        "pruned": 212549632,
        "reduced": 5562368,
        "reduction_ratio": 0.025502347417840375
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175841280,
        "reduced": 319488,
        "reduction_ratio": 0.0018136160714285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14310
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": {
        "original": 218112000,
        "pruned": 217915392,
        "reduced": 196608,
        "reduction_ratio": 0.0009014084507042254
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175964160,
        "reduced": 196608,
        "reduction_ratio": 0.0011160714285714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14320
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": {
        "original": 218112000,
        "pruned": 217853952,
        "reduced": 258048,
        "reduction_ratio": 0.0011830985915492957
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175902720,
        "reduced": 258048,
        "reduction_ratio": 0.00146484375,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14315
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": {
        "original": 218112000,
        "pruned": 218013696,
        "reduced": 98304,
        "reduction_ratio": 0.0004507042253521127
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176062464,
        "reduced": 98304,
        "reduction_ratio": 0.0005580357142857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14328
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": {
        "original": 218112000,
        "pruned": 212168704,
        "reduced": 5943296,
        "reduction_ratio": 0.027248826291079813
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175460352,
        "reduced": 700416,
        "reduction_ratio": 0.003976004464285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14279
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": {
        "original": 218112000,
        "pruned": 211357696,
        "reduced": 6754304,
        "reduction_ratio": 0.03096713615023474
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174649344,
        "reduced": 1511424,
        "reduction_ratio": 0.008579799107142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14213
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": {
        "original": 218112000,
        "pruned": 216158208,
        "reduced": 1953792,
        "reduction_ratio": 0.008957746478873239
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174206976,
        "reduced": 1953792,
        "reduction_ratio": 0.011090959821428572,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14177
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": {
        "original": 218112000,
        "pruned": 209846272,
        "reduced": 8265728,
        "reduction_ratio": 0.037896713615023475
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173137920,
        "reduced": 3022848,
        "reduction_ratio": 0.017159598214285716,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14090
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": {
        "original": 218112000,
        "pruned": 201277440,
        "reduced": 16834560,
        "reduction_ratio": 0.0771830985915493
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 159326208,
        "reduced": 16834560,
        "reduction_ratio": 0.09556361607142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12966
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": {
        "original": 218112000,
        "pruned": 181690368,
        "reduced": 36421632,
        "reduction_ratio": 0.16698591549295774
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 139739136,
        "reduced": 36421632,
        "reduction_ratio": 0.20675223214285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11372
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": {
        "original": 218112000,
        "pruned": 157847552,
        "reduced": 60264448,
        "reduction_ratio": 0.27630046948356807
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 126382080,
        "reduced": 49778688,
        "reduction_ratio": 0.28257533482142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10285
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": {
        "original": 218112000,
        "pruned": 160149504,
        "reduced": 57962496,
        "reduction_ratio": 0.26574647887323943
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 118198272,
        "reduced": 57962496,
        "reduction_ratio": 0.3290318080357143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9619
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": {
        "original": 218112000,
        "pruned": 146059264,
        "reduced": 72052736,
        "reduction_ratio": 0.3303474178403756
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 109350912,
        "reduced": 66809856,
        "reduction_ratio": 0.37925502232142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8899
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": {
        "original": 218112000,
        "pruned": 163176448,
        "reduced": 54935552,
        "reduction_ratio": 0.251868544600939
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 126468096,
        "reduced": 49692672,
        "reduction_ratio": 0.28208705357142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10292
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": {
        "original": 218112000,
        "pruned": 182771712,
        "reduced": 35340288,
        "reduction_ratio": 0.1620281690140845
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 140820480,
        "reduced": 35340288,
        "reduction_ratio": 0.20061383928571427,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11460
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": {
        "original": 218112000,
        "pruned": 188792832,
        "reduced": 29319168,
        "reduction_ratio": 0.1344225352112676
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 146841600,
        "reduced": 29319168,
        "reduction_ratio": 0.16643415178571427,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11950
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": {
        "original": 218112000,
        "pruned": 192532480,
        "reduced": 25579520,
        "reduction_ratio": 0.11727699530516432
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 155824128,
        "reduced": 20336640,
        "reduction_ratio": 0.11544363839285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12681
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": {
        "original": 218112000,
        "pruned": 201146368,
        "reduced": 16965632,
        "reduction_ratio": 0.07778403755868545
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 164438016,
        "reduced": 11722752,
        "reduction_ratio": 0.06654575892857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13382
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": {
        "original": 218112000,
        "pruned": 199581696,
        "reduced": 18530304,
        "reduction_ratio": 0.08495774647887323
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173359104,
        "reduced": 2801664,
        "reduction_ratio": 0.015904017857142856,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14108
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": {
        "original": 218112000,
        "pruned": 211922944,
        "reduced": 6189056,
        "reduction_ratio": 0.028375586854460094
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175214592,
        "reduced": 946176,
        "reduction_ratio": 0.00537109375,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14259
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": {
        "original": 218112000,
        "pruned": 191332352,
        "reduced": 26779648,
        "reduction_ratio": 0.1227793427230047
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175595520,
        "reduced": 565248,
        "reduction_ratio": 0.003208705357142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14290
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": {
        "original": 218112000,
        "pruned": 180748288,
        "reduced": 37363712,
        "reduction_ratio": 0.17130516431924883
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175497216,
        "reduced": 663552,
        "reduction_ratio": 0.0037667410714285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14282
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": {
        "original": 218112000,
        "pruned": 175308800,
        "reduced": 42803200,
        "reduction_ratio": 0.19624413145539907
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175300608,
        "reduced": 860160,
        "reduction_ratio": 0.0048828125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14266
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": {
        "original": 218112000,
        "pruned": 174067712,
        "reduced": 44044288,
        "reduction_ratio": 0.20193427230046948
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174059520,
        "reduced": 2101248,
        "reduction_ratio": 0.011928013392857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14165
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": {
        "original": 218112000,
        "pruned": 169078784,
        "reduced": 49033216,
        "reduction_ratio": 0.2248075117370892
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 169070592,
        "reduced": 7090176,
        "reduction_ratio": 0.040248325892857144,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13759
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": {
        "original": 218112000,
        "pruned": 157593600,
        "reduced": 60518400,
        "reduction_ratio": 0.2774647887323944
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 147099648,
        "reduced": 29061120,
        "reduction_ratio": 0.16496930803571427,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11971
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": {
        "original": 218112000,
        "pruned": 94019584,
        "reduced": 124092416,
        "reduction_ratio": 0.5689389671361502
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 88768512,
        "reduced": 87392256,
        "reduction_ratio": 0.49609375,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7224
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": {
        "original": 218112000,
        "pruned": 57225216,
        "reduced": 160886784,
        "reduction_ratio": 0.7376338028169014
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 46731264,
        "reduced": 129429504,
        "reduction_ratio": 0.7347237723214286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 3803
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": {
        "original": 218112000,
        "pruned": 32448512,
        "reduced": 185663488,
        "reduction_ratio": 0.8512300469483568
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 32440320,
        "reduced": 143720448,
        "reduction_ratio": 0.8158482142857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 2640
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": {
        "original": 218112000,
        "pruned": 42188800,
        "reduced": 175923200,
        "reduction_ratio": 0.8065727699530516
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 36937728,
        "reduced": 139223040,
        "reduction_ratio": 0.7903180803571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 3006
        }
      },
      "is_zero_layer": false
    }
  ]
}