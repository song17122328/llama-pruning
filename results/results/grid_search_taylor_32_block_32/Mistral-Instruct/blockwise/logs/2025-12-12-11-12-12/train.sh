python run_global_pruning.py --base_model /newdata/LLMs/Mistral-7B-Instruct-v0.3 --output_name results/grid_search_taylor_32_block_32/Mistral-Instruct/blockwise --taylor_num_samples 256 --taylor_seq_len 32 --layer_importance_num_samples 256 --layer_importance_seq_len 32 --block_importance_num_samples 256 --block_importance_seq_len 32 --gradient_batch_size 8 --pruning_ratio 0.2 --device cuda