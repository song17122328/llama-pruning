python run_global_pruning.py --base_model /newdata/LLMs/Mistral-7B-Instruct-v0.3 --output_name results/grid_search_taylor_32_block_32/Mistral-Instruct/wanda --importance_method wanda --taylor_num_samples 256 --taylor_seq_len 32 --gradient_batch_size 8 --pruning_ratio 0.2 --temperature 0.0 --device cuda