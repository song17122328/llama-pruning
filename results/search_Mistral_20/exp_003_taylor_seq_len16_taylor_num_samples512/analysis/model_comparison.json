{
  "original_name": "原始模型",
  "pruned_name": "剪枝后模型",
  "total_params": {
    "original": 7248023552,
    "pruned": 5798420480,
    "reduced": 1449603072,
    "reduction_ratio": 0.19999977395216942
  },
  "layer_params": {
    "original": 6979584000,
    "pruned": 5529980928,
    "reduced": 1449603072,
    "reduction_ratio": 0.2076919014084507
  },
  "layers": [
    {
      "layer_idx": 0,
      "total": {
        "original": 218112000,
        "pruned": 64647168,
        "reduced": 153464832,
        "reduction_ratio": 0.7036056338028169
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 54153216,
        "reduced": 122007552,
        "reduction_ratio": 0.6925920758928571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 4407
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": {
        "original": 218112000,
        "pruned": 204455936,
        "reduced": 13656064,
        "reduction_ratio": 0.06261032863849765
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 172990464,
        "reduced": 3170304,
        "reduction_ratio": 0.017996651785714284,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14078
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": {
        "original": 218112000,
        "pruned": 211640320,
        "reduced": 6471680,
        "reduction_ratio": 0.029671361502347417
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174931968,
        "reduced": 1228800,
        "reduction_ratio": 0.006975446428571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14236
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": {
        "original": 218112000,
        "pruned": 217214976,
        "reduced": 897024,
        "reduction_ratio": 0.004112676056338028
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175263744,
        "reduced": 897024,
        "reduction_ratio": 0.005092075892857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14263
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": {
        "original": 218112000,
        "pruned": 211271680,
        "reduced": 6840320,
        "reduction_ratio": 0.03136150234741784
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174563328,
        "reduced": 1597440,
        "reduction_ratio": 0.009068080357142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14206
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": {
        "original": 218112000,
        "pruned": 211369984,
        "reduced": 6742016,
        "reduction_ratio": 0.03091079812206573
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174661632,
        "reduced": 1499136,
        "reduction_ratio": 0.008510044642857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14214
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": {
        "original": 218112000,
        "pruned": 194482176,
        "reduced": 23629824,
        "reduction_ratio": 0.10833802816901408
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 168259584,
        "reduced": 7901184,
        "reduction_ratio": 0.04485212053571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13693
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": {
        "original": 218112000,
        "pruned": 195584000,
        "reduced": 22528000,
        "reduction_ratio": 0.10328638497652583
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 164118528,
        "reduced": 12042240,
        "reduction_ratio": 0.068359375,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13356
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": {
        "original": 218112000,
        "pruned": 193658880,
        "reduced": 24453120,
        "reduction_ratio": 0.11211267605633803
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 151707648,
        "reduced": 24453120,
        "reduction_ratio": 0.13881138392857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12346
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": {
        "original": 218112000,
        "pruned": 148078592,
        "reduced": 70033408,
        "reduction_ratio": 0.32108920187793427
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 116613120,
        "reduced": 59547648,
        "reduction_ratio": 0.33803013392857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9490
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": {
        "original": 218112000,
        "pruned": 115539968,
        "reduced": 102572032,
        "reduction_ratio": 0.4702723004694836
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 84074496,
        "reduced": 92086272,
        "reduction_ratio": 0.5227399553571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6842
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": {
        "original": 218112000,
        "pruned": 85532672,
        "reduced": 132579328,
        "reduction_ratio": 0.607849765258216
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 69795840,
        "reduced": 106364928,
        "reduction_ratio": 0.6037946428571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 5680
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": {
        "original": 218112000,
        "pruned": 80273408,
        "reduced": 137838592,
        "reduction_ratio": 0.631962441314554
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 64536576,
        "reduced": 111624192,
        "reduction_ratio": 0.6336495535714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 5252
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": {
        "original": 218112000,
        "pruned": 103616512,
        "reduced": 114495488,
        "reduction_ratio": 0.5249389671361502
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 66908160,
        "reduced": 109252608,
        "reduction_ratio": 0.6201869419642857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 5445
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": {
        "original": 218112000,
        "pruned": 95494144,
        "reduced": 122617856,
        "reduction_ratio": 0.5621784037558686
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 74514432,
        "reduced": 101646336,
        "reduction_ratio": 0.5770089285714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6064
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": {
        "original": 218112000,
        "pruned": 120963072,
        "reduced": 97148928,
        "reduction_ratio": 0.44540845070422536
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 94740480,
        "reduced": 81420288,
        "reduction_ratio": 0.46219308035714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7710
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": {
        "original": 218112000,
        "pruned": 138072064,
        "reduced": 80039936,
        "reduction_ratio": 0.36696713615023474
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 117092352,
        "reduced": 59068416,
        "reduction_ratio": 0.33530970982142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9529
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": {
        "original": 218112000,
        "pruned": 170319872,
        "reduced": 47792128,
        "reduction_ratio": 0.21911737089201877
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 138854400,
        "reduced": 37306368,
        "reduction_ratio": 0.21177455357142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11300
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": {
        "original": 218112000,
        "pruned": 188166144,
        "reduced": 29945856,
        "reduction_ratio": 0.13729577464788734
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 161943552,
        "reduced": 14217216,
        "reduction_ratio": 0.08070591517857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13179
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": {
        "original": 218112000,
        "pruned": 209416192,
        "reduced": 8695808,
        "reduction_ratio": 0.039868544600938964
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 172707840,
        "reduced": 3452928,
        "reduction_ratio": 0.019601004464285716,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14055
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": {
        "original": 218112000,
        "pruned": 201658368,
        "reduced": 16453632,
        "reduction_ratio": 0.07543661971830985
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175435776,
        "reduced": 724992,
        "reduction_ratio": 0.004115513392857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14277
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": {
        "original": 218112000,
        "pruned": 212586496,
        "reduced": 5525504,
        "reduction_ratio": 0.025333333333333333
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175878144,
        "reduced": 282624,
        "reduction_ratio": 0.0016043526785714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14313
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": {
        "original": 218112000,
        "pruned": 207429632,
        "reduced": 10682368,
        "reduction_ratio": 0.04897652582159624
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175964160,
        "reduced": 196608,
        "reduction_ratio": 0.0011160714285714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14320
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": {
        "original": 218112000,
        "pruned": 191750144,
        "reduced": 26361856,
        "reduction_ratio": 0.12086384976525821
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176013312,
        "reduced": 147456,
        "reduction_ratio": 0.0008370535714285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14324
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": {
        "original": 218112000,
        "pruned": 186544128,
        "reduced": 31567872,
        "reduction_ratio": 0.14473239436619717
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176050176,
        "reduced": 110592,
        "reduction_ratio": 0.0006277901785714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14327
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": {
        "original": 218112000,
        "pruned": 186580992,
        "reduced": 31531008,
        "reduction_ratio": 0.14456338028169013
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176087040,
        "reduced": 73728,
        "reduction_ratio": 0.0004185267857142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14330
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": {
        "original": 218112000,
        "pruned": 191713280,
        "reduced": 26398720,
        "reduction_ratio": 0.12103286384976526
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175976448,
        "reduced": 184320,
        "reduction_ratio": 0.0010463169642857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14321
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": {
        "original": 218112000,
        "pruned": 201940992,
        "reduced": 16171008,
        "reduction_ratio": 0.07414084507042254
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175718400,
        "reduced": 442368,
        "reduction_ratio": 0.0025111607142857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14300
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": {
        "original": 218112000,
        "pruned": 190484480,
        "reduced": 27627520,
        "reduction_ratio": 0.12666666666666668
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174747648,
        "reduced": 1413120,
        "reduction_ratio": 0.008021763392857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14221
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": {
        "original": 218112000,
        "pruned": 204824576,
        "reduced": 13287424,
        "reduction_ratio": 0.06092018779342723
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173359104,
        "reduced": 2801664,
        "reduction_ratio": 0.015904017857142856,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14108
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": {
        "original": 218112000,
        "pruned": 194142208,
        "reduced": 23969792,
        "reduction_ratio": 0.10989671361502347
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173162496,
        "reduced": 2998272,
        "reduction_ratio": 0.017020089285714284,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14092
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": {
        "original": 218112000,
        "pruned": 200527872,
        "reduced": 17584128,
        "reduction_ratio": 0.08061971830985916
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174305280,
        "reduced": 1855488,
        "reduction_ratio": 0.010532924107142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14185
        }
      },
      "is_zero_layer": false
    }
  ]
}