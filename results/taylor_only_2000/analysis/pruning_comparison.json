{
  "original_name": "Llama-3-8B-Instruct",
  "pruned_name": "taylor_only_2000",
  "total_params": {
    "original": 8030261248,
    "pruned": 6424211456,
    "reduced": 1606049792,
    "reduction_ratio": 0.1999996939576529
  },
  "layer_params": {
    "original": 6979584000,
    "pruned": 5373534208,
    "reduced": 1606049792,
    "reduction_ratio": 0.2301068075117371
  },
  "layers": [
    {
      "layer_idx": 0,
      "total": {
        "original": 218112000,
        "pruned": 195870720,
        "reduced": 22241280,
        "reduction_ratio": 0.10197183098591549
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 153919488,
        "reduced": 22241280,
        "reduction_ratio": 0.12625558035714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12526
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": {
        "original": 218112000,
        "pruned": 209289216,
        "reduced": 8822784,
        "reduction_ratio": 0.040450704225352116
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 167337984,
        "reduced": 8822784,
        "reduction_ratio": 0.050083705357142856,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13618
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": {
        "original": 218112000,
        "pruned": 215322624,
        "reduced": 2789376,
        "reduction_ratio": 0.012788732394366197
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173371392,
        "reduced": 2789376,
        "reduction_ratio": 0.015834263392857144,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14109
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": {
        "original": 218112000,
        "pruned": 213233664,
        "reduced": 4878336,
        "reduction_ratio": 0.022366197183098593
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 171282432,
        "reduced": 4878336,
        "reduction_ratio": 0.027692522321428572,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13939
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": {
        "original": 218112000,
        "pruned": 213307392,
        "reduced": 4804608,
        "reduction_ratio": 0.022028169014084508
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 171356160,
        "reduced": 4804608,
        "reduction_ratio": 0.027273995535714284,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13945
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": {
        "original": 218112000,
        "pruned": 208699392,
        "reduced": 9412608,
        "reduction_ratio": 0.043154929577464786
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 166748160,
        "reduced": 9412608,
        "reduction_ratio": 0.053431919642857144,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13570
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": {
        "original": 218112000,
        "pruned": 205197312,
        "reduced": 12914688,
        "reduction_ratio": 0.059211267605633805
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 163246080,
        "reduced": 12914688,
        "reduction_ratio": 0.07331194196428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13285
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": {
        "original": 218112000,
        "pruned": 195551232,
        "reduced": 22560768,
        "reduction_ratio": 0.10343661971830986
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 153600000,
        "reduced": 22560768,
        "reduction_ratio": 0.12806919642857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12500
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": {
        "original": 218112000,
        "pruned": 193708032,
        "reduced": 24403968,
        "reduction_ratio": 0.11188732394366198
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 151756800,
        "reduced": 24403968,
        "reduction_ratio": 0.13853236607142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12350
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": {
        "original": 218112000,
        "pruned": 192933888,
        "reduced": 25178112,
        "reduction_ratio": 0.11543661971830986
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 150982656,
        "reduced": 25178112,
        "reduction_ratio": 0.14292689732142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12287
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": {
        "original": 218112000,
        "pruned": 183988224,
        "reduced": 34123776,
        "reduction_ratio": 0.15645070422535212
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 142036992,
        "reduced": 34123776,
        "reduction_ratio": 0.19370814732142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11559
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": {
        "original": 218112000,
        "pruned": 186298368,
        "reduced": 31813632,
        "reduction_ratio": 0.14585915492957746
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 144347136,
        "reduced": 31813632,
        "reduction_ratio": 0.18059430803571427,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11747
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": {
        "original": 218112000,
        "pruned": 178593792,
        "reduced": 39518208,
        "reduction_ratio": 0.1811830985915493
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 136642560,
        "reduced": 39518208,
        "reduction_ratio": 0.22433035714285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11120
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": {
        "original": 218112000,
        "pruned": 171835392,
        "reduced": 46276608,
        "reduction_ratio": 0.21216901408450703
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 129884160,
        "reduced": 46276608,
        "reduction_ratio": 0.2626953125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10570
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": {
        "original": 218112000,
        "pruned": 171147264,
        "reduced": 46964736,
        "reduction_ratio": 0.21532394366197183
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 129196032,
        "reduced": 46964736,
        "reduction_ratio": 0.2666015625,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10514
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": {
        "original": 218112000,
        "pruned": 179355648,
        "reduced": 38756352,
        "reduction_ratio": 0.17769014084507043
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 137404416,
        "reduced": 38756352,
        "reduction_ratio": 0.22000558035714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11182
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": {
        "original": 218112000,
        "pruned": 169635840,
        "reduced": 48476160,
        "reduction_ratio": 0.22225352112676056
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 127684608,
        "reduced": 48476160,
        "reduction_ratio": 0.27518136160714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10391
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": {
        "original": 218112000,
        "pruned": 162111488,
        "reduced": 56000512,
        "reduction_ratio": 0.2567511737089202
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 130646016,
        "reduced": 45514752,
        "reduction_ratio": 0.2583705357142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10632
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": {
        "original": 218112000,
        "pruned": 157736960,
        "reduced": 60375040,
        "reduction_ratio": 0.27680751173708923
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 126271488,
        "reduced": 49889280,
        "reduction_ratio": 0.283203125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10276
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": {
        "original": 218112000,
        "pruned": 164024320,
        "reduced": 54087680,
        "reduction_ratio": 0.24798122065727699
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 127315968,
        "reduced": 48844800,
        "reduction_ratio": 0.2772739955357143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10361
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": {
        "original": 218112000,
        "pruned": 152670208,
        "reduced": 65441792,
        "reduction_ratio": 0.300037558685446
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 131690496,
        "reduced": 44470272,
        "reduction_ratio": 0.25244140625,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10717
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": {
        "original": 218112000,
        "pruned": 165773312,
        "reduced": 52338688,
        "reduction_ratio": 0.239962441314554
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 134307840,
        "reduced": 41852928,
        "reduction_ratio": 0.23758370535714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10930
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": {
        "original": 218112000,
        "pruned": 147636224,
        "reduced": 70475776,
        "reduction_ratio": 0.3231173708920188
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 131899392,
        "reduced": 44261376,
        "reduction_ratio": 0.25125558035714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10734
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": {
        "original": 218112000,
        "pruned": 139087872,
        "reduced": 79024128,
        "reduction_ratio": 0.3623098591549296
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 128593920,
        "reduced": 47566848,
        "reduction_ratio": 0.27001953125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10465
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": {
        "original": 218112000,
        "pruned": 155721728,
        "reduced": 62390272,
        "reduction_ratio": 0.2860469483568075
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 124256256,
        "reduced": 51904512,
        "reduction_ratio": 0.29464285714285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10112
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": {
        "original": 218112000,
        "pruned": 141082624,
        "reduced": 77029376,
        "reduction_ratio": 0.3531643192488263
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 120102912,
        "reduced": 56057856,
        "reduction_ratio": 0.31821986607142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9774
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": {
        "original": 218112000,
        "pruned": 138088448,
        "reduced": 80023552,
        "reduction_ratio": 0.36689201877934274
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 106622976,
        "reduced": 69537792,
        "reduction_ratio": 0.39474051339285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8677
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": {
        "original": 218112000,
        "pruned": 126468096,
        "reduced": 91643904,
        "reduction_ratio": 0.420169014084507
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 100245504,
        "reduced": 75915264,
        "reduction_ratio": 0.43094308035714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8158
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": {
        "original": 218112000,
        "pruned": 134418432,
        "reduced": 83693568,
        "reduction_ratio": 0.38371830985915495
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 92467200,
        "reduced": 83693568,
        "reduction_ratio": 0.47509765625,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7525
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": {
        "original": 218112000,
        "pruned": 102567936,
        "reduced": 115544064,
        "reduction_ratio": 0.5297464788732394
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 76345344,
        "reduced": 99815424,
        "reduction_ratio": 0.5666155133928571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6213
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": {
        "original": 218112000,
        "pruned": 100564992,
        "reduced": 117547008,
        "reduction_ratio": 0.5389295774647888
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 58613760,
        "reduced": 117547008,
        "reduction_ratio": 0.6672712053571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 4770
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": {
        "original": 218112000,
        "pruned": 101613568,
        "reduced": 116498432,
        "reduction_ratio": 0.5341220657276995
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 64905216,
        "reduced": 111255552,
        "reduction_ratio": 0.6315569196428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 5282
        }
      },
      "is_zero_layer": false
    }
  ]
}