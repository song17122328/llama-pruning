{
  "model_path": "results/ShortGPT_remove_4/pruned_model.bin",
  "timestamp": "2025-11-26T19:48:17.241582",
  "metrics": {
    "model_info": {
      "total_params": 7157813248,
      "trainable_params": 7157813248,
      "total_params_M": 7157.813248,
      "total_params_B": 7.157813248,
      "attention_params": 1174405120,
      "mlp_params": 4932501504,
      "attention_params_M": 1174.40512,
      "mlp_params_M": 4932.501504,
      "attention_ratio": 0.16407317141560607,
      "mlp_ratio": 0.6891073199455454,
      "num_layers": 28,
      "model_size_mb": 13652.445556640625,
      "model_size_gb": 13.33246636390686
    },
    "ppl_quick_128": {
      "wikitext2 (wikitext-2-raw-v1)": 45.80365753173828,
      "ptb": 70.67324829101562
    },
    "ppl_standard_2048_512": {
      "wikitext2 (wikitext-2-raw-v1)": 18.662338256835938,
      "ptb": 29.919784545898438
    },
    "ppl": {
      "wikitext2 (wikitext-2-raw-v1)": 18.662338256835938,
      "ptb": 29.919784545898438
    },
    "zeroshot": {},
    "efficiency": {
      "model_info": {
        "total_params": 7157813248,
        "trainable_params": 7157813248,
        "total_params_M": 7157.813248,
        "total_params_B": 7.157813248,
        "attention_params": 1174405120,
        "mlp_params": 4932501504,
        "attention_params_M": 1174.40512,
        "mlp_params_M": 4932.501504,
        "attention_ratio": 0.16407317141560607,
        "mlp_ratio": 0.6891073199455454,
        "num_layers": 28,
        "model_size_mb": 13652.445556640625,
        "model_size_gb": 13.33246636390686
      },
      "speed": {
        "batch_size_1": {
          "throughput_tokens_per_sec": 32.41194066737103,
          "latency_ms_per_token": 30.852827057242393,
          "total_time_sec": 197.45809316635132,
          "total_tokens": 6400
        },
        "batch_size_4": {
          "throughput_tokens_per_sec": 122.78160209884669,
          "latency_ms_per_token": 8.14454269129783,
          "total_time_sec": 50.04007029533386,
          "total_tokens": 6144
        }
      },
      "memory": {
        "model_memory_mb": 27313.01708984375,
        "inference_peak_mb": 27427.28857421875
      }
    }
  }
}