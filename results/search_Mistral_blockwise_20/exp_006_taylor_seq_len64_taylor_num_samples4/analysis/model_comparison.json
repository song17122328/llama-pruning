{
  "original_name": "原始模型",
  "pruned_name": "剪枝后模型",
  "total_params": {
    "original": 7248023552,
    "pruned": 5798424576,
    "reduced": 1449598976,
    "reduction_ratio": 0.19999920883259292
  },
  "layer_params": {
    "original": 6979584000,
    "pruned": 5529985024,
    "reduced": 1449598976,
    "reduction_ratio": 0.20769131455399062
  },
  "layers": [
    {
      "layer_idx": 0,
      "total": {
        "original": 218112000,
        "pruned": 78237696,
        "reduced": 139874304,
        "reduction_ratio": 0.6412957746478873
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 67743744,
        "reduced": 108417024,
        "reduction_ratio": 0.6154436383928571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 5513
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": {
        "original": 218112000,
        "pruned": 209551360,
        "reduced": 8560640,
        "reduction_ratio": 0.039248826291079814
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 172843008,
        "reduced": 3317760,
        "reduction_ratio": 0.018833705357142856,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14066
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": {
        "original": 218112000,
        "pruned": 210878464,
        "reduced": 7233536,
        "reduction_ratio": 0.03316431924882629
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174170112,
        "reduced": 1990656,
        "reduction_ratio": 0.011300223214285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14174
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": {
        "original": 218112000,
        "pruned": 217645056,
        "reduced": 466944,
        "reduction_ratio": 0.002140845070422535
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175693824,
        "reduced": 466944,
        "reduction_ratio": 0.002650669642857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14298
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": {
        "original": 218112000,
        "pruned": 211652608,
        "reduced": 6459392,
        "reduction_ratio": 0.029615023474178402
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174944256,
        "reduced": 1216512,
        "reduction_ratio": 0.006905691964285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14237
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": {
        "original": 218112000,
        "pruned": 216637440,
        "reduced": 1474560,
        "reduction_ratio": 0.0067605633802816905
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174686208,
        "reduced": 1474560,
        "reduction_ratio": 0.008370535714285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14216
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": {
        "original": 218112000,
        "pruned": 200216576,
        "reduced": 17895424,
        "reduction_ratio": 0.08204694835680751
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 168751104,
        "reduced": 7409664,
        "reduction_ratio": 0.04206194196428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13733
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": {
        "original": 218112000,
        "pruned": 202448896,
        "reduced": 15663104,
        "reduction_ratio": 0.07181220657276996
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 165740544,
        "reduced": 10420224,
        "reduction_ratio": 0.05915178571428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13488
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": {
        "original": 218112000,
        "pruned": 202850304,
        "reduced": 15261696,
        "reduction_ratio": 0.06997183098591549
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 160899072,
        "reduced": 15261696,
        "reduction_ratio": 0.08663504464285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13094
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": {
        "original": 218112000,
        "pruned": 190087168,
        "reduced": 28024832,
        "reduction_ratio": 0.12848826291079812
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 153378816,
        "reduced": 22781952,
        "reduction_ratio": 0.12932477678571427,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12482
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": {
        "original": 218112000,
        "pruned": 177745920,
        "reduced": 40366080,
        "reduction_ratio": 0.18507042253521128
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 135794688,
        "reduced": 40366080,
        "reduction_ratio": 0.22914341517857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11051
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": {
        "original": 218112000,
        "pruned": 169168896,
        "reduced": 48943104,
        "reduction_ratio": 0.2243943661971831
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 127217664,
        "reduced": 48943104,
        "reduction_ratio": 0.27783203125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10353
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": {
        "original": 218112000,
        "pruned": 165281792,
        "reduced": 52830208,
        "reduction_ratio": 0.24221596244131455
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 133816320,
        "reduced": 42344448,
        "reduction_ratio": 0.24037388392857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10890
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": {
        "original": 218112000,
        "pruned": 176406528,
        "reduced": 41705472,
        "reduction_ratio": 0.1912112676056338
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 134455296,
        "reduced": 41705472,
        "reduction_ratio": 0.23674665178571427,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10942
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": {
        "original": 218112000,
        "pruned": 171417600,
        "reduced": 46694400,
        "reduction_ratio": 0.2140845070422535
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 129466368,
        "reduced": 46694400,
        "reduction_ratio": 0.2650669642857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10536
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": {
        "original": 218112000,
        "pruned": 172896256,
        "reduced": 45215744,
        "reduction_ratio": 0.20730516431924884
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 136187904,
        "reduced": 39972864,
        "reduction_ratio": 0.22691127232142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11083
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": {
        "original": 218112000,
        "pruned": 191004672,
        "reduced": 27107328,
        "reduction_ratio": 0.12428169014084507
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 149053440,
        "reduced": 27107328,
        "reduction_ratio": 0.15387834821428573,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12130
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": {
        "original": 218112000,
        "pruned": 187932672,
        "reduced": 30179328,
        "reduction_ratio": 0.1383661971830986
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 145981440,
        "reduced": 30179328,
        "reduction_ratio": 0.17131696428571427,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11880
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": {
        "original": 218112000,
        "pruned": 184107008,
        "reduced": 34004992,
        "reduction_ratio": 0.155906103286385
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 152641536,
        "reduced": 23519232,
        "reduction_ratio": 0.13351004464285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12422
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": {
        "original": 218112000,
        "pruned": 194338816,
        "reduced": 23773184,
        "reduction_ratio": 0.10899530516431925
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 157630464,
        "reduced": 18530304,
        "reduction_ratio": 0.10518973214285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12828
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": {
        "original": 218112000,
        "pruned": 199110656,
        "reduced": 19001344,
        "reduction_ratio": 0.08711737089201878
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 167645184,
        "reduced": 8515584,
        "reduction_ratio": 0.04833984375,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13643
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": {
        "original": 218112000,
        "pruned": 209723392,
        "reduced": 8388608,
        "reduction_ratio": 0.038460093896713614
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173015040,
        "reduced": 3145728,
        "reduction_ratio": 0.017857142857142856,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14080
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": {
        "original": 218112000,
        "pruned": 195211264,
        "reduced": 22900736,
        "reduction_ratio": 0.10499530516431925
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174231552,
        "reduced": 1929216,
        "reduction_ratio": 0.010951450892857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14179
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": {
        "original": 218112000,
        "pruned": 205082624,
        "reduced": 13029376,
        "reduction_ratio": 0.05973708920187793
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173617152,
        "reduced": 2543616,
        "reduction_ratio": 0.014439174107142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14129
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": {
        "original": 218112000,
        "pruned": 183607296,
        "reduced": 34504704,
        "reduction_ratio": 0.15819718309859154
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173113344,
        "reduced": 3047424,
        "reduction_ratio": 0.017299107142857144,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14088
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": {
        "original": 218112000,
        "pruned": 176779264,
        "reduced": 41332736,
        "reduction_ratio": 0.1895023474178404
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 171528192,
        "reduced": 4632576,
        "reduction_ratio": 0.026297433035714284,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13959
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": {
        "original": 218112000,
        "pruned": 177217536,
        "reduced": 40894464,
        "reduction_ratio": 0.18749295774647887
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 166723584,
        "reduced": 9437184,
        "reduction_ratio": 0.05357142857142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13568
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": {
        "original": 218112000,
        "pruned": 179712000,
        "reduced": 38400000,
        "reduction_ratio": 0.176056338028169
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 153489408,
        "reduced": 22671360,
        "reduction_ratio": 0.12869698660714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12491
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": {
        "original": 218112000,
        "pruned": 127614976,
        "reduced": 90497024,
        "reduction_ratio": 0.4149107981220657
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 122363904,
        "reduced": 53796864,
        "reduction_ratio": 0.30538504464285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9958
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": {
        "original": 218112000,
        "pruned": 105578496,
        "reduced": 112533504,
        "reduction_ratio": 0.515943661971831
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 79355904,
        "reduced": 96804864,
        "reduction_ratio": 0.5495256696428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6458
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": {
        "original": 218112000,
        "pruned": 31268864,
        "reduced": 186843136,
        "reduction_ratio": 0.8566384976525822
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 31260672,
        "reduced": 144900096,
        "reduction_ratio": 0.8225446428571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 2544
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": {
        "original": 218112000,
        "pruned": 8572928,
        "reduced": 209539072,
        "reduction_ratio": 0.9606948356807512
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 8564736,
        "reduced": 167596032,
        "reduction_ratio": 0.9513811383928571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 697
        }
      },
      "is_zero_layer": false
    }
  ]
}