{
  "model_name": "剪枝后模型",
  "total_params": 6092498944,
  "embedding_params": 544997376,
  "lm_head_params": 544997376,
  "layers": [
    {
      "layer_idx": 0,
      "total": 144848384,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 38492160,
        "up_proj": 38492160,
        "down_proj": 38492160,
        "total": 115476480,
        "intermediate_size": 10740
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": 103883264,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 24837120,
        "up_proj": 24837120,
        "down_proj": 24837120,
        "total": 74511360,
        "intermediate_size": 6930
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": 144439808,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 38355968,
        "up_proj": 38355968,
        "down_proj": 38355968,
        "total": 115067904,
        "intermediate_size": 10702
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": 185394176,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 52007424,
        "up_proj": 52007424,
        "down_proj": 52007424,
        "total": 156022272,
        "intermediate_size": 14511
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": 186168320,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 52265472,
        "up_proj": 52265472,
        "down_proj": 52265472,
        "total": 156796416,
        "intermediate_size": 14583
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": 154880000,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 41836032,
        "up_proj": 41836032,
        "down_proj": 41836032,
        "total": 125508096,
        "intermediate_size": 11673
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": 198500864,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56376320,
        "up_proj": 56376320,
        "down_proj": 56376320,
        "total": 169128960,
        "intermediate_size": 15730
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": 209231360,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 59953152,
        "up_proj": 59953152,
        "down_proj": 59953152,
        "total": 179859456,
        "intermediate_size": 16728
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": 209285120,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 59971072,
        "up_proj": 59971072,
        "down_proj": 59971072,
        "total": 179913216,
        "intermediate_size": 16733
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": 213897728,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 61508608,
        "up_proj": 61508608,
        "down_proj": 61508608,
        "total": 184525824,
        "intermediate_size": 17162
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": 207951872,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 59526656,
        "up_proj": 59526656,
        "down_proj": 59526656,
        "total": 178579968,
        "intermediate_size": 16609
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": 209908736,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 60178944,
        "up_proj": 60178944,
        "down_proj": 60178944,
        "total": 180536832,
        "intermediate_size": 16791
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": 205887488,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58838528,
        "up_proj": 58838528,
        "down_proj": 58838528,
        "total": 176515584,
        "intermediate_size": 16417
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": 208145408,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 59591168,
        "up_proj": 59591168,
        "down_proj": 59591168,
        "total": 178773504,
        "intermediate_size": 16627
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": 215553536,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 62060544,
        "up_proj": 62060544,
        "down_proj": 62060544,
        "total": 186181632,
        "intermediate_size": 17316
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": 217908224,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 62845440,
        "up_proj": 62845440,
        "down_proj": 62845440,
        "total": 188536320,
        "intermediate_size": 17535
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": 218252288,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 62960128,
        "up_proj": 62960128,
        "down_proj": 62960128,
        "total": 188880384,
        "intermediate_size": 17567
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": 206661632,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 59096576,
        "up_proj": 59096576,
        "down_proj": 59096576,
        "total": 177289728,
        "intermediate_size": 16489
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": 193888256,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 54838784,
        "up_proj": 54838784,
        "down_proj": 54838784,
        "total": 164516352,
        "intermediate_size": 15301
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": 190727168,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 53785088,
        "up_proj": 53785088,
        "down_proj": 53785088,
        "total": 161355264,
        "intermediate_size": 15007
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": 180190208,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 50272768,
        "up_proj": 50272768,
        "down_proj": 50272768,
        "total": 150818304,
        "intermediate_size": 14027
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": 174545408,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 48391168,
        "up_proj": 48391168,
        "down_proj": 48391168,
        "total": 145173504,
        "intermediate_size": 13502
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": 181147136,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 50591744,
        "up_proj": 50591744,
        "down_proj": 50591744,
        "total": 151775232,
        "intermediate_size": 14116
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": 168879104,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 46502400,
        "up_proj": 46502400,
        "down_proj": 46502400,
        "total": 139507200,
        "intermediate_size": 12975
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": 152998400,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 41208832,
        "up_proj": 41208832,
        "down_proj": 41208832,
        "total": 123626496,
        "intermediate_size": 11498
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": 128881664,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 33169920,
        "up_proj": 33169920,
        "down_proj": 33169920,
        "total": 99509760,
        "intermediate_size": 9255
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": 84948992,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 18525696,
        "up_proj": 18525696,
        "down_proj": 18525696,
        "total": 55577088,
        "intermediate_size": 5169
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": 105496064,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 25374720,
        "up_proj": 25374720,
        "down_proj": 25374720,
        "total": 76124160,
        "intermediate_size": 7080
      },
      "norm": 7168,
      "is_zero_layer": false
    }
  ],
  "layer_summary": {
    "num_layers": 28,
    "total_layer_params": 5002500608
  }
}