{
  "original_name": "原始模型",
  "pruned_name": "剪枝后模型",
  "total_params": {
    "original": 8030261248,
    "pruned": 6424219648,
    "reduced": 1606041600,
    "reduction_ratio": 0.199998673816496
  },
  "layer_params": {
    "original": 6979584000,
    "pruned": 5373542400,
    "reduced": 1606041600,
    "reduction_ratio": 0.2301056338028169
  },
  "layers": [
    {
      "layer_idx": 0,
      "total": {
        "original": 218112000,
        "pruned": 218112000,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176160768,
        "reduced": 0,
        "reduction_ratio": 0.0,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14336
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": {
        "original": 218112000,
        "pruned": 218112000,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176160768,
        "reduced": 0,
        "reduction_ratio": 0.0,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14336
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": {
        "original": 218112000,
        "pruned": 216612864,
        "reduced": 1499136,
        "reduction_ratio": 0.006873239436619718
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174661632,
        "reduced": 1499136,
        "reduction_ratio": 0.008510044642857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14214
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": {
        "original": 218112000,
        "pruned": 213430272,
        "reduced": 4681728,
        "reduction_ratio": 0.021464788732394366
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 171479040,
        "reduced": 4681728,
        "reduction_ratio": 0.026576450892857144,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13955
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": {
        "original": 218112000,
        "pruned": 212840448,
        "reduced": 5271552,
        "reduction_ratio": 0.024169014084507043
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 170889216,
        "reduced": 5271552,
        "reduction_ratio": 0.029924665178571428,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13907
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": {
        "original": 218112000,
        "pruned": 210972672,
        "reduced": 7139328,
        "reduction_ratio": 0.03273239436619718
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 169021440,
        "reduced": 7139328,
        "reduction_ratio": 0.04052734375,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13755
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": {
        "original": 218112000,
        "pruned": 128212992,
        "reduced": 89899008,
        "reduction_ratio": 0.41216901408450707
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 86261760,
        "reduced": 89899008,
        "reduction_ratio": 0.5103236607142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7020
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": {
        "original": 218112000,
        "pruned": 112791552,
        "reduced": 105320448,
        "reduction_ratio": 0.4828732394366197
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 70840320,
        "reduced": 105320448,
        "reduction_ratio": 0.5978655133928571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 5765
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": {
        "original": 218112000,
        "pruned": 150454272,
        "reduced": 67657728,
        "reduction_ratio": 0.31019718309859157
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 108503040,
        "reduced": 67657728,
        "reduction_ratio": 0.38406808035714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8830
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": {
        "original": 218112000,
        "pruned": 148377600,
        "reduced": 69734400,
        "reduction_ratio": 0.31971830985915495
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 106426368,
        "reduced": 69734400,
        "reduction_ratio": 0.39585658482142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8661
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": {
        "original": 218112000,
        "pruned": 91742208,
        "reduced": 126369792,
        "reduction_ratio": 0.5793802816901409
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 49790976,
        "reduced": 126369792,
        "reduction_ratio": 0.7173549107142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 4052
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": {
        "original": 218112000,
        "pruned": 88436736,
        "reduced": 129675264,
        "reduction_ratio": 0.5945352112676057
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 46485504,
        "reduced": 129675264,
        "reduction_ratio": 0.7361188616071429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 3783
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": {
        "original": 218112000,
        "pruned": 94715904,
        "reduced": 123396096,
        "reduction_ratio": 0.5657464788732395
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 52764672,
        "reduced": 123396096,
        "reduction_ratio": 0.7004743303571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 4294
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": {
        "original": 218112000,
        "pruned": 163381248,
        "reduced": 54730752,
        "reduction_ratio": 0.2509295774647887
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 121430016,
        "reduced": 54730752,
        "reduction_ratio": 0.31068638392857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9882
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": {
        "original": 218112000,
        "pruned": 113897472,
        "reduced": 104214528,
        "reduction_ratio": 0.47780281690140847
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 71946240,
        "reduced": 104214528,
        "reduction_ratio": 0.5915876116071429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 5855
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": {
        "original": 218112000,
        "pruned": 186482688,
        "reduced": 31629312,
        "reduction_ratio": 0.14501408450704226
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 144531456,
        "reduced": 31629312,
        "reduction_ratio": 0.17954799107142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11762
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": {
        "original": 218112000,
        "pruned": 188276736,
        "reduced": 29835264,
        "reduction_ratio": 0.1367887323943662
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 146325504,
        "reduced": 29835264,
        "reduction_ratio": 0.16936383928571427,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11908
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": {
        "original": 218112000,
        "pruned": 210198528,
        "reduced": 7913472,
        "reduction_ratio": 0.03628169014084507
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 168247296,
        "reduced": 7913472,
        "reduction_ratio": 0.044921875,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13692
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": {
        "original": 218112000,
        "pruned": 208355328,
        "reduced": 9756672,
        "reduction_ratio": 0.044732394366197185
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 166404096,
        "reduced": 9756672,
        "reduction_ratio": 0.055385044642857144,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13542
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": {
        "original": 218112000,
        "pruned": 176738304,
        "reduced": 41373696,
        "reduction_ratio": 0.1896901408450704
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 134787072,
        "reduced": 41373696,
        "reduction_ratio": 0.23486328125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10969
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": {
        "original": 218112000,
        "pruned": 193327104,
        "reduced": 24784896,
        "reduction_ratio": 0.11363380281690141
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 151375872,
        "reduced": 24784896,
        "reduction_ratio": 0.14069475446428573,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12319
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": {
        "original": 218112000,
        "pruned": 189210624,
        "reduced": 28901376,
        "reduction_ratio": 0.13250704225352114
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 147259392,
        "reduced": 28901376,
        "reduction_ratio": 0.1640625,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11984
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": {
        "original": 218112000,
        "pruned": 200122368,
        "reduced": 17989632,
        "reduction_ratio": 0.08247887323943662
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 158171136,
        "reduced": 17989632,
        "reduction_ratio": 0.10212053571428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12872
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": {
        "original": 218112000,
        "pruned": 153477120,
        "reduced": 64634880,
        "reduction_ratio": 0.2963380281690141
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 111525888,
        "reduced": 64634880,
        "reduction_ratio": 0.36690848214285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9076
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": {
        "original": 218112000,
        "pruned": 163958784,
        "reduced": 54153216,
        "reduction_ratio": 0.24828169014084506
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 122007552,
        "reduced": 54153216,
        "reduction_ratio": 0.30740792410714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9929
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": {
        "original": 218112000,
        "pruned": 93671424,
        "reduced": 124440576,
        "reduction_ratio": 0.5705352112676056
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 51720192,
        "reduced": 124440576,
        "reduction_ratio": 0.7064034598214286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 4209
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": {
        "original": 218112000,
        "pruned": 137060352,
        "reduced": 81051648,
        "reduction_ratio": 0.3716056338028169
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 95109120,
        "reduced": 81051648,
        "reduction_ratio": 0.46010044642857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7740
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": {
        "original": 218112000,
        "pruned": 184123392,
        "reduced": 33988608,
        "reduction_ratio": 0.15583098591549296
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 142172160,
        "reduced": 33988608,
        "reduction_ratio": 0.19294084821428573,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11570
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": {
        "original": 218112000,
        "pruned": 163565568,
        "reduced": 54546432,
        "reduction_ratio": 0.25008450704225355
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 121614336,
        "reduced": 54546432,
        "reduction_ratio": 0.3096400669642857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9897
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": {
        "original": 218112000,
        "pruned": 179159040,
        "reduced": 38952960,
        "reduction_ratio": 0.17859154929577464
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 137207808,
        "reduced": 38952960,
        "reduction_ratio": 0.22112165178571427,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11166
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": {
        "original": 218112000,
        "pruned": 165470208,
        "reduced": 52641792,
        "reduction_ratio": 0.24135211267605633
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 123518976,
        "reduced": 52641792,
        "reduction_ratio": 0.298828125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10052
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": {
        "original": 218112000,
        "pruned": 198254592,
        "reduced": 19857408,
        "reduction_ratio": 0.09104225352112676
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 156303360,
        "reduced": 19857408,
        "reduction_ratio": 0.11272321428571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12720
        }
      },
      "is_zero_layer": false
    }
  ]
}