{
  "original_name": "原始模型",
  "pruned_name": "剪枝后模型",
  "total_params": {
    "original": 8030261248,
    "pruned": 6424219648,
    "reduced": 1606041600,
    "reduction_ratio": 0.199998673816496
  },
  "layer_params": {
    "original": 6979584000,
    "pruned": 5373542400,
    "reduced": 1606041600,
    "reduction_ratio": 0.2301056338028169
  },
  "layers": [
    {
      "layer_idx": 0,
      "total": {
        "original": 218112000,
        "pruned": 218112000,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176160768,
        "reduced": 0,
        "reduction_ratio": 0.0,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14336
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": {
        "original": 218112000,
        "pruned": 218112000,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176160768,
        "reduced": 0,
        "reduction_ratio": 0.0,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14336
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": {
        "original": 218112000,
        "pruned": 216489984,
        "reduced": 1622016,
        "reduction_ratio": 0.007436619718309859
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174538752,
        "reduced": 1622016,
        "reduction_ratio": 0.009207589285714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14204
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": {
        "original": 218112000,
        "pruned": 214622208,
        "reduced": 3489792,
        "reduction_ratio": 0.016
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 172670976,
        "reduced": 3489792,
        "reduction_ratio": 0.019810267857142856,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14052
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": {
        "original": 218112000,
        "pruned": 215408640,
        "reduced": 2703360,
        "reduction_ratio": 0.012394366197183098
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173457408,
        "reduced": 2703360,
        "reduction_ratio": 0.015345982142857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14116
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": {
        "original": 218112000,
        "pruned": 212054016,
        "reduced": 6057984,
        "reduction_ratio": 0.027774647887323943
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 170102784,
        "reduced": 6057984,
        "reduction_ratio": 0.034388950892857144,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13843
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": {
        "original": 218112000,
        "pruned": 207212544,
        "reduced": 10899456,
        "reduction_ratio": 0.04997183098591549
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 165261312,
        "reduced": 10899456,
        "reduction_ratio": 0.06187220982142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13449
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": {
        "original": 218112000,
        "pruned": 201154560,
        "reduced": 16957440,
        "reduction_ratio": 0.07774647887323943
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 159203328,
        "reduced": 16957440,
        "reduction_ratio": 0.09626116071428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12956
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": {
        "original": 218112000,
        "pruned": 200515584,
        "reduced": 17596416,
        "reduction_ratio": 0.08067605633802817
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 158564352,
        "reduced": 17596416,
        "reduction_ratio": 0.09988839285714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12904
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": {
        "original": 218112000,
        "pruned": 199360512,
        "reduced": 18751488,
        "reduction_ratio": 0.08597183098591549
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 157409280,
        "reduced": 18751488,
        "reduction_ratio": 0.1064453125,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12810
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": {
        "original": 218112000,
        "pruned": 189825024,
        "reduced": 28286976,
        "reduction_ratio": 0.1296901408450704
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 147873792,
        "reduced": 28286976,
        "reduction_ratio": 0.16057477678571427,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12034
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": {
        "original": 218112000,
        "pruned": 192983040,
        "reduced": 25128960,
        "reduction_ratio": 0.1152112676056338
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 151031808,
        "reduced": 25128960,
        "reduction_ratio": 0.14264787946428573,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12291
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": {
        "original": 218112000,
        "pruned": 188571648,
        "reduced": 29540352,
        "reduction_ratio": 0.13543661971830986
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 146620416,
        "reduced": 29540352,
        "reduction_ratio": 0.16768973214285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11932
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": {
        "original": 218112000,
        "pruned": 182710272,
        "reduced": 35401728,
        "reduction_ratio": 0.16230985915492957
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 140759040,
        "reduced": 35401728,
        "reduction_ratio": 0.20096261160714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11455
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": {
        "original": 218112000,
        "pruned": 175546368,
        "reduced": 42565632,
        "reduction_ratio": 0.19515492957746478
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 133595136,
        "reduced": 42565632,
        "reduction_ratio": 0.24162946428571427,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10872
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": {
        "original": 218112000,
        "pruned": 177463296,
        "reduced": 40648704,
        "reduction_ratio": 0.1863661971830986
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 135512064,
        "reduced": 40648704,
        "reduction_ratio": 0.23074776785714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11028
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": {
        "original": 218112000,
        "pruned": 169672704,
        "reduced": 48439296,
        "reduction_ratio": 0.22208450704225352
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 127721472,
        "reduced": 48439296,
        "reduction_ratio": 0.2749720982142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10394
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": {
        "original": 218112000,
        "pruned": 167157760,
        "reduced": 50954240,
        "reduction_ratio": 0.2336150234741784
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 130449408,
        "reduced": 45711360,
        "reduction_ratio": 0.25948660714285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10616
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": {
        "original": 218112000,
        "pruned": 156213248,
        "reduced": 61898752,
        "reduction_ratio": 0.28379342723004697
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 124747776,
        "reduced": 51412992,
        "reduction_ratio": 0.29185267857142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10152
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": {
        "original": 218112000,
        "pruned": 148074496,
        "reduced": 70037504,
        "reduction_ratio": 0.32110798122065726
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 111366144,
        "reduced": 64794624,
        "reduction_ratio": 0.36781529017857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9063
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": {
        "original": 218112000,
        "pruned": 148336640,
        "reduced": 69775360,
        "reduction_ratio": 0.31990610328638497
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 116871168,
        "reduced": 59289600,
        "reduction_ratio": 0.33656529017857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9511
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": {
        "original": 218112000,
        "pruned": 151212032,
        "reduced": 66899968,
        "reduction_ratio": 0.30672300469483565
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 119746560,
        "reduced": 56414208,
        "reduction_ratio": 0.3202427455357143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9745
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": {
        "original": 218112000,
        "pruned": 131342336,
        "reduced": 86769664,
        "reduction_ratio": 0.39782159624413144
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 115605504,
        "reduced": 60555264,
        "reduction_ratio": 0.34375,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9408
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": {
        "original": 218112000,
        "pruned": 104427520,
        "reduced": 113684480,
        "reduction_ratio": 0.5212206572769953
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 99176448,
        "reduced": 76984320,
        "reduction_ratio": 0.43701171875,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8071
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": {
        "original": 218112000,
        "pruned": 134807552,
        "reduced": 83304448,
        "reduction_ratio": 0.3819342723004695
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 103342080,
        "reduced": 72818688,
        "reduction_ratio": 0.41336495535714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8410
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": {
        "original": 218112000,
        "pruned": 111185920,
        "reduced": 106926080,
        "reduction_ratio": 0.49023474178403753
      },
      "attention": {
        "original": 41943040,
        "pruned": 20971520,
        "reduced": 20971520,
        "reduction_ratio": 0.5
      },
      "mlp": {
        "original": 176160768,
        "pruned": 90206208,
        "reduced": 85954560,
        "reduction_ratio": 0.48793247767857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7341
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": {
        "original": 218112000,
        "pruned": 121475072,
        "reduced": 96636928,
        "reduction_ratio": 0.4430610328638498
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 90009600,
        "reduced": 86151168,
        "reduction_ratio": 0.48904854910714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7325
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": {
        "original": 218112000,
        "pruned": 129155072,
        "reduced": 88956928,
        "reduction_ratio": 0.407849765258216
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 97689600,
        "reduced": 78471168,
        "reduction_ratio": 0.44545200892857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7950
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": {
        "original": 218112000,
        "pruned": 128458752,
        "reduced": 89653248,
        "reduction_ratio": 0.4110422535211268
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 86507520,
        "reduced": 89653248,
        "reduction_ratio": 0.5089285714285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7040
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": {
        "original": 218112000,
        "pruned": 111108096,
        "reduced": 107003904,
        "reduction_ratio": 0.49059154929577464
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 84885504,
        "reduced": 91275264,
        "reduction_ratio": 0.5181361607142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6908
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": {
        "original": 218112000,
        "pruned": 107298816,
        "reduced": 110813184,
        "reduction_ratio": 0.508056338028169
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 65347584,
        "reduced": 110813184,
        "reduction_ratio": 0.6290457589285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 5318
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": {
        "original": 218112000,
        "pruned": 143474688,
        "reduced": 74637312,
        "reduction_ratio": 0.34219718309859154
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 101523456,
        "reduced": 74637312,
        "reduction_ratio": 0.42368861607142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8262
        }
      },
      "is_zero_layer": false
    }
  ]
}