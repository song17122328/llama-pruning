{
  "base_model": [
    "/newdata/LLMs/Llama-3-8B",
    "/newdata/LLMs/Llama-3-8B-Instruct",
    "/newdata/LLMs/Mistral-7B-v0.3",
    "/newdata/LLMs/Mistral-7B-Instruct-v0.3",
    "/newdata/LLMs/Qwen2.5-7B",
    "/newdata/LLMs/Qwen2.5-7B-Instruct"
  ],
  "pruning_ratio": 0.2,
  "output_base": "search_all_model_blockwise_128_128",
  "taylor_seq_len": 128,
  "taylor_num_samples": 128,
  "layer_importance_num_samples": 128,
  "layer_importance_seq_len": 128,
  "block_importance_num_samples": 128,
  "block_importance_seq_len": 128,
  "other_args": {
    "dataset": "wikitext2",
    "temperature": 1.0,
    "tau": -100,
    "importance_method": "taylor",
    "gradient_batch_size": 8,
    "run_evaluation": "ppl,zeroshot",
    "eval_ppl_datasets": "wikitext2,ptb",
    "eval_zeroshot_tasks": "boolq,piqa,hellaswag,winogrande,arc_easy,arc_challenge,openbookqa"
  }
}