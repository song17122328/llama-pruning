{
  "model": "Llama",
  "method": "LLM-Pruner",
  "lora_config": {
    "lora_r": 8,
    "lora_alpha": 16,
    "lora_dropout": 0.05,
    "num_epochs": 2,
    "learning_rate": 0.0001,
    "batch_size": 64,
    "micro_batch_size": 4
  },
  "pruned_model_path": "results/all_model_blockwise_128_128_8/Llama/LLM-Pruner/pruned_model.bin"
}