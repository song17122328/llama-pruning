# å®éªŒç»“æœæ€»ç»“

## ğŸ“Š æ•°æ®å®Œæ•´æ€§

æ‰€æœ‰135ä¸ªå®éªŒå…¨éƒ¨æœ‰æ•ˆï¼ˆ100%å®Œæ•´ç‡ï¼‰ï¼š

| æ¨¡å‹ | Taylor | Layerwise | Blockwise | æ€»è®¡ |
|------|--------|-----------|-----------|------|
| Llama | 15 | 15 | 15 | **45** |
| Qwen | 15 | 15 | 15 | **45** |
| Mistral | 15 | 15 | 15 | **45** |
| **æ€»è®¡** | 45 | 45 | 45 | **135** |

## ğŸ† æœ€ä½³ç»“æœ

### æ€»ä½“å† å†›ï¼šQwen + Layerwise

- **ACC**: 0.6161 (æœ€é«˜)
- **PPL**: 10.80 (æœ€ä½)
- **å‚æ•°**:
  - taylor_seq_len: 128
  - taylor_num_samples: 512
- **ç»“æœç›®å½•**: `results/best_Qwen_20/`

### å„æ¨¡å‹æœ€ä½³é…ç½®

#### 1. Llama (äºšå†›)
- **å‰ªææ–¹æ³•**: Blockwise
- **ACC**: 0.5980
- **PPL**: 13.17
- **å‚æ•°**:
  - taylor_seq_len: 64
  - taylor_num_samples: 128
- **ç»“æœç›®å½•**: `results/best_Llama_20/`

#### 2. Mistral (å­£å†›)
- **å‰ªææ–¹æ³•**: Blockwise
- **ACC**: 0.5947
- **PPL**: 13.29
- **å‚æ•°**:
  - taylor_seq_len: 64
  - taylor_num_samples: 128
- **ç»“æœç›®å½•**: `results/best_Mistral_20/`

## ğŸ“ ç›®å½•ç»“æ„

```
results/
â”œâ”€â”€ consolidated_Llama_20/          # Llamaæ±‡æ€»ç»“æœï¼ˆ45ä¸ªå®éªŒï¼‰
â”‚   â”œâ”€â”€ all_methods_results.csv     # æ‰€æœ‰æ–¹æ³•çš„å®Œæ•´æ•°æ®
â”‚   â”œâ”€â”€ global_best_config.json     # å…¨å±€æœ€ä½³é…ç½®
â”‚   â””â”€â”€ method_comparison.json      # æ–¹æ³•å¯¹æ¯”ç»Ÿè®¡
â”‚
â”œâ”€â”€ consolidated_Qwen_20/           # Qwenæ±‡æ€»ç»“æœï¼ˆ45ä¸ªå®éªŒï¼‰
â”‚   â”œâ”€â”€ all_methods_results.csv
â”‚   â”œâ”€â”€ global_best_config.json
â”‚   â””â”€â”€ method_comparison.json
â”‚
â”œâ”€â”€ consolidated_Mistral_20/        # Mistralæ±‡æ€»ç»“æœï¼ˆ45ä¸ªå®éªŒï¼‰
â”‚   â”œâ”€â”€ all_methods_results.csv
â”‚   â”œâ”€â”€ global_best_config.json
â”‚   â””â”€â”€ method_comparison.json
â”‚
â”œâ”€â”€ best_Llama_20/                  # Llamaæœ€ä½³å®éªŒå®Œæ•´ç»“æœ
â”‚   â”œâ”€â”€ best_config.json
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â””â”€â”€ evaluation_results.json
â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â”œâ”€â”€ gradient_diagnosis.json
â”‚   â”‚   â”œâ”€â”€ pruning_comparison.json
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ visualization/
â”‚       â”œâ”€â”€ gradient_analysis.png
â”‚       â”œâ”€â”€ pruning_ratio.png
â”‚       â””â”€â”€ retention_ratio.png
â”‚
â”œâ”€â”€ best_Qwen_20/                   # Qwenæœ€ä½³å®éªŒå®Œæ•´ç»“æœï¼ˆæ€»å† å†›ï¼‰
â”‚   â””â”€â”€ (ç»“æ„åŒä¸Š)
â”‚
â”œâ”€â”€ best_Mistral_20/                # Mistralæœ€ä½³å®éªŒå®Œæ•´ç»“æœ
â”‚   â””â”€â”€ (ç»“æ„åŒä¸Š)
â”‚
â”œâ”€â”€ cross_model_comparison.json     # è·¨æ¨¡å‹å¯¹æ¯”
â””â”€â”€ final_analysis_report.txt       # å®Œæ•´åˆ†ææŠ¥å‘Š
```

## ğŸ” å…³é”®å‘ç°

### 1. å‰ªææ–¹æ³•å¯¹æ¯”

- **Blockwise**: Llamaå’ŒMistralçš„æœ€ä½³é€‰æ‹©
- **Layerwise**: Qwençš„æœ€ä½³é€‰æ‹©ï¼ˆè·å¾—å…¨å±€æœ€é«˜ACCï¼‰
- **Taylor**: æ–¹å·®è¾ƒå¤§ï¼Œæ€§èƒ½ä¸å¤Ÿç¨³å®š

### 2. Taylorå‚æ•°å½±å“

| æ¨¡å‹ | æœ€ä½³seq_len | æœ€ä½³num_samples | è¶‹åŠ¿ |
|------|-------------|-----------------|------|
| Llama | 256 | 512 | seq_lenè¶Šå¤§è¶Šå¥½ |
| Qwen | 128 | 512 | ä¸­ç­‰seq_lenæœ€ä½³ |
| Mistral | 64 | 128 | è¾ƒå°å‚æ•°å³å¯ |

### 3. æ¢¯åº¦æŒ‡æ ‡ç›¸å…³æ€§

- **grad_mean_ratio** ä¸ ACC å‘ˆä¸­ç­‰æ­£ç›¸å…³ï¼ˆ0.697ï¼‰
- **PPL** ä¸ ACC å‘ˆå¼ºè´Ÿç›¸å…³ï¼ˆ-0.5 ~ -0.8ï¼‰
- PPLè¶Šä½ï¼ŒACCé€šå¸¸è¶Šé«˜

### 4. æç«¯å‰ªæå½±å“

- **æœ€ä¼˜èŒƒå›´**: 3-5å±‚æç«¯å‰ªæ
- **è´Ÿé¢å½±å“**: è¶…è¿‡6å±‚ä¼šæ˜¾è‘—é™ä½æ€§èƒ½
- ä¸ACCå‘ˆå¼±åˆ°ä¸­ç­‰è´Ÿç›¸å…³ï¼ˆ-0.13 ~ -0.29ï¼‰

## ğŸ“ˆ å„ä»»åŠ¡è¯¦ç»†è¡¨ç°

### Qwen Layerwise (æœ€ä½³)
| ä»»åŠ¡ | ACC |
|------|-----|
| BoolQ | 0.7618 |
| PIQA | 0.7465 |
| HellaSwag | 0.6579 |
| WinoGrande | 0.6259 |
| ARC-Easy | 0.6940 |
| ARC-Challenge | 0.4505 |
| OpenBookQA | 0.3760 |

### Llama Blockwise
| ä»»åŠ¡ | ACC |
|------|-----|
| BoolQ | 0.7324 |
| PIQA | 0.7301 |
| HellaSwag | 0.6476 |
| WinoGrande | 0.6953 |
| ARC-Easy | 0.5981 |
| ARC-Challenge | 0.3968 |
| OpenBookQA | 0.3860 |

### Mistral Blockwise
| ä»»åŠ¡ | ACC |
|------|-----|
| BoolQ | 0.6875 |
| PIQA | 0.7693 |
| HellaSwag | 0.6377 |
| WinoGrande | 0.6440 |
| ARC-Easy | 0.6503 |
| ARC-Challenge | 0.3959 |
| OpenBookQA | 0.3780 |

## ğŸ› ï¸ ä½¿ç”¨å·¥å…·

### 1. æ±‡æ€»ç»“æœ
```bash
python param_search/consolidate_model_results.py --model Llama
python param_search/consolidate_model_results.py --model Qwen
python param_search/consolidate_model_results.py --model Mistral
```

### 2. åˆ†æç»“æœ
```bash
# åˆ†æå•ä¸ªæ¨¡å‹
python param_search/analyze_consolidated_results.py --model Llama

# åˆ†ææ‰€æœ‰æ¨¡å‹å¹¶è¿›è¡Œè·¨æ¨¡å‹å¯¹æ¯”
python param_search/analyze_consolidated_results.py --all
```

### 3. å¤åˆ¶æœ€ä½³ç»“æœ
```bash
# å¤åˆ¶å•ä¸ªæ¨¡å‹çš„æœ€ä½³ç»“æœ
python param_search/copy_best_results.py --model Llama

# å¤åˆ¶æ‰€æœ‰æ¨¡å‹çš„æœ€ä½³ç»“æœ
python param_search/copy_best_results.py --all
```

## ğŸ“ æ•°æ®è¯´æ˜

### CSVæ–‡ä»¶å­—æ®µ

- `output_dir`: å®éªŒè¾“å‡ºç›®å½•
- `ppl`: Perplexity (WikiText2)
- `acc_mean`: å¹³å‡å‡†ç¡®ç‡ï¼ˆ7ä¸ªzero-shotä»»åŠ¡ï¼‰
- `acc_*`: å„ä¸ªä»»åŠ¡çš„è¯¦ç»†å‡†ç¡®ç‡
- `params_count`: æ¨¡å‹å‚æ•°æ•°é‡
- `pruning_ratio`: å‰ªææ¯”ç‡
- `grad_mean_ratio`: æ¢¯åº¦å‡å€¼æ¯”ç‡
- `grad_norm_ratio`: æ¢¯åº¦èŒƒæ•°æ¯”ç‡
- `extreme_pruning_layers`: æç«¯å‰ªæå±‚æ•°
- `pruning_method`: å‰ªææ–¹æ³•ï¼ˆtaylor/layerwise/blockwiseï¼‰

### JSONé…ç½®æ–‡ä»¶

- `global_best_config.json`: åŒ…å«æ¨¡å‹å…¨å±€æœ€ä½³é…ç½®çš„å®Œæ•´ä¿¡æ¯
- `method_comparison.json`: æ¯ç§å‰ªææ–¹æ³•çš„ç»Ÿè®¡å’Œæœ€ä½³é…ç½®
- `cross_model_comparison.json`: æ‰€æœ‰æ¨¡å‹çš„è·¨æ¨¡å‹å¯¹æ¯”

## ğŸ¯ å»ºè®®

åŸºäºå®éªŒç»“æœï¼Œå»ºè®®ï¼š

1. **Qwenæ¨¡å‹**: ä¼˜å…ˆä½¿ç”¨Layerwiseæ–¹æ³•ï¼Œseq_len=128, samples=512
2. **Llamaæ¨¡å‹**: ä¼˜å…ˆä½¿ç”¨Blockwiseæ–¹æ³•ï¼Œseq_len=64, samples=128
3. **Mistralæ¨¡å‹**: ä¼˜å…ˆä½¿ç”¨Blockwiseæ–¹æ³•ï¼Œseq_len=64, samples=128
4. **é€šç”¨åŸåˆ™**:
   - æ§åˆ¶æç«¯å‰ªæå±‚æ•°åœ¨3-5å±‚
   - ç›‘æ§PPLæŒ‡æ ‡ï¼Œä¿æŒåœ¨è¾ƒä½æ°´å¹³
   - è¾ƒå¤§çš„seq_lené€šå¸¸å¸¦æ¥æ›´å¥½çš„æ€§èƒ½
