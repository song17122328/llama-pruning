================================================================================
微调前后性能对比
================================================================================

模型: Llama-Instruct
配置: best_ppl (best_ppl)
剪枝方法: layerwise

--------------------------------------------------------------------------------
PPL:
  WikiText2:
    微调前: 13.20
    微调后: 11.28
    变化: -1.92 (-14.56%)
  PTB:
    微调前: 18.62
    微调后: 16.30
    变化: -2.32 (-12.47%)

--------------------------------------------------------------------------------
Zero-shot ACC:
  boolq          : 0.8211 → 0.8229 (+0.0018)
  piqa           : 0.7399 → 0.7535 (+0.0136)
  hellaswag      : 0.6466 → 0.6994 (+0.0528)
  winogrande     : 0.6843 → 0.6946 (+0.0103)
  arc_easy       : 0.6679 → 0.6978 (+0.0299)
  arc_challenge  : 0.4369 → 0.4744 (+0.0375)
  openbookqa     : 0.3760 → 0.3980 (+0.0220)

  平均             : 0.6247 → 0.6487 (+0.0240)

================================================================================