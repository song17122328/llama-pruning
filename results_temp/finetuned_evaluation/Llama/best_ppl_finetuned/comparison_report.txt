================================================================================
微调前后性能对比
================================================================================

模型: Llama
配置: best_ppl (best_ppl)
剪枝方法: blockwise

--------------------------------------------------------------------------------
PPL:
  WikiText2:
    微调前: 11.82
    微调后: 10.18
    变化: -1.65 (-13.94%)
  PTB:
    微调前: 16.96
    微调后: 14.80
    变化: -2.16 (-12.74%)

--------------------------------------------------------------------------------
Zero-shot ACC:
  boolq          : 0.6306 → 0.7599 (+0.1294)
  piqa           : 0.7361 → 0.7682 (+0.0321)
  hellaswag      : 0.6226 → 0.6926 (+0.0700)
  winogrande     : 0.6709 → 0.6803 (+0.0095)
  arc_easy       : 0.5694 → 0.6810 (+0.1115)
  arc_challenge  : 0.3797 → 0.4317 (+0.0520)
  openbookqa     : 0.3560 → 0.4040 (+0.0480)

  平均             : 0.5665 → 0.6311 (+0.0646)

================================================================================