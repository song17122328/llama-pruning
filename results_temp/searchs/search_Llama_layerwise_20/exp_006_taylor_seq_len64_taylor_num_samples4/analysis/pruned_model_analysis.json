{
  "model_name": "剪枝后模型",
  "total_params": 6424211456,
  "embedding_params": 525336576,
  "lm_head_params": 525336576,
  "layers": [
    {
      "layer_idx": 0,
      "total": 212869120,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58720256,
        "up_proj": 58720256,
        "down_proj": 58720256,
        "total": 176160768,
        "intermediate_size": 14336
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": 218112000,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58720256,
        "up_proj": 58720256,
        "down_proj": 58720256,
        "total": 176160768,
        "intermediate_size": 14336
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": 207515648,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58683392,
        "up_proj": 58683392,
        "down_proj": 58683392,
        "total": 176050176,
        "intermediate_size": 14327
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": 217804800,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58617856,
        "up_proj": 58617856,
        "down_proj": 58617856,
        "total": 175853568,
        "intermediate_size": 14311
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": 216662016,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58236928,
        "up_proj": 58236928,
        "down_proj": 58236928,
        "total": 174710784,
        "intermediate_size": 14218
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": 202096640,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56877056,
        "up_proj": 56877056,
        "down_proj": 56877056,
        "total": 170631168,
        "intermediate_size": 13886
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": 189796352,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 52776960,
        "up_proj": 52776960,
        "down_proj": 52776960,
        "total": 158330880,
        "intermediate_size": 12885
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": 168435712,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 43909120,
        "up_proj": 43909120,
        "down_proj": 43909120,
        "total": 131727360,
        "intermediate_size": 10720
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": 129302528,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 32612352,
        "up_proj": 32612352,
        "down_proj": 32612352,
        "total": 97837056,
        "intermediate_size": 7962
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": 120197120,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 29577216,
        "up_proj": 29577216,
        "down_proj": 29577216,
        "total": 88731648,
        "intermediate_size": 7221
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": 96550912,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 8388608,
        "k_proj": 2097152,
        "v_proj": 2097152,
        "o_proj": 8388608,
        "total": 20971520,
        "num_heads": 16,
        "num_kv_heads": 4
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 25190400,
        "up_proj": 25190400,
        "down_proj": 25190400,
        "total": 75571200,
        "intermediate_size": 6150
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": 105410560,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 22900736,
        "up_proj": 22900736,
        "down_proj": 22900736,
        "total": 68702208,
        "intermediate_size": 5591
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": 104448000,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 20832256,
        "up_proj": 20832256,
        "down_proj": 20832256,
        "total": 62496768,
        "intermediate_size": 5086
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": 104849408,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 24461312,
        "up_proj": 24461312,
        "down_proj": 24461312,
        "total": 73383936,
        "intermediate_size": 5972
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": 115007488,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 26099712,
        "up_proj": 26099712,
        "down_proj": 26099712,
        "total": 78299136,
        "intermediate_size": 6372
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": 131788800,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 10485760,
        "k_proj": 2621440,
        "v_proj": 2621440,
        "o_proj": 10485760,
        "total": 26214400,
        "num_heads": 20,
        "num_kv_heads": 5
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 35188736,
        "up_proj": 35188736,
        "down_proj": 35188736,
        "total": 105566208,
        "intermediate_size": 8591
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": 166445056,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 43245568,
        "up_proj": 43245568,
        "down_proj": 43245568,
        "total": 129736704,
        "intermediate_size": 10558
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": 179691520,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 47661056,
        "up_proj": 47661056,
        "down_proj": 47661056,
        "total": 142983168,
        "intermediate_size": 11636
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": 182222848,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 8388608,
        "k_proj": 2097152,
        "v_proj": 2097152,
        "o_proj": 8388608,
        "total": 20971520,
        "num_heads": 16,
        "num_kv_heads": 4
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 53747712,
        "up_proj": 53747712,
        "down_proj": 53747712,
        "total": 161243136,
        "intermediate_size": 13122
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": 174649344,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 4194304,
        "k_proj": 1048576,
        "v_proj": 1048576,
        "o_proj": 4194304,
        "total": 10485760,
        "num_heads": 8,
        "num_kv_heads": 2
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 54718464,
        "up_proj": 54718464,
        "down_proj": 54718464,
        "total": 164155392,
        "intermediate_size": 13359
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": 176676864,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 4194304,
        "k_proj": 1048576,
        "v_proj": 1048576,
        "o_proj": 4194304,
        "total": 10485760,
        "num_heads": 8,
        "num_kv_heads": 2
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 55394304,
        "up_proj": 55394304,
        "down_proj": 55394304,
        "total": 166182912,
        "intermediate_size": 13524
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": 190087168,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 8388608,
        "k_proj": 2097152,
        "v_proj": 2097152,
        "o_proj": 8388608,
        "total": 20971520,
        "num_heads": 16,
        "num_kv_heads": 4
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56369152,
        "up_proj": 56369152,
        "down_proj": 56369152,
        "total": 169107456,
        "intermediate_size": 13762
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": 180338688,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 4194304,
        "k_proj": 1048576,
        "v_proj": 1048576,
        "o_proj": 4194304,
        "total": 10485760,
        "num_heads": 8,
        "num_kv_heads": 2
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56614912,
        "up_proj": 56614912,
        "down_proj": 56614912,
        "total": 169844736,
        "intermediate_size": 13822
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": 171065344,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 2097152,
        "k_proj": 524288,
        "v_proj": 524288,
        "o_proj": 2097152,
        "total": 5242880,
        "num_heads": 4,
        "num_kv_heads": 1
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 55271424,
        "up_proj": 55271424,
        "down_proj": 55271424,
        "total": 165814272,
        "intermediate_size": 13494
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": 182976512,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 6291456,
        "k_proj": 1572864,
        "v_proj": 1572864,
        "o_proj": 6291456,
        "total": 15728640,
        "num_heads": 12,
        "num_kv_heads": 3
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 55746560,
        "up_proj": 55746560,
        "down_proj": 55746560,
        "total": 167239680,
        "intermediate_size": 13610
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": 164306944,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 2097152,
        "k_proj": 524288,
        "v_proj": 524288,
        "o_proj": 2097152,
        "total": 5242880,
        "num_heads": 4,
        "num_kv_heads": 1
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 53018624,
        "up_proj": 53018624,
        "down_proj": 53018624,
        "total": 159055872,
        "intermediate_size": 12944
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": 164241408,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 4194304,
        "k_proj": 1048576,
        "v_proj": 1048576,
        "o_proj": 4194304,
        "total": 10485760,
        "num_heads": 8,
        "num_kv_heads": 2
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 51249152,
        "up_proj": 51249152,
        "down_proj": 51249152,
        "total": 153747456,
        "intermediate_size": 12512
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": 176824320,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 10485760,
        "k_proj": 2621440,
        "v_proj": 2621440,
        "o_proj": 10485760,
        "total": 26214400,
        "num_heads": 20,
        "num_kv_heads": 5
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 50200576,
        "up_proj": 50200576,
        "down_proj": 50200576,
        "total": 150601728,
        "intermediate_size": 12256
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": 158998528,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 8388608,
        "k_proj": 2097152,
        "v_proj": 2097152,
        "o_proj": 8388608,
        "total": 20971520,
        "num_heads": 16,
        "num_kv_heads": 4
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 46006272,
        "up_proj": 46006272,
        "down_proj": 46006272,
        "total": 138018816,
        "intermediate_size": 11232
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": 168996864,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 10485760,
        "k_proj": 2621440,
        "v_proj": 2621440,
        "o_proj": 10485760,
        "total": 26214400,
        "num_heads": 20,
        "num_kv_heads": 5
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 47591424,
        "up_proj": 47591424,
        "down_proj": 47591424,
        "total": 142774272,
        "intermediate_size": 11619
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": 178884608,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 49139712,
        "up_proj": 49139712,
        "down_proj": 49139712,
        "total": 147419136,
        "intermediate_size": 11997
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": 216281088,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58109952,
        "up_proj": 58109952,
        "down_proj": 58109952,
        "total": 174329856,
        "intermediate_size": 14187
      },
      "norm": 8192,
      "is_zero_layer": false
    }
  ],
  "layer_summary": {
    "num_layers": 32,
    "total_layer_params": 5373534208
  }
}