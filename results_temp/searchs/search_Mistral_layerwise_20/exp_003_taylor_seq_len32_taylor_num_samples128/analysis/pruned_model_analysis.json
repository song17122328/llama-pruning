{
  "model_name": "剪枝后模型",
  "total_params": 5798424576,
  "embedding_params": 134217728,
  "lm_head_params": 134217728,
  "layers": [
    {
      "layer_idx": 0,
      "total": 202272768,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 10485760,
        "k_proj": 2621440,
        "v_proj": 2621440,
        "o_proj": 10485760,
        "total": 26214400,
        "num_heads": 20,
        "num_kv_heads": 5
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58683392,
        "up_proj": 58683392,
        "down_proj": 58683392,
        "total": 176050176,
        "intermediate_size": 14327
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": 218112000,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58720256,
        "up_proj": 58720256,
        "down_proj": 58720256,
        "total": 176160768,
        "intermediate_size": 14336
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": 211800064,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58363904,
        "up_proj": 58363904,
        "down_proj": 58363904,
        "total": 175091712,
        "intermediate_size": 14249
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": 217387008,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58478592,
        "up_proj": 58478592,
        "down_proj": 58478592,
        "total": 175435776,
        "intermediate_size": 14277
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": 211517440,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58269696,
        "up_proj": 58269696,
        "down_proj": 58269696,
        "total": 174809088,
        "intermediate_size": 14226
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": 211763200,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58351616,
        "up_proj": 58351616,
        "down_proj": 58351616,
        "total": 175054848,
        "intermediate_size": 14246
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": 192307200,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 10485760,
        "k_proj": 2621440,
        "v_proj": 2621440,
        "o_proj": 10485760,
        "total": 26214400,
        "num_heads": 20,
        "num_kv_heads": 5
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 55361536,
        "up_proj": 55361536,
        "down_proj": 55361536,
        "total": 166084608,
        "intermediate_size": 13516
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": 194633728,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 52641792,
        "up_proj": 52641792,
        "down_proj": 52641792,
        "total": 157925376,
        "intermediate_size": 12852
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": 188866560,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 48971776,
        "up_proj": 48971776,
        "down_proj": 48971776,
        "total": 146915328,
        "intermediate_size": 11956
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": 138371072,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 35635200,
        "up_proj": 35635200,
        "down_proj": 35635200,
        "total": 106905600,
        "intermediate_size": 8700
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": 113348608,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 25546752,
        "up_proj": 25546752,
        "down_proj": 25546752,
        "total": 76640256,
        "intermediate_size": 6237
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": 86913024,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 10485760,
        "k_proj": 2621440,
        "v_proj": 2621440,
        "o_proj": 10485760,
        "total": 26214400,
        "num_heads": 20,
        "num_kv_heads": 5
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 20230144,
        "up_proj": 20230144,
        "down_proj": 20230144,
        "total": 60690432,
        "intermediate_size": 4939
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": 82698240,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 10485760,
        "k_proj": 2621440,
        "v_proj": 2621440,
        "o_proj": 10485760,
        "total": 26214400,
        "num_heads": 20,
        "num_kv_heads": 5
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 18825216,
        "up_proj": 18825216,
        "down_proj": 18825216,
        "total": 56475648,
        "intermediate_size": 4596
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": 98623488,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 18890752,
        "up_proj": 18890752,
        "down_proj": 18890752,
        "total": 56672256,
        "intermediate_size": 4612
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": 86065152,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 10485760,
        "k_proj": 2621440,
        "v_proj": 2621440,
        "o_proj": 10485760,
        "total": 26214400,
        "num_heads": 20,
        "num_kv_heads": 5
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 19947520,
        "up_proj": 19947520,
        "down_proj": 19947520,
        "total": 59842560,
        "intermediate_size": 4870
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": 108818432,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 25784320,
        "up_proj": 25784320,
        "down_proj": 25784320,
        "total": 77352960,
        "intermediate_size": 6295
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": 123920384,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 30818304,
        "up_proj": 30818304,
        "down_proj": 30818304,
        "total": 92454912,
        "intermediate_size": 7524
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": 157216768,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 40169472,
        "up_proj": 40169472,
        "down_proj": 40169472,
        "total": 120508416,
        "intermediate_size": 9807
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": 175566848,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 48033792,
        "up_proj": 48033792,
        "down_proj": 48033792,
        "total": 144101376,
        "intermediate_size": 11727
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": 203567104,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 55619584,
        "up_proj": 55619584,
        "down_proj": 55619584,
        "total": 166858752,
        "intermediate_size": 13579
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": 198537216,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 10485760,
        "k_proj": 2621440,
        "v_proj": 2621440,
        "o_proj": 10485760,
        "total": 26214400,
        "num_heads": 20,
        "num_kv_heads": 5
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 57438208,
        "up_proj": 57438208,
        "down_proj": 57438208,
        "total": 172314624,
        "intermediate_size": 14023
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": 211726336,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58339328,
        "up_proj": 58339328,
        "down_proj": 58339328,
        "total": 175017984,
        "intermediate_size": 14243
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": 201732096,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 10485760,
        "k_proj": 2621440,
        "v_proj": 2621440,
        "o_proj": 10485760,
        "total": 26214400,
        "num_heads": 20,
        "num_kv_heads": 5
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58503168,
        "up_proj": 58503168,
        "down_proj": 58503168,
        "total": 175509504,
        "intermediate_size": 14283
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": 185929728,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 4194304,
        "k_proj": 1048576,
        "v_proj": 1048576,
        "o_proj": 4194304,
        "total": 10485760,
        "num_heads": 8,
        "num_kv_heads": 2
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58478592,
        "up_proj": 58478592,
        "down_proj": 58478592,
        "total": 175435776,
        "intermediate_size": 14277
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": 180355072,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 2097152,
        "k_proj": 524288,
        "v_proj": 524288,
        "o_proj": 2097152,
        "total": 5242880,
        "num_heads": 4,
        "num_kv_heads": 1
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58368000,
        "up_proj": 58368000,
        "down_proj": 58368000,
        "total": 175104000,
        "intermediate_size": 14250
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": 190656512,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 6291456,
        "k_proj": 1572864,
        "v_proj": 1572864,
        "o_proj": 6291456,
        "total": 15728640,
        "num_heads": 12,
        "num_kv_heads": 3
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58306560,
        "up_proj": 58306560,
        "down_proj": 58306560,
        "total": 174919680,
        "intermediate_size": 14235
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": 179531776,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 2097152,
        "k_proj": 524288,
        "v_proj": 524288,
        "o_proj": 2097152,
        "total": 5242880,
        "num_heads": 4,
        "num_kv_heads": 1
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58093568,
        "up_proj": 58093568,
        "down_proj": 58093568,
        "total": 174280704,
        "intermediate_size": 14183
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": 184389632,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 6291456,
        "k_proj": 1572864,
        "v_proj": 1572864,
        "o_proj": 6291456,
        "total": 15728640,
        "num_heads": 12,
        "num_kv_heads": 3
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56217600,
        "up_proj": 56217600,
        "down_proj": 56217600,
        "total": 168652800,
        "intermediate_size": 13725
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": 177106944,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 4194304,
        "k_proj": 1048576,
        "v_proj": 1048576,
        "o_proj": 4194304,
        "total": 10485760,
        "num_heads": 8,
        "num_kv_heads": 2
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 55537664,
        "up_proj": 55537664,
        "down_proj": 55537664,
        "total": 166612992,
        "intermediate_size": 13559
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": 196493312,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 55009280,
        "up_proj": 55009280,
        "down_proj": 55009280,
        "total": 165027840,
        "intermediate_size": 13430
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": 182812672,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 8388608,
        "k_proj": 2097152,
        "v_proj": 2097152,
        "o_proj": 8388608,
        "total": 20971520,
        "num_heads": 16,
        "num_kv_heads": 4
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 53944320,
        "up_proj": 53944320,
        "down_proj": 53944320,
        "total": 161832960,
        "intermediate_size": 13170
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": 216944640,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58331136,
        "up_proj": 58331136,
        "down_proj": 58331136,
        "total": 174993408,
        "intermediate_size": 14241
      },
      "norm": 8192,
      "is_zero_layer": false
    }
  ],
  "layer_summary": {
    "num_layers": 32,
    "total_layer_params": 5529985024
  }
}