{
  "model_name": "剪枝后模型",
  "total_params": 5798428672,
  "embedding_params": 134217728,
  "lm_head_params": 134217728,
  "layers": [
    {
      "layer_idx": 0,
      "total": 77500416,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 4194304,
        "k_proj": 1048576,
        "v_proj": 1048576,
        "o_proj": 4194304,
        "total": 10485760,
        "num_heads": 8,
        "num_kv_heads": 2
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 22335488,
        "up_proj": 22335488,
        "down_proj": 22335488,
        "total": 67006464,
        "intermediate_size": 5453
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": 204255232,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 55848960,
        "up_proj": 55848960,
        "down_proj": 55848960,
        "total": 167546880,
        "intermediate_size": 13635
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": 210743296,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58011648,
        "up_proj": 58011648,
        "down_proj": 58011648,
        "total": 174034944,
        "intermediate_size": 14163
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": 217042944,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58363904,
        "up_proj": 58363904,
        "down_proj": 58363904,
        "total": 175091712,
        "intermediate_size": 14249
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": 208605184,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 57298944,
        "up_proj": 57298944,
        "down_proj": 57298944,
        "total": 171896832,
        "intermediate_size": 13989
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": 210726912,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56258560,
        "up_proj": 56258560,
        "down_proj": 56258560,
        "total": 168775680,
        "intermediate_size": 13735
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": 186454016,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 51662848,
        "up_proj": 51662848,
        "down_proj": 51662848,
        "total": 154988544,
        "intermediate_size": 12613
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": 179838976,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 47710208,
        "up_proj": 47710208,
        "down_proj": 47710208,
        "total": 143130624,
        "intermediate_size": 11648
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": 171552768,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 43200512,
        "up_proj": 43200512,
        "down_proj": 43200512,
        "total": 129601536,
        "intermediate_size": 10547
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": 151687168,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 38326272,
        "up_proj": 38326272,
        "down_proj": 38326272,
        "total": 114978816,
        "intermediate_size": 9357
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": 137089024,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 33460224,
        "up_proj": 33460224,
        "down_proj": 33460224,
        "total": 100380672,
        "intermediate_size": 8169
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": 119562240,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 10485760,
        "k_proj": 2621440,
        "v_proj": 2621440,
        "o_proj": 10485760,
        "total": 26214400,
        "num_heads": 20,
        "num_kv_heads": 5
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 31113216,
        "up_proj": 31113216,
        "down_proj": 31113216,
        "total": 93339648,
        "intermediate_size": 7596
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": 122212352,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 30248960,
        "up_proj": 30248960,
        "down_proj": 30248960,
        "total": 90746880,
        "intermediate_size": 7385
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": 133275648,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 16777216,
        "k_proj": 4194304,
        "v_proj": 4194304,
        "o_proj": 16777216,
        "total": 41943040
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 30441472,
        "up_proj": 30441472,
        "down_proj": 30441472,
        "total": 91324416,
        "intermediate_size": 7432
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": 128872448,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 32468992,
        "up_proj": 32468992,
        "down_proj": 32468992,
        "total": 97406976,
        "intermediate_size": 7927
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": 138690560,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 35741696,
        "up_proj": 35741696,
        "down_proj": 35741696,
        "total": 107225088,
        "intermediate_size": 8726
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": 158224384,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 14680064,
        "k_proj": 3670016,
        "v_proj": 3670016,
        "o_proj": 14680064,
        "total": 36700160,
        "num_heads": 28,
        "num_kv_heads": 7
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 40505344,
        "up_proj": 40505344,
        "down_proj": 40505344,
        "total": 121516032,
        "intermediate_size": 9889
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": 156413952,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 10485760,
        "k_proj": 2621440,
        "v_proj": 2621440,
        "o_proj": 10485760,
        "total": 26214400,
        "num_heads": 20,
        "num_kv_heads": 5
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 43397120,
        "up_proj": 43397120,
        "down_proj": 43397120,
        "total": 130191360,
        "intermediate_size": 10595
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": 174153728,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 47562752,
        "up_proj": 47562752,
        "down_proj": 47562752,
        "total": 142688256,
        "intermediate_size": 11612
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": 184549376,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 51027968,
        "up_proj": 51027968,
        "down_proj": 51027968,
        "total": 153083904,
        "intermediate_size": 12458
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": 177176576,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 6291456,
        "k_proj": 1572864,
        "v_proj": 1572864,
        "o_proj": 6291456,
        "total": 15728640,
        "num_heads": 12,
        "num_kv_heads": 3
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 53813248,
        "up_proj": 53813248,
        "down_proj": 53813248,
        "total": 161439744,
        "intermediate_size": 13138
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": 199528448,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56020992,
        "up_proj": 56020992,
        "down_proj": 56020992,
        "total": 168062976,
        "intermediate_size": 13677
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": 180129792,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 4194304,
        "k_proj": 1048576,
        "v_proj": 1048576,
        "o_proj": 4194304,
        "total": 10485760,
        "num_heads": 8,
        "num_kv_heads": 2
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56545280,
        "up_proj": 56545280,
        "down_proj": 56545280,
        "total": 169635840,
        "intermediate_size": 13805
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": 201494528,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56676352,
        "up_proj": 56676352,
        "down_proj": 56676352,
        "total": 170029056,
        "intermediate_size": 13837
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": 180731904,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 4194304,
        "k_proj": 1048576,
        "v_proj": 1048576,
        "o_proj": 4194304,
        "total": 10485760,
        "num_heads": 8,
        "num_kv_heads": 2
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56745984,
        "up_proj": 56745984,
        "down_proj": 56745984,
        "total": 170237952,
        "intermediate_size": 13854
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": 174997504,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 2097152,
        "k_proj": 524288,
        "v_proj": 524288,
        "o_proj": 2097152,
        "total": 5242880,
        "num_heads": 4,
        "num_kv_heads": 1
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56582144,
        "up_proj": 56582144,
        "down_proj": 56582144,
        "total": 169746432,
        "intermediate_size": 13814
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": 180375552,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 4194304,
        "k_proj": 1048576,
        "v_proj": 1048576,
        "o_proj": 4194304,
        "total": 10485760,
        "num_heads": 8,
        "num_kv_heads": 2
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56627200,
        "up_proj": 56627200,
        "down_proj": 56627200,
        "total": 169881600,
        "intermediate_size": 13825
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": 194801664,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 10485760,
        "k_proj": 2621440,
        "v_proj": 2621440,
        "o_proj": 10485760,
        "total": 26214400,
        "num_heads": 20,
        "num_kv_heads": 5
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56193024,
        "up_proj": 56193024,
        "down_proj": 56193024,
        "total": 168579072,
        "intermediate_size": 13719
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": 182091776,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 6291456,
        "k_proj": 1572864,
        "v_proj": 1572864,
        "o_proj": 6291456,
        "total": 15728640,
        "num_heads": 12,
        "num_kv_heads": 3
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 55451648,
        "up_proj": 55451648,
        "down_proj": 55451648,
        "total": 166354944,
        "intermediate_size": 13538
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": 195510272,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 54681600,
        "up_proj": 54681600,
        "down_proj": 54681600,
        "total": 164044800,
        "intermediate_size": 13350
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": 190230528,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 10485760,
        "k_proj": 2621440,
        "v_proj": 2621440,
        "o_proj": 10485760,
        "total": 26214400,
        "num_heads": 20,
        "num_kv_heads": 5
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 54669312,
        "up_proj": 54669312,
        "down_proj": 54669312,
        "total": 164007936,
        "intermediate_size": 13347
      },
      "norm": 8192,
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": 201469952,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12582912,
        "k_proj": 3145728,
        "v_proj": 3145728,
        "o_proj": 12582912,
        "total": 31457280,
        "num_heads": 24,
        "num_kv_heads": 6
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56668160,
        "up_proj": 56668160,
        "down_proj": 56668160,
        "total": 170004480,
        "intermediate_size": 13835
      },
      "norm": 8192,
      "is_zero_layer": false
    }
  ],
  "layer_summary": {
    "num_layers": 32,
    "total_layer_params": 5529989120
  }
}