{
  "model_name": "剪枝后模型",
  "total_params": 6092498944,
  "embedding_params": 544997376,
  "lm_head_params": 544997376,
  "layers": [
    {
      "layer_idx": 0,
      "total": 145310720,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 38646272,
        "up_proj": 38646272,
        "down_proj": 38646272,
        "total": 115938816,
        "intermediate_size": 10783
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": 103141376,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 24589824,
        "up_proj": 24589824,
        "down_proj": 24589824,
        "total": 73769472,
        "intermediate_size": 6861
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": 143439872,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 38022656,
        "up_proj": 38022656,
        "down_proj": 38022656,
        "total": 114067968,
        "intermediate_size": 10609
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": 183684608,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 51437568,
        "up_proj": 51437568,
        "down_proj": 51437568,
        "total": 154312704,
        "intermediate_size": 14352
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": 185770496,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 52132864,
        "up_proj": 52132864,
        "down_proj": 52132864,
        "total": 156398592,
        "intermediate_size": 14546
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": 154299392,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 41642496,
        "up_proj": 41642496,
        "down_proj": 41642496,
        "total": 124927488,
        "intermediate_size": 11619
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": 198328832,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56318976,
        "up_proj": 56318976,
        "down_proj": 56318976,
        "total": 168956928,
        "intermediate_size": 15714
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": 207984128,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 59537408,
        "up_proj": 59537408,
        "down_proj": 59537408,
        "total": 178612224,
        "intermediate_size": 16612
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": 207984128,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 59537408,
        "up_proj": 59537408,
        "down_proj": 59537408,
        "total": 178612224,
        "intermediate_size": 16612
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": 213499904,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 61376000,
        "up_proj": 61376000,
        "down_proj": 61376000,
        "total": 184128000,
        "intermediate_size": 17125
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": 207027200,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 59218432,
        "up_proj": 59218432,
        "down_proj": 59218432,
        "total": 177655296,
        "intermediate_size": 16523
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": 208629248,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 59752448,
        "up_proj": 59752448,
        "down_proj": 59752448,
        "total": 179257344,
        "intermediate_size": 16672
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": 204532736,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 58386944,
        "up_proj": 58386944,
        "down_proj": 58386944,
        "total": 175160832,
        "intermediate_size": 16291
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": 207468032,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 59365376,
        "up_proj": 59365376,
        "down_proj": 59365376,
        "total": 178096128,
        "intermediate_size": 16564
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": 214940672,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 61856256,
        "up_proj": 61856256,
        "down_proj": 61856256,
        "total": 185568768,
        "intermediate_size": 17259
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": 217241600,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 62623232,
        "up_proj": 62623232,
        "down_proj": 62623232,
        "total": 187869696,
        "intermediate_size": 17473
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": 217402880,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 62676992,
        "up_proj": 62676992,
        "down_proj": 62676992,
        "total": 188030976,
        "intermediate_size": 17488
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": 206414336,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 59014144,
        "up_proj": 59014144,
        "down_proj": 59014144,
        "total": 177042432,
        "intermediate_size": 16466
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": 194081792,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 54903296,
        "up_proj": 54903296,
        "down_proj": 54903296,
        "total": 164709888,
        "intermediate_size": 15319
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": 190673408,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 53767168,
        "up_proj": 53767168,
        "down_proj": 53767168,
        "total": 161301504,
        "intermediate_size": 15002
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": 181286912,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 50638336,
        "up_proj": 50638336,
        "down_proj": 50638336,
        "total": 151915008,
        "intermediate_size": 14129
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": 176222720,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 48950272,
        "up_proj": 48950272,
        "down_proj": 48950272,
        "total": 146850816,
        "intermediate_size": 13658
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": 183329792,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 51319296,
        "up_proj": 51319296,
        "down_proj": 51319296,
        "total": 153957888,
        "intermediate_size": 14319
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": 171427328,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 47351808,
        "up_proj": 47351808,
        "down_proj": 47351808,
        "total": 142055424,
        "intermediate_size": 13212
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": 155600384,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 42076160,
        "up_proj": 42076160,
        "down_proj": 42076160,
        "total": 126228480,
        "intermediate_size": 11740
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": 131161088,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 33929728,
        "up_proj": 33929728,
        "down_proj": 33929728,
        "total": 101789184,
        "intermediate_size": 9467
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": 85282304,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 18636800,
        "up_proj": 18636800,
        "down_proj": 18636800,
        "total": 55910400,
        "intermediate_size": 5200
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": 106334720,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 25654272,
        "up_proj": 25654272,
        "down_proj": 25654272,
        "total": 76962816,
        "intermediate_size": 7158
      },
      "norm": 7168,
      "is_zero_layer": false
    }
  ],
  "layer_summary": {
    "num_layers": 28,
    "total_layer_params": 5002500608
  }
}