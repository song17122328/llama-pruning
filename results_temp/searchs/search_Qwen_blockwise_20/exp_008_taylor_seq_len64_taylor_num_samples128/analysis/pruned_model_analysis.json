{
  "model_name": "剪枝后模型",
  "total_params": 6092492032,
  "embedding_params": 544997376,
  "lm_head_params": 544997376,
  "layers": [
    {
      "layer_idx": 0,
      "total": 146966528,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 39198208,
        "up_proj": 39198208,
        "down_proj": 39198208,
        "total": 117594624,
        "intermediate_size": 10937
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": 108689408,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 26439168,
        "up_proj": 26439168,
        "down_proj": 26439168,
        "total": 79317504,
        "intermediate_size": 7377
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": 148192256,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 39606784,
        "up_proj": 39606784,
        "down_proj": 39606784,
        "total": 118820352,
        "intermediate_size": 11051
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": 203016704,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 57881600,
        "up_proj": 57881600,
        "down_proj": 57881600,
        "total": 173644800,
        "intermediate_size": 16150
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": 207900544,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 9636480,
        "k_proj": 1376640,
        "v_proj": 1376640,
        "o_proj": 9633792,
        "total": 22023552,
        "num_heads": 21,
        "num_kv_heads": 3
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 61956608,
        "up_proj": 61956608,
        "down_proj": 61956608,
        "total": 185869824,
        "intermediate_size": 17287
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": 184114688,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 51580928,
        "up_proj": 51580928,
        "down_proj": 51580928,
        "total": 154742784,
        "intermediate_size": 14392
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": 224423936,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 65017344,
        "up_proj": 65017344,
        "down_proj": 65017344,
        "total": 195052032,
        "intermediate_size": 18141
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": 224187392,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 64938496,
        "up_proj": 64938496,
        "down_proj": 64938496,
        "total": 194815488,
        "intermediate_size": 18119
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": 221338112,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 63988736,
        "up_proj": 63988736,
        "down_proj": 63988736,
        "total": 191966208,
        "intermediate_size": 17854
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": 215843840,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 62157312,
        "up_proj": 62157312,
        "down_proj": 62157312,
        "total": 186471936,
        "intermediate_size": 17343
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": 215370752,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 61999616,
        "up_proj": 61999616,
        "down_proj": 61999616,
        "total": 185998848,
        "intermediate_size": 17299
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": 212833280,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 61153792,
        "up_proj": 61153792,
        "down_proj": 61153792,
        "total": 183461376,
        "intermediate_size": 17063
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": 200124416,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 56917504,
        "up_proj": 56917504,
        "down_proj": 56917504,
        "total": 170752512,
        "intermediate_size": 15881
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": 193382912,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 54670336,
        "up_proj": 54670336,
        "down_proj": 54670336,
        "total": 164011008,
        "intermediate_size": 15254
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": 195995648,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 55541248,
        "up_proj": 55541248,
        "down_proj": 55541248,
        "total": 166623744,
        "intermediate_size": 15497
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": 191920640,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 54182912,
        "up_proj": 54182912,
        "down_proj": 54182912,
        "total": 162548736,
        "intermediate_size": 15118
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": 189963776,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 53530624,
        "up_proj": 53530624,
        "down_proj": 53530624,
        "total": 160591872,
        "intermediate_size": 14936
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": 162976256,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 44534784,
        "up_proj": 44534784,
        "down_proj": 44534784,
        "total": 133604352,
        "intermediate_size": 12426
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": 145203200,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 38610432,
        "up_proj": 38610432,
        "down_proj": 38610432,
        "total": 115831296,
        "intermediate_size": 10773
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": 150138368,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 40255488,
        "up_proj": 40255488,
        "down_proj": 40255488,
        "total": 120766464,
        "intermediate_size": 11232
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": 150471680,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 40366592,
        "up_proj": 40366592,
        "down_proj": 40366592,
        "total": 121099776,
        "intermediate_size": 11263
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": 140633600,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 37087232,
        "up_proj": 37087232,
        "down_proj": 37087232,
        "total": 111261696,
        "intermediate_size": 10348
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": 147431296,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 9636480,
        "k_proj": 1376640,
        "v_proj": 1376640,
        "o_proj": 9633792,
        "total": 22023552,
        "num_heads": 21,
        "num_kv_heads": 3
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 41800192,
        "up_proj": 41800192,
        "down_proj": 41800192,
        "total": 125400576,
        "intermediate_size": 11663
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": 146676224,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 39101440,
        "up_proj": 39101440,
        "down_proj": 39101440,
        "total": 117304320,
        "intermediate_size": 10910
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": 151667584,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 9636480,
        "k_proj": 1376640,
        "v_proj": 1376640,
        "o_proj": 9633792,
        "total": 22023552,
        "num_heads": 21,
        "num_kv_heads": 3
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 43212288,
        "up_proj": 43212288,
        "down_proj": 43212288,
        "total": 129636864,
        "intermediate_size": 12057
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": 154387840,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 9636480,
        "k_proj": 1376640,
        "v_proj": 1376640,
        "o_proj": 9633792,
        "total": 22023552,
        "num_heads": 21,
        "num_kv_heads": 3
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 44119040,
        "up_proj": 44119040,
        "down_proj": 44119040,
        "total": 132357120,
        "intermediate_size": 12310
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": 159325440,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 6424320,
        "k_proj": 917760,
        "v_proj": 917760,
        "o_proj": 6422528,
        "total": 14682368,
        "num_heads": 14,
        "num_kv_heads": 2
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 48211968,
        "up_proj": 48211968,
        "down_proj": 48211968,
        "total": 144635904,
        "intermediate_size": 13452
      },
      "norm": 7168,
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": 209317376,
      "attention": {
        "type": "LlamaAttention",
        "q_proj": 12848640,
        "k_proj": 1835520,
        "v_proj": 1835520,
        "o_proj": 12845056,
        "total": 29364736
      },
      "mlp": {
        "type": "LlamaMLP",
        "gate_proj": 59981824,
        "up_proj": 59981824,
        "down_proj": 59981824,
        "total": 179945472,
        "intermediate_size": 16736
      },
      "norm": 7168,
      "is_zero_layer": false
    }
  ],
  "layer_summary": {
    "num_layers": 28,
    "total_layer_params": 5002493696
  }
}