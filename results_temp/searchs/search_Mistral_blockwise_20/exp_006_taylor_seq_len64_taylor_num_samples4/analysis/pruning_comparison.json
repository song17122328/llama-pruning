{
  "original_name": "原始模型",
  "pruned_name": "剪枝后模型",
  "total_params": {
    "original": 7248023552,
    "pruned": 5798428672,
    "reduced": 1449594880,
    "reduction_ratio": 0.19999864371301646
  },
  "layer_params": {
    "original": 6979584000,
    "pruned": 5529989120,
    "reduced": 1449594880,
    "reduction_ratio": 0.2076907276995305
  },
  "layers": [
    {
      "layer_idx": 0,
      "total": {
        "original": 218112000,
        "pruned": 67448832,
        "reduced": 150663168,
        "reduction_ratio": 0.6907605633802817
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 56954880,
        "reduced": 119205888,
        "reduction_ratio": 0.6766880580357143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 4635
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": {
        "original": 218112000,
        "pruned": 206626816,
        "reduced": 11485184,
        "reduction_ratio": 0.05265727699530517
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 169918464,
        "reduced": 6242304,
        "reduction_ratio": 0.035435267857142856,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13828
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": {
        "original": 218112000,
        "pruned": 209809408,
        "reduced": 8302592,
        "reduction_ratio": 0.03806572769953052
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173101056,
        "reduced": 3059712,
        "reduction_ratio": 0.017368861607142856,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14087
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": {
        "original": 218112000,
        "pruned": 217239552,
        "reduced": 872448,
        "reduction_ratio": 0.004
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175288320,
        "reduced": 872448,
        "reduction_ratio": 0.004952566964285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14265
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": {
        "original": 218112000,
        "pruned": 210509824,
        "reduced": 7602176,
        "reduction_ratio": 0.034854460093896714
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173801472,
        "reduced": 2359296,
        "reduction_ratio": 0.013392857142857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14144
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": {
        "original": 218112000,
        "pruned": 214892544,
        "reduced": 3219456,
        "reduction_ratio": 0.01476056338028169
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 172941312,
        "reduced": 3219456,
        "reduction_ratio": 0.018275669642857144,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14074
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": {
        "original": 218112000,
        "pruned": 194846720,
        "reduced": 23265280,
        "reduction_ratio": 0.10666666666666667
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 163381248,
        "reduced": 12779520,
        "reduction_ratio": 0.07254464285714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13296
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": {
        "original": 218112000,
        "pruned": 195678208,
        "reduced": 22433792,
        "reduction_ratio": 0.10285446009389672
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 158969856,
        "reduced": 17190912,
        "reduction_ratio": 0.09758649553571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12937
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": {
        "original": 218112000,
        "pruned": 195121152,
        "reduced": 22990848,
        "reduction_ratio": 0.10540845070422535
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 153169920,
        "reduced": 22990848,
        "reduction_ratio": 0.13051060267857142,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12465
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": {
        "original": 218112000,
        "pruned": 180379648,
        "reduced": 37732352,
        "reduction_ratio": 0.17299530516431924
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 143671296,
        "reduced": 32489472,
        "reduction_ratio": 0.18443080357142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11692
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": {
        "original": 218112000,
        "pruned": 167731200,
        "reduced": 50380800,
        "reduction_ratio": 0.23098591549295774
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 125779968,
        "reduced": 50380800,
        "reduction_ratio": 0.28599330357142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10236
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": {
        "original": 218112000,
        "pruned": 153751552,
        "reduced": 64360448,
        "reduction_ratio": 0.29507981220657276
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 117043200,
        "reduced": 59117568,
        "reduction_ratio": 0.33558872767857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9525
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": {
        "original": 218112000,
        "pruned": 154480640,
        "reduced": 63631360,
        "reduction_ratio": 0.2917370892018779
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 123015168,
        "reduced": 53145600,
        "reduction_ratio": 0.3016880580357143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10011
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": {
        "original": 218112000,
        "pruned": 165212160,
        "reduced": 52899840,
        "reduction_ratio": 0.24253521126760563
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 123260928,
        "reduced": 52899840,
        "reduction_ratio": 0.30029296875,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10031
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": {
        "original": 218112000,
        "pruned": 152698880,
        "reduced": 65413120,
        "reduction_ratio": 0.29990610328638495
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 121233408,
        "reduced": 54927360,
        "reduction_ratio": 0.31180245535714285,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9866
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": {
        "original": 218112000,
        "pruned": 159444992,
        "reduced": 58667008,
        "reduction_ratio": 0.26897652582159626
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 127979520,
        "reduced": 48181248,
        "reduction_ratio": 0.2735072544642857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10415
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": {
        "original": 218112000,
        "pruned": 183926784,
        "reduced": 34185216,
        "reduction_ratio": 0.15673239436619718
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 141975552,
        "reduced": 34185216,
        "reduction_ratio": 0.19405691964285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11554
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": {
        "original": 218112000,
        "pruned": 178081792,
        "reduced": 40030208,
        "reduction_ratio": 0.1835305164319249
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 141373440,
        "reduced": 34787328,
        "reduction_ratio": 0.19747488839285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11505
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": {
        "original": 218112000,
        "pruned": 180789248,
        "reduced": 37322752,
        "reduction_ratio": 0.17111737089201878
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 149323776,
        "reduced": 26836992,
        "reduction_ratio": 0.15234375,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12152
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": {
        "original": 218112000,
        "pruned": 193368064,
        "reduced": 24743936,
        "reduction_ratio": 0.11344600938967137
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 156659712,
        "reduced": 19501056,
        "reduction_ratio": 0.11070033482142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12749
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": {
        "original": 218112000,
        "pruned": 192872448,
        "reduced": 25239552,
        "reduction_ratio": 0.11571830985915493
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 166649856,
        "reduced": 9510912,
        "reduction_ratio": 0.053989955357142856,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13562
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": {
        "original": 218112000,
        "pruned": 204025856,
        "reduced": 14086144,
        "reduction_ratio": 0.06458215962441315
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 172560384,
        "reduced": 3600384,
        "reduction_ratio": 0.020438058035714284,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14043
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": {
        "original": 218112000,
        "pruned": 184406016,
        "reduced": 33705984,
        "reduction_ratio": 0.15453521126760564
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173912064,
        "reduced": 2248704,
        "reduction_ratio": 0.012765066964285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14153
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": {
        "original": 218112000,
        "pruned": 204824576,
        "reduced": 13287424,
        "reduction_ratio": 0.06092018779342723
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173359104,
        "reduced": 2801664,
        "reduction_ratio": 0.015904017857142856,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14108
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": {
        "original": 218112000,
        "pruned": 183705600,
        "reduced": 34406400,
        "reduction_ratio": 0.15774647887323945
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173211648,
        "reduced": 2949120,
        "reduction_ratio": 0.016741071428571428,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14096
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": {
        "original": 218112000,
        "pruned": 172064768,
        "reduced": 46047232,
        "reduction_ratio": 0.2111173708920188
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 172056576,
        "reduced": 4104192,
        "reduction_ratio": 0.023297991071428572,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14002
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": {
        "original": 218112000,
        "pruned": 179650560,
        "reduced": 38461440,
        "reduction_ratio": 0.1763380281690141
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 169156608,
        "reduced": 7004160,
        "reduction_ratio": 0.039760044642857144,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13766
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": {
        "original": 218112000,
        "pruned": 166481920,
        "reduced": 51630080,
        "reduction_ratio": 0.23671361502347418
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 161230848,
        "reduced": 14929920,
        "reduction_ratio": 0.08475167410714286,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13121
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": {
        "original": 218112000,
        "pruned": 150089728,
        "reduced": 68022272,
        "reduction_ratio": 0.311868544600939
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 144838656,
        "reduced": 31322112,
        "reduction_ratio": 0.17780412946428573,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11787
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": {
        "original": 218112000,
        "pruned": 136589312,
        "reduced": 81522688,
        "reduction_ratio": 0.37376525821596246
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 120852480,
        "reduced": 55308288,
        "reduction_ratio": 0.31396484375,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9835
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": {
        "original": 218112000,
        "pruned": 93360128,
        "reduced": 124751872,
        "reduction_ratio": 0.571962441314554
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 93351936,
        "reduced": 82808832,
        "reduction_ratio": 0.47007533482142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7597
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": {
        "original": 218112000,
        "pruned": 79880192,
        "reduced": 138231808,
        "reduction_ratio": 0.6337652582159624
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 79872000,
        "reduced": 96288768,
        "reduction_ratio": 0.5465959821428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 6500
        }
      },
      "is_zero_layer": false
    }
  ]
}