{
  "original_name": "原始模型",
  "pruned_name": "剪枝后模型",
  "total_params": {
    "original": 7248023552,
    "pruned": 5798420480,
    "reduced": 1449603072,
    "reduction_ratio": 0.19999977395216942
  },
  "layer_params": {
    "original": 6979584000,
    "pruned": 5529980928,
    "reduced": 1449603072,
    "reduction_ratio": 0.2076919014084507
  },
  "layers": [
    {
      "layer_idx": 0,
      "total": {
        "original": 218112000,
        "pruned": 131002368,
        "reduced": 87109632,
        "reduction_ratio": 0.39938028169014084
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 120508416,
        "reduced": 55652352,
        "reduction_ratio": 0.31591796875,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9807
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 1,
      "total": {
        "original": 218112000,
        "pruned": 212684800,
        "reduced": 5427200,
        "reduction_ratio": 0.02488262910798122
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175976448,
        "reduced": 184320,
        "reduction_ratio": 0.0010463169642857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14321
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 2,
      "total": {
        "original": 218112000,
        "pruned": 212475904,
        "reduced": 5636096,
        "reduction_ratio": 0.02584037558685446
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175767552,
        "reduced": 393216,
        "reduction_ratio": 0.002232142857142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14304
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 3,
      "total": {
        "original": 218112000,
        "pruned": 217964544,
        "reduced": 147456,
        "reduction_ratio": 0.000676056338028169
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176013312,
        "reduced": 147456,
        "reduction_ratio": 0.0008370535714285714,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14324
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 4,
      "total": {
        "original": 218112000,
        "pruned": 212512768,
        "reduced": 5599232,
        "reduction_ratio": 0.025671361502347417
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175804416,
        "reduced": 356352,
        "reduction_ratio": 0.0020228794642857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14307
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 5,
      "total": {
        "original": 218112000,
        "pruned": 217976832,
        "reduced": 135168,
        "reduction_ratio": 0.0006197183098591549
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 176025600,
        "reduced": 135168,
        "reduction_ratio": 0.0007672991071428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14325
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 6,
      "total": {
        "original": 218112000,
        "pruned": 211800064,
        "reduced": 6311936,
        "reduction_ratio": 0.028938967136150236
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175091712,
        "reduced": 1069056,
        "reduction_ratio": 0.006068638392857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14249
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 7,
      "total": {
        "original": 218112000,
        "pruned": 210829312,
        "reduced": 7282688,
        "reduction_ratio": 0.033389671361502345
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174120960,
        "reduced": 2039808,
        "reduction_ratio": 0.011579241071428572,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14170
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 8,
      "total": {
        "original": 218112000,
        "pruned": 214708224,
        "reduced": 3403776,
        "reduction_ratio": 0.015605633802816902
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 172756992,
        "reduced": 3403776,
        "reduction_ratio": 0.019321986607142856,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14059
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 9,
      "total": {
        "original": 218112000,
        "pruned": 206344192,
        "reduced": 11767808,
        "reduction_ratio": 0.05395305164319249
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 169635840,
        "reduced": 6524928,
        "reduction_ratio": 0.03703962053571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13805
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 10,
      "total": {
        "original": 218112000,
        "pruned": 182857728,
        "reduced": 35254272,
        "reduction_ratio": 0.1616338028169014
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 140906496,
        "reduced": 35254272,
        "reduction_ratio": 0.20012555803571427,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11467
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 11,
      "total": {
        "original": 218112000,
        "pruned": 155435008,
        "reduced": 62676992,
        "reduction_ratio": 0.28736150234741786
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 118726656,
        "reduced": 57434112,
        "reduction_ratio": 0.32603236607142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 9662
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 12,
      "total": {
        "original": 218112000,
        "pruned": 136994816,
        "reduced": 81117184,
        "reduction_ratio": 0.37190610328638496
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 105529344,
        "reduced": 70631424,
        "reduction_ratio": 0.4009486607142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8588
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 13,
      "total": {
        "original": 218112000,
        "pruned": 139898880,
        "reduced": 78213120,
        "reduction_ratio": 0.35859154929577464
      },
      "attention": {
        "original": 41943040,
        "pruned": 41943040,
        "reduced": 0,
        "reduction_ratio": 0.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 97947648,
        "reduced": 78213120,
        "reduction_ratio": 0.44398716517857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7971
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 14,
      "total": {
        "original": 218112000,
        "pruned": 127959040,
        "reduced": 90152960,
        "reduction_ratio": 0.41333333333333333
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 91250688,
        "reduced": 84910080,
        "reduction_ratio": 0.4820033482142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 7426
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 15,
      "total": {
        "original": 218112000,
        "pruned": 138481664,
        "reduced": 79630336,
        "reduction_ratio": 0.36508920187793426
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 107016192,
        "reduced": 69144576,
        "reduction_ratio": 0.3925083705357143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8709
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 16,
      "total": {
        "original": 218112000,
        "pruned": 162918400,
        "reduced": 55193600,
        "reduction_ratio": 0.25305164319248824
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 126210048,
        "reduced": 49950720,
        "reduction_ratio": 0.28355189732142855,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10271
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 17,
      "total": {
        "original": 218112000,
        "pruned": 164028416,
        "reduced": 54083584,
        "reduction_ratio": 0.247962441314554
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 132562944,
        "reduced": 43597824,
        "reduction_ratio": 0.24748883928571427,
        "intermediate_size": {
          "original": 14336,
          "pruned": 10788
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 18,
      "total": {
        "original": 218112000,
        "pruned": 177106944,
        "reduced": 41005056,
        "reduction_ratio": 0.188
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 150884352,
        "reduced": 25276416,
        "reduction_ratio": 0.14348493303571427,
        "intermediate_size": {
          "original": 14336,
          "pruned": 12279
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 19,
      "total": {
        "original": 218112000,
        "pruned": 199462912,
        "reduced": 18649088,
        "reduction_ratio": 0.08550234741784038
      },
      "attention": {
        "original": 41943040,
        "pruned": 36700160,
        "reduced": 5242880,
        "reduction_ratio": 0.125
      },
      "mlp": {
        "original": 176160768,
        "pruned": 162754560,
        "reduced": 13406208,
        "reduction_ratio": 0.07610212053571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13245
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 20,
      "total": {
        "original": 218112000,
        "pruned": 199716864,
        "reduced": 18395136,
        "reduction_ratio": 0.08433802816901409
      },
      "attention": {
        "original": 41943040,
        "pruned": 26214400,
        "reduced": 15728640,
        "reduction_ratio": 0.375
      },
      "mlp": {
        "original": 176160768,
        "pruned": 173494272,
        "reduced": 2666496,
        "reduction_ratio": 0.01513671875,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14119
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 21,
      "total": {
        "original": 218112000,
        "pruned": 206790656,
        "reduced": 11321344,
        "reduction_ratio": 0.05190610328638497
      },
      "attention": {
        "original": 41943040,
        "pruned": 31457280,
        "reduced": 10485760,
        "reduction_ratio": 0.25
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175325184,
        "reduced": 835584,
        "reduction_ratio": 0.004743303571428571,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14268
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 22,
      "total": {
        "original": 218112000,
        "pruned": 191430656,
        "reduced": 26681344,
        "reduction_ratio": 0.12232863849765258
      },
      "attention": {
        "original": 41943040,
        "pruned": 15728640,
        "reduced": 26214400,
        "reduction_ratio": 0.625
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175693824,
        "reduced": 466944,
        "reduction_ratio": 0.002650669642857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14298
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 23,
      "total": {
        "original": 218112000,
        "pruned": 186249216,
        "reduced": 31862784,
        "reduction_ratio": 0.1460845070422535
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175755264,
        "reduced": 405504,
        "reduction_ratio": 0.0023018973214285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14303
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 24,
      "total": {
        "original": 218112000,
        "pruned": 180969472,
        "reduced": 37142528,
        "reduction_ratio": 0.17029107981220656
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175718400,
        "reduced": 442368,
        "reduction_ratio": 0.0025111607142857145,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14300
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 25,
      "total": {
        "original": 218112000,
        "pruned": 175357952,
        "reduced": 42754048,
        "reduction_ratio": 0.196018779342723
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 175349760,
        "reduced": 811008,
        "reduction_ratio": 0.004603794642857143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14270
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 26,
      "total": {
        "original": 218112000,
        "pruned": 174227456,
        "reduced": 43884544,
        "reduction_ratio": 0.2012018779342723
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 174219264,
        "reduced": 1941504,
        "reduction_ratio": 0.011021205357142858,
        "intermediate_size": {
          "original": 14336,
          "pruned": 14178
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 27,
      "total": {
        "original": 218112000,
        "pruned": 171102208,
        "reduced": 47009792,
        "reduction_ratio": 0.2155305164319249
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 165851136,
        "reduced": 10309632,
        "reduction_ratio": 0.05852399553571429,
        "intermediate_size": {
          "original": 14336,
          "pruned": 13497
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 28,
      "total": {
        "original": 218112000,
        "pruned": 147656704,
        "reduced": 70455296,
        "reduction_ratio": 0.32302347417840377
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 142405632,
        "reduced": 33755136,
        "reduction_ratio": 0.19161551339285715,
        "intermediate_size": {
          "original": 14336,
          "pruned": 11589
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 29,
      "total": {
        "original": 218112000,
        "pruned": 118087680,
        "reduced": 100024320,
        "reduction_ratio": 0.45859154929577467
      },
      "attention": {
        "original": 41943040,
        "pruned": 10485760,
        "reduced": 31457280,
        "reduction_ratio": 0.75
      },
      "mlp": {
        "original": 176160768,
        "pruned": 107593728,
        "reduced": 68567040,
        "reduction_ratio": 0.3892299107142857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 8756
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 30,
      "total": {
        "original": 218112000,
        "pruned": 73625600,
        "reduced": 144486400,
        "reduction_ratio": 0.6624413145539906
      },
      "attention": {
        "original": 41943040,
        "pruned": 0,
        "reduced": 41943040,
        "reduction_ratio": 1.0
      },
      "mlp": {
        "original": 176160768,
        "pruned": 73617408,
        "reduced": 102543360,
        "reduction_ratio": 0.5821010044642857,
        "intermediate_size": {
          "original": 14336,
          "pruned": 5991
        }
      },
      "is_zero_layer": false
    },
    {
      "layer_idx": 31,
      "total": {
        "original": 218112000,
        "pruned": 71323648,
        "reduced": 146788352,
        "reduction_ratio": 0.6729953051643193
      },
      "attention": {
        "original": 41943040,
        "pruned": 5242880,
        "reduced": 36700160,
        "reduction_ratio": 0.875
      },
      "mlp": {
        "original": 176160768,
        "pruned": 66072576,
        "reduced": 110088192,
        "reduction_ratio": 0.6249302455357143,
        "intermediate_size": {
          "original": 14336,
          "pruned": 5377
        }
      },
      "is_zero_layer": false
    }
  ]
}