import os
import shutil

# ================= é…ç½®åŒºåŸŸ =================
# 1. å¼ºåˆ¶è®¾ç½®ç¯å¢ƒå˜é‡ä½¿ç”¨ hf-mirror (å¿…é¡»åœ¨ import datasets å‰è®¾ç½®)
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

# 2. è¿™æ˜¯ä½ æŠ¥é”™æ—¥å¿—ä¸­æç¤ºçš„ç¼ºå¤±è·¯å¾„
SAVE_PATH = "/newdata/DataSets/wikipedia_zh"

# 3. ä½¿ç”¨ä¸€ä¸ªç¨³å®šçš„ä¸­æ–‡ç»´åŸºç™¾ç§‘æº
# åŸä»£ç ç”¨çš„ wikipedia 20220301 å·²è¿‡æœŸï¼Œè¿™é‡Œä½¿ç”¨ pleisto æ¸…æ´—ç‰ˆï¼Œè´¨é‡æ›´é«˜ä¸”ç¨³å®š
DATASET_NAME = "pleisto/wikipedia-cn-20230720-filtered"
# ===========================================

import datasets
from datasets import load_dataset

def main():
    print(f"ğŸš€ å¼€å§‹é€šè¿‡ hf-mirror ä¸‹è½½: {DATASET_NAME}")
    print(f"ğŸ“‚ ç›®æ ‡ä¿å­˜è·¯å¾„: {SAVE_PATH}")

    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º
    if not os.path.exists(SAVE_PATH):
        os.makedirs(SAVE_PATH, exist_ok=True)
        print(f"å·²åˆ›å»ºç›®å½•: {SAVE_PATH}")
    else:
        print(f"âš ï¸ ç›®å½•å·²å­˜åœ¨: {SAVE_PATH} (å¦‚æœè„šæœ¬è¿è¡Œå¤±è´¥ï¼Œè¯·æ‰‹åŠ¨åˆ é™¤è¯¥ç›®å½•åé‡è¯•)")

    try:
        # å¼€å§‹ä¸‹è½½
        # split='train' ç¡®ä¿æˆ‘ä»¬æ‹¿åˆ°çš„æ˜¯ Dataset å¯¹è±¡è€Œä¸æ˜¯ DatasetDict
        dataset = load_dataset(DATASET_NAME, split='train', trust_remote_code=True)
        
        print(f"âœ… ä¸‹è½½æˆåŠŸï¼æ•°æ®é‡: {len(dataset)} æ¡")
        print("ğŸ’¾ æ­£åœ¨è½¬æ¢å¹¶ä¿å­˜åˆ°æœ¬åœ°ç£ç›˜ (Save to Disk)...")

        # æ ¸å¿ƒæ­¥éª¤ï¼šä¿å­˜ä¸º load_from_disk èƒ½è¯»å–çš„æ ¼å¼
        dataset.save_to_disk(SAVE_PATH)

        print("-" * 30)
        print(f"ğŸ‰ æˆåŠŸï¼æ‰€æœ‰æ•°æ®å·²ä¿å­˜è‡³: {SAVE_PATH}")
        print("ç°åœ¨ä½ å¯ä»¥ç›´æ¥è¿è¡ŒåŸæœ¬çš„ pruning è„šæœ¬äº†ï¼Œå®ƒä¼šç›´æ¥è¯»å–æœ¬åœ°æ•°æ®ã€‚")
        print("-" * 30)

    except Exception as e:
        print("\nâŒ å‘ç”Ÿé”™è¯¯:")
        print(e)
        print("\nå»ºè®®æ’æŸ¥ï¼š")
        print("1. ç¡®ä¿æœåŠ¡å™¨èƒ½è®¿é—® https://hf-mirror.com")
        print("2. æ£€æŸ¥ç£ç›˜ç©ºé—´æ˜¯å¦å……è¶³")

if __name__ == "__main__":
    main()