```bash
# shortGPT Mistral
python baselines/run_shortgpt.py \
    --base_model /newdata/LLMs/Mistral-7B-Instruct-v0.3 \
    --n_remove_layers 6 \
    --dataset c4 \
    --output_name for_finetuning/Mistral-Instruct/ShortGPT_remove_6
    
python baselines/run_shortgpt.py \
    --base_model /newdata/LLMs/Mistral-7B-Instruct-v0.3 \
    --n_remove_layers 7 \
    --dataset c4 \
    --output_name for_finetuning/Mistral-Instruct/ShortGPT_remove_7

python baselines/run_shortgpt.py \
    --base_model /newdata/LLMs/Mistral-7B-v0.3 \
    --n_remove_layers 6 \
    --dataset c4 \
    --output_name for_finetuning/Mistral/ShortGPT_remove_6

python baselines/run_shortgpt.py \
    --base_model /newdata/LLMs/Mistral-7B-v0.3 \
    --n_remove_layers 7 \
    --dataset c4 \
    --output_name for_finetuning/Mistral/ShortGPT_remove_7

# shortGPT Qwen
python baselines/run_shortgpt.py \
    --base_model /newdata/LLMs/Qwen2.5-7B-Instruct \
    --n_remove_layers 6 \
    --dataset c4 \
    --output_name for_finetuning/Qwen-Instruct/ShortGPT_remove_6

python baselines/run_shortgpt.py \
    --base_model /newdata/LLMs/Qwen2.5-7B-Instruct \
    --n_remove_layers 7 \
    --dataset c4 \
    --output_name for_finetuning/Qwen-Instruct/ShortGPT_remove_7

python baselines/run_shortgpt.py \
    --base_model /newdata/LLMs/Qwen2.5-7B \
    --n_remove_layers 6 \
    --dataset c4 \
    --output_name for_finetuning/Qwen/ShortGPT_remove_6
    
python baselines/run_shortgpt.py \
    --base_model /newdata/LLMs/Qwen2.5-7B \
    --n_remove_layers 7 \
    --dataset c4 \
    --output_name for_finetuning/Qwen/ShortGPT_remove_7


# magnitude
python baselines/run_magnitude.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruning_ratio 0.2 \
    --dataset wikitext2 \
    --output_name for_finetuning/Llama-Instruct/magnitude
    
python baselines/run_magnitude.py \
    --base_model /newdata/LLMs/Llama-3-8B \
    --pruning_ratio 0.2 \
    --dataset wikitext2 \
    --output_name for_finetuning/Llama/magnitude

python baselines/run_magnitude.py \
    --base_model /newdata/LLMs/Mistral-7B-Instruct-v0.3 \
    --pruning_ratio 0.2 \
    --dataset c4 \
    --output_name for_finetuning/Mistral-Instruct/magnitude

python baselines/run_magnitude.py \
    --base_model /newdata/LLMs/Mistral-7B-v0.3 \
    --pruning_ratio 0.2 \
    --dataset c4 \
    --output_name for_finetuning/Mistral/magnitude

python baselines/run_magnitude.py \
    --base_model /newdata/LLMs/Qwen2.5-7B-Instruct \
    --pruning_ratio 0.2 \
    --dataset c4 \
    --output_name for_finetuning/Qwen-Instruct/magnitude

python baselines/run_magnitude.py \
    --base_model /newdata/LLMs/Qwen2.5-7B \
    --pruning_ratio 0.2 \
    --dataset c4 \
    --output_name for_finetuning/Qwen/magnitude

# wanda
python baselines/run_wanda.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruning_ratio 0.2 \
    --dataset wikitext2 \
    --output_name for_finetuning/Llama-Instruct/wanda
    
python baselines/run_wanda.py \
    --base_model /newdata/LLMs/Llama-3-8B \
    --pruning_ratio 0.2 \
    --dataset wikitext2 \
    --output_name for_finetuning/Llama/wanda

python baselines/run_wanda.py \
    --base_model /newdata/LLMs/Mistral-7B-Instruct-v0.3 \
    --pruning_ratio 0.2 \
    --dataset c4 \
    --output_name for_finetuning/Mistral-Instruct/wanda

python baselines/run_wanda.py \
    --base_model /newdata/LLMs/Mistral-7B-v0.3 \
    --pruning_ratio 0.2 \
    --dataset c4 \
    --output_name for_finetuning/Mistral/wanda

python baselines/run_wanda.py \
    --base_model /newdata/LLMs/Qwen2.5-7B-Instruct \
    --pruning_ratio 0.2 \
    --dataset c4 \
    --output_name for_finetuning/Qwen-Instruct/wanda

python baselines/run_wanda.py \
    --base_model /newdata/LLMs/Qwen2.5-7B \
    --pruning_ratio 0.2 \
    --dataset c4 \
    --output_name for_finetuning/Qwen/wanda
```