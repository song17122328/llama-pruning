# å‚æ•°æœç´¢å’Œç»“æœåˆ†æå·¥å…·

æœ¬ç›®å½•åŒ…å«ç”¨äº LLaMAã€Qwenã€Mistral åŠå…¶ Instruct ç‰ˆæœ¬çš„å‚æ•°æœç´¢å’Œç»“æœåˆ†æçš„å®Œæ•´å·¥å…·é“¾ã€‚

## ğŸ“‚ ç›®å½•ç»“æ„

```
param_search/
â”œâ”€â”€ search_best_params.py          # ä¸»å‚æ•°æœç´¢è„šæœ¬
â”œâ”€â”€ consolidate_model_results.py   # å•æ¨¡å‹ç»“æœæ±‡æ€»
â”œâ”€â”€ consolidate_all_models.py      # æ‰¹é‡æ±‡æ€»æ‰€æœ‰6ä¸ªæ¨¡å‹
â”œâ”€â”€ analyze_all_models.py          # è·¨æ¨¡å‹ç»¼åˆåˆ†æ
â”œâ”€â”€ re_extract_results.py          # é‡æå–ç»“æœå·¥å…·
â”œâ”€â”€ copy_best_results.py           # å¤åˆ¶æœ€ä½³ç»“æœåˆ°ç‹¬ç«‹ç›®å½•
â””â”€â”€ README.md                      # æœ¬æ–‡ä»¶
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®Œæ•´å·¥ä½œæµç¨‹

```bash
# 1. è¿è¡Œå‚æ•°æœç´¢ï¼ˆé’ˆå¯¹æŸä¸ªæ¨¡å‹ï¼‰
python param_search/search_best_params.py --config configs/Llama_param_search.json

# 2. å¦‚æœéœ€è¦é‡æå–ç»“æœï¼ˆå¯é€‰ï¼‰
python param_search/re_extract_results.py --search_dir results/search_Llama_20

# 3. æ±‡æ€»å•ä¸ªæ¨¡å‹çš„æ‰€æœ‰å‰ªææ–¹æ³•ç»“æœ
python param_search/consolidate_model_results.py --model Llama

# 4. æ‰¹é‡æ±‡æ€»æ‰€æœ‰6ä¸ªæ¨¡å‹
python param_search/consolidate_all_models.py

# 5. ç”Ÿæˆè·¨æ¨¡å‹ç»¼åˆåˆ†ææŠ¥å‘Š
python param_search/analyze_all_models.py
```

## ğŸ“– è„šæœ¬è¯¦è§£

### 1. search_best_params.py - ä¸»å‚æ•°æœç´¢

**åŠŸèƒ½**: è‡ªåŠ¨åŒ–å‚æ•°ç½‘æ ¼æœç´¢ï¼Œæµ‹è¯•ä¸åŒçš„ Taylor é‡è¦æ€§è®¡ç®—å‚æ•°ç»„åˆ

**ç”¨æ³•**:
```bash
# Base æ¨¡å‹
python param_search/search_best_params.py --config configs/Llama_param_search.json
python param_search/search_best_params.py --config configs/Qwen_param_search.json
python param_search/search_best_params.py --config configs/Mistral_param_search.json

# Instruct æ¨¡å‹
python param_search/search_best_params.py --config configs/Llama-Instruct_param_search.json
python param_search/search_best_params.py --config configs/Qwen-Instruct_param_search.json
python param_search/search_best_params.py --config configs/Mistral-Instruct_param_search.json

# ä½¿ç”¨ --resume å‚æ•°ç»§ç»­ä¸­æ–­çš„æœç´¢
python param_search/search_best_params.py --config configs/Llama_param_search.json --resume
```

**é…ç½®å‚æ•°**:
- `taylor_seq_len`: åºåˆ—é•¿åº¦ï¼ˆå¦‚ [32, 64, 128, 256]ï¼‰
- `taylor_num_samples`: æ ·æœ¬æ•°é‡ï¼ˆå¦‚ [4, 64, 128, 256, 512]ï¼‰
- `pruning_ratio`: å‰ªæç‡ï¼ˆå¦‚ 0.2 è¡¨ç¤º 20%ï¼‰
- `importance_method`: é‡è¦æ€§è®¡ç®—æ–¹æ³•ï¼ˆtaylor, layerwise, blockwiseï¼‰

**è¾“å‡º**:
- `results/search_{model}_20/search_results.csv` - æ‰€æœ‰å®éªŒç»“æœ
- `results/search_{model}_20/best_config.json` - æœ€ä½³é…ç½®
- `results/search_{model}_20/exp_*` - æ¯ä¸ªå®éªŒçš„è¯¦ç»†ç»“æœ

**æ”¶é›†çš„æŒ‡æ ‡**:
- **ACC æŒ‡æ ‡**: 7ä¸ª zero-shot ä»»åŠ¡ï¼ˆBoolQ, PIQA, HellaSwag, WinoGrande, ARC-Easy, ARC-Challenge, OpenBookQAï¼‰
- **PPL**: WikiText2 å’Œ PTB æ•°æ®é›†ä¸Šçš„å›°æƒ‘åº¦
- **æ¢¯åº¦ç»Ÿè®¡**: grad_norm_ratio, grad_mean_ratio, extreme_pruning_layers ç­‰

---

### 2. re_extract_results.py - é‡æå–ç»“æœ

**åŠŸèƒ½**: ä»å·²å®Œæˆçš„å®éªŒç›®å½•é‡æ–°æå–ç»“æœåˆ° CSVï¼ˆç”¨äºä¿®å¤æˆ–æ›´æ–°ï¼‰

**ç”¨æ³•**:
```bash
python param_search/re_extract_results.py --search_dir results/search_Llama_20
```

**é€‚ç”¨åœºæ™¯**:
- CSV æ–‡ä»¶æŸåæˆ–ä¸¢å¤±
- éœ€è¦æ›´æ–°è¾“å‡ºæ ¼å¼
- ä¿®å¤å‚æ•°æå–é”™è¯¯

---

### 3. consolidate_model_results.py - å•æ¨¡å‹ç»“æœæ±‡æ€»

**åŠŸèƒ½**: æ±‡æ€»å•ä¸ªæ¨¡å‹çš„æ‰€æœ‰å‰ªææ–¹æ³•ï¼ˆTaylorã€Layerwiseã€Blockwiseï¼‰çš„ç»“æœ

**ç”¨æ³•**:
```bash
# Base æ¨¡å‹
python param_search/consolidate_model_results.py --model Llama
python param_search/consolidate_model_results.py --model Qwen
python param_search/consolidate_model_results.py --model Mistral

# Instruct æ¨¡å‹
python param_search/consolidate_model_results.py --model Llama-Instruct
python param_search/consolidate_model_results.py --model Qwen-Instruct
python param_search/consolidate_model_results.py --model Mistral-Instruct
```

**è¾“å‡º**:
- `results/consolidated_{model}_20/all_methods_results.csv` - æ‰€æœ‰å‰ªææ–¹æ³•çš„å®Œæ•´ç»“æœ
- `results/consolidated_{model}_20/global_best_config.json` - å…¨å±€æœ€ä½³é…ç½®
- `results/consolidated_{model}_20/method_comparison.json` - å‰ªææ–¹æ³•å¯¹æ¯”ç»Ÿè®¡

---

### 4. consolidate_all_models.py - æ‰¹é‡æ±‡æ€»æ‰€æœ‰æ¨¡å‹

**åŠŸèƒ½**: è‡ªåŠ¨å¯¹æ‰€æœ‰6ä¸ªæ¨¡å‹è¿è¡Œæ±‡æ€»

**ç”¨æ³•**:
```bash
python param_search/consolidate_all_models.py
```

**è¯´æ˜**: ç­‰ä»·äºå¯¹æ¯ä¸ªæ¨¡å‹è¿è¡Œ `consolidate_model_results.py`

---

### 5. analyze_all_models.py - è·¨æ¨¡å‹ç»¼åˆåˆ†æ â­

**åŠŸèƒ½**: å¯¹æ¯”åˆ†ææ‰€æœ‰6ä¸ªæ¨¡å‹çš„æœ€ä½³é…ç½®ï¼Œç”Ÿæˆç»¼åˆæŠ¥å‘Š

**ç”¨æ³•**:
```bash
python param_search/analyze_all_models.py
```

**åˆ†æå†…å®¹**:
1. æ‰€æœ‰æ¨¡å‹æœ€ä½³é…ç½®æ€»è§ˆ
2. Base vs Instruct æ€§èƒ½å¯¹æ¯”
3. å‰ªææ–¹æ³•åå¥½ç»Ÿè®¡
4. å‚æ•°åˆ†å¸ƒç»Ÿè®¡ï¼ˆtaylor_seq_len, taylor_num_samplesï¼‰
5. æ¨¡å‹æ¶æ„å¯¹æ¯”ï¼ˆLlama vs Qwen vs Mistralï¼‰

**è¾“å‡º**:
- `results/cross_model_analysis/all_models_best_configs.csv` - æ‰€æœ‰æ¨¡å‹æœ€ä½³é…ç½®å¯¹æ¯”è¡¨
- `results/cross_model_analysis/analysis_summary.json` - ç»Ÿè®¡æ‘˜è¦ï¼ˆJSONæ ¼å¼ï¼‰
- ç»ˆç«¯è¾“å‡ºå®Œæ•´çš„åˆ†ææŠ¥å‘Š

**ç¤ºä¾‹è¾“å‡º**:
```
====================================================================================================
æ‰€æœ‰æ¨¡å‹æœ€ä½³é…ç½®æ€»è§ˆ
====================================================================================================
æ¨¡å‹                   ç±»å‹         æ–¹æ³•           ACC        PPL        seq_len    samples
----------------------------------------------------------------------------------------------------
Llama                Base       BLOCKWISE    0.5980     13.17      64         128
Qwen                 Base       LAYERWISE    0.6161     10.80      128        512
Mistral              Base       BLOCKWISE    0.5947     13.29      64         128
----------------------------------------------------------------------------------------------------
Llama                Instruct   BLOCKWISE    0.6318     13.29      32         512
Qwen                 Instruct   LAYERWISE    0.6202     13.42      32         4
Mistral              Instruct   BLOCKWISE    0.6552     24.33      32         256
```

---

### 6. copy_best_results.py - å¤åˆ¶æœ€ä½³ç»“æœ

**åŠŸèƒ½**: å°†æœ€ä½³å®éªŒç»“æœå¤åˆ¶åˆ°ç‹¬ç«‹ç›®å½•ä»¥ä¾¿æŸ¥çœ‹å’Œåˆ†æ

**ç”¨æ³•**:
```bash
python param_search/copy_best_results.py --model Llama
python param_search/copy_best_results.py --all  # å¤åˆ¶æ‰€æœ‰æ¨¡å‹
```

**è¾“å‡º**: `results/best_{model}_20/` ç›®å½•

---

## ğŸ“Š å…³é”®å‘ç°ï¼ˆåŸºäºå½“å‰å®éªŒç»“æœï¼‰

### æœ€ä½³æ¨¡å‹é…ç½®

| æ’å | æ¨¡å‹ | ç±»å‹ | æ–¹æ³• | ACC | PPL | seq_len | samples |
|------|------|------|------|-----|-----|---------|---------|
| ğŸ¥‡ | **Mistral** | **Instruct** | **BLOCKWISE** | **0.6552** | 24.33 | 32 | 256 |
| ğŸ¥ˆ | Llama | Instruct | BLOCKWISE | 0.6318 | 13.29 | 32 | 512 |
| ğŸ¥‰ | Qwen | Instruct | LAYERWISE | 0.6202 | 13.42 | 32 | 4 |
| 4 | Qwen | Base | LAYERWISE | 0.6161 | 10.80 | 128 | 512 |
| 5 | Llama | Base | BLOCKWISE | 0.5980 | 13.17 | 64 | 128 |
| 6 | Mistral | Base | BLOCKWISE | 0.5947 | 13.29 | 64 | 128 |

### Base vs Instruct æ€§èƒ½æå‡

- **Mistral**: +10.18% (0.5947 â†’ 0.6552) - ğŸ”¥ æœ€å¤§æå‡
- **Llama**: +5.64% (0.5980 â†’ 0.6318)
- **Qwen**: +0.66% (0.6161 â†’ 0.6202) - Base å·²ç»å¾ˆå¼º

### å‰ªææ–¹æ³•åå¥½

- **BLOCKWISE**: 4/6 æ¨¡å‹ (66.7%) - æœ€å—æ¬¢è¿
- **LAYERWISE**: 2/6 æ¨¡å‹ (33.3%) - Qwen ç³»åˆ—ä¸“å±åå¥½
- **TAYLOR**: 0/6 æ¨¡å‹ (0.0%) - æœªè¢«é€‰ä¸ºæœ€ä½³

### å‚æ•°è§„å¾‹å‘ç° ğŸ”

**taylor_seq_len**:
- **32**: 3/6 æ¨¡å‹ (50.0%) - **æ‰€æœ‰ Instruct æ¨¡å‹éƒ½ä½¿ç”¨ 32**
- **64**: 2/6 æ¨¡å‹ (33.3%) - Llama/Mistral Base
- **128**: 1/6 æ¨¡å‹ (16.7%) - Qwen Base

**å…³é”®è§‚å¯Ÿ**: Instruct æ¨¡å‹æ™®éåå¥½æ›´å°çš„ seq_len (32)ï¼Œè€Œ Base æ¨¡å‹éœ€è¦æ›´å¤§çš„å€¼

**taylor_num_samples**:
- åˆ†å¸ƒè¾ƒä¸ºå‡åŒ€ï¼š4, 128, 256, 512 å„æœ‰æ¨¡å‹ä½¿ç”¨
- Qwen-Instruct ä»…éœ€ 4 ä¸ªæ ·æœ¬å³å¯è¾¾åˆ°æœ€ä½³æ€§èƒ½ï¼ˆæé«˜æ•ˆç‡ï¼‰

### æ¶æ„å¯¹æ¯”ï¼ˆå¹³å‡ Base + Instructï¼‰

| æ’å | æ¶æ„ | å¹³å‡ ACC | å¹³å‡ PPL |
|------|------|---------|---------|
| ğŸ¥‡ | Mistral | 0.6249 | 18.81 |
| ğŸ¥ˆ | Qwen | 0.6181 | 12.11 â­ æœ€ä½ PPL |
| ğŸ¥‰ | Llama | 0.6149 | 13.23 |

---

## ğŸ’¡ é‡è¦è§‚å¯Ÿ

1. **Instruct æ¨¡å‹çš„ç‰¹æ®Šæ€§**:
   - å…¨éƒ¨ä½¿ç”¨ `taylor_seq_len=32`ï¼ˆæ›´å°çš„åºåˆ—é•¿åº¦ï¼‰
   - Base æ¨¡å‹éœ€è¦ 64-128 çš„æ›´å¤§å€¼
   - è¿™å¯èƒ½ä¸ Instruct æ¨¡å‹çš„å¯¹é½è®­ç»ƒæœ‰å…³

2. **å‰ªææ–¹æ³•é€‰æ‹©**:
   - **BLOCKWISE** åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹è¡¨ç°æœ€å¥½ï¼ˆå°¤å…¶æ˜¯ Llama å’Œ Mistralï¼‰
   - **Qwen æ˜¯å”¯ä¸€åå¥½ LAYERWISE çš„æ¶æ„**ï¼ˆBase å’Œ Instruct éƒ½æ˜¯ï¼‰
   - **TAYLOR** æ–¹æ³•ä»æœªæˆä¸ºæœ€ä½³ï¼ˆå¯èƒ½éœ€è¦ä¼˜åŒ–æˆ–ä¸é€‚åˆè¿™ä¸ªä»»åŠ¡ï¼‰

3. **æ€§èƒ½ä¸æ•ˆç‡æƒè¡¡**:
   - **Mistral-Instruct**: æœ€é«˜ ACC (0.6552) ä½† PPL è¾ƒé«˜ (24.33)
   - **Qwen Base**: æ‰€æœ‰ Base æ¨¡å‹ä¸­è¡¨ç°æœ€å¥½ (ACC: 0.6161, PPL: 10.80)
   - **Qwen-Instruct**: æœ€é«˜æ•ˆç‡ï¼ˆä»…éœ€ 4 ä¸ªæ ·æœ¬ï¼‰

4. **PPL ä¸ ACC çš„å…³ç³»**:
   - ä¸¤è€…ä¸å®Œå…¨æ­£ç›¸å…³
   - Mistral-Instruct è™½ç„¶ PPL é«˜ä½† ACC æœ€å¥½
   - åœ¨å‰ªæåœºæ™¯ä¸­ï¼Œzero-shot ACC å¯èƒ½æ¯” PPL æ›´é‡è¦

---

## ğŸ“ˆ ç”¨äºè®ºæ–‡çš„æ•°æ®

æ‰€æœ‰åˆ†æç»“æœéƒ½å·²ä¿å­˜ä¸º CSV å’Œ JSON æ ¼å¼ï¼Œå¯ç›´æ¥ç”¨äºè®ºæ–‡ï¼š

- **è¡¨æ ¼æ•°æ®**: `results/cross_model_analysis/all_models_best_configs.csv`
- **ç»Ÿè®¡æ•°æ®**: `results/cross_model_analysis/analysis_summary.json`
- **å•æ¨¡å‹è¯¦ç»†æ•°æ®**: `results/consolidated_{model}_20/`

### å»ºè®®çš„è®ºæ–‡å‘ˆç°æ–¹å¼

1. **ä¸»è¡¨**: å±•ç¤ºæ‰€æœ‰6ä¸ªæ¨¡å‹çš„æœ€ä½³é…ç½®ï¼ˆä½¿ç”¨ all_models_best_configs.csvï¼‰
2. **å¯¹æ¯”å›¾**: Base vs Instruct æ€§èƒ½æå‡æŸ±çŠ¶å›¾
3. **åˆ†å¸ƒå›¾**: å‚æ•°åå¥½åˆ†å¸ƒï¼ˆseq_len å’Œ num_samplesï¼‰
4. **æ–¹æ³•å¯¹æ¯”**: ä¸‰ç§å‰ªææ–¹æ³•çš„ ACC å¯¹æ¯”ï¼ˆæŒ‰æ¨¡å‹åˆ†ç»„ï¼‰

---

## ğŸ”§ é…ç½®æ–‡ä»¶

é…ç½®æ–‡ä»¶ä½äº `configs/` ç›®å½•ï¼š

**Base æ¨¡å‹**:
- `configs/Llama_param_search.json`
- `configs/Qwen_param_search.json`
- `configs/Mistral_param_search.json`

**Instruct æ¨¡å‹**:
- `configs/Llama-Instruct_param_search.json`
- `configs/Qwen-Instruct_param_search.json`
- `configs/Mistral-Instruct_param_search.json`

**å‰ªææ–¹æ³•å˜ä½“**:
- `configs/{model}_layerwise_param_search.json`
- `configs/{model}_blockwise_param_search.json`

---

## âš™ï¸ å®éªŒç¯å¢ƒè¦æ±‚

- Python 3.8+
- PyTorch 2.0+
- Transformers 4.30+
- è¶³å¤Ÿçš„ GPU å†…å­˜ï¼ˆå»ºè®® 40GB+ ç”¨äº 7B-8B æ¨¡å‹ï¼‰

---

## ğŸ“ å¸¸è§é—®é¢˜

**Q: å®éªŒä¸­æ–­äº†æ€ä¹ˆåŠï¼Ÿ**
A: ä½¿ç”¨ `--resume` å‚æ•°ç»§ç»­ï¼š
```bash
python param_search/search_best_params.py --config configs/Llama_param_search.json --resume
```

**Q: CSV æ–‡ä»¶æŸåäº†æ€ä¹ˆåŠï¼Ÿ**
A: ä½¿ç”¨ `re_extract_results.py` é‡æ–°æå–ï¼š
```bash
python param_search/re_extract_results.py --search_dir results/search_Llama_20
```

**Q: å¦‚ä½•å¿«é€Ÿæµ‹è¯•æµç¨‹ï¼Ÿ**
A: åˆ›å»ºä¸€ä¸ªå°çš„æµ‹è¯•é…ç½®ï¼Œåªä½¿ç”¨ 2-3 ä¸ªå‚æ•°ç»„åˆ

**Q: åˆ†æè„šæœ¬æŠ¥é”™æ‰¾ä¸åˆ°æ–‡ä»¶ï¼Ÿ**
A: ç¡®ä¿å…ˆè¿è¡Œäº† `consolidate_all_models.py` ç”Ÿæˆæ±‡æ€»æ–‡ä»¶

---

## ğŸ¯ åç»­ä¼˜åŒ–æ–¹å‘

åŸºäºå½“å‰å®éªŒç»“æœï¼Œå»ºè®®ï¼š

1. **é’ˆå¯¹ TAYLOR æ–¹æ³•**:
   - å¯èƒ½éœ€è¦è°ƒæ•´ H-GSP çš„æ¸©åº¦å‚æ•°å’Œé—¨æ§é˜ˆå€¼
   - å°è¯•äºŒé˜¶ Taylor å±•å¼€ï¼ˆ`importance_method: taylor_2nd`ï¼‰

2. **é’ˆå¯¹ Instruct æ¨¡å‹**:
   - æ¢ç´¢ä¸ºä»€ä¹ˆ seq_len=32 æ€»æ˜¯æœ€ä¼˜
   - ç ”ç©¶å¯¹é½è®­ç»ƒå¯¹é‡è¦æ€§è¯„ä¼°çš„å½±å“

3. **é’ˆå¯¹ Qwen**:
   - æ·±å…¥åˆ†æä¸ºä»€ä¹ˆåå¥½ LAYERWISE
   - ç ”ç©¶å…¶æ¶æ„ç‰¹ç‚¹ï¼ˆå¦‚ GQA ratio, layer æ•°é‡ç­‰ï¼‰

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- ä¸»é¡¹ç›® README: `../README.md`
- é…ç½®æ–‡ä»¶è¯´æ˜: `../configs/README.md`
- å‰ªææ–¹æ³•æ–‡æ¡£: `../docs/`

---

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æäº¤ Issue æˆ– Pull Requestã€‚
