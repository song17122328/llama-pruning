#!/usr/bin/env python3
"""
ä¸ºæ¯ä¸ªæ¨¡å‹é€‰æ‹©ACCæœ€é«˜å’ŒPPLæœ€ä½çš„é…ç½®ï¼Œå‡†å¤‡ç”¨äºå¾®è°ƒ

ç”¨æ³•:
    python param_search/select_best_for_finetuning.py
"""

import csv
import json
import shutil
from pathlib import Path


def load_and_select_best(model):
    """åŠ è½½æ¨¡å‹ç»“æœå¹¶é€‰æ‹©ACCæœ€é«˜å’ŒPPLæœ€ä½çš„é…ç½®"""
    csv_file = Path('results') / f'consolidated_{model}_20' / 'all_methods_results.csv'

    if not csv_file.exists():
        print(f"âš ï¸  {model}: CSVæ–‡ä»¶ä¸å­˜åœ¨")
        return None, None

    results = []
    with open(csv_file, 'r') as f:
        reader = csv.DictReader(f)
        for row in reader:
            # åªä¿ç•™æˆåŠŸçš„å®éªŒ
            if row.get('success') == 'True' and row.get('acc_mean') and row.get('ppl'):
                try:
                    row['acc_mean'] = float(row['acc_mean'])
                    row['ppl'] = float(row['ppl'])
                    results.append(row)
                except (ValueError, TypeError):
                    continue

    if not results:
        print(f"âš ï¸  {model}: æ²¡æœ‰æœ‰æ•ˆç»“æœ")
        return None, None

    # é€‰æ‹©ACCæœ€é«˜çš„
    best_acc = max(results, key=lambda x: x['acc_mean'])

    # é€‰æ‹©PPLæœ€ä½çš„ï¼ˆæ³¨æ„ï¼šPPLè¶Šä½è¶Šå¥½ï¼‰
    best_ppl = min(results, key=lambda x: x['ppl'])

    return best_acc, best_ppl


def copy_model_for_finetuning(source_dir, dest_dir, selection_info):
    """å¤åˆ¶æ¨¡å‹æ–‡ä»¶åˆ°å¾®è°ƒç›®å½•"""
    source_path = Path(source_dir)
    dest_path = Path(dest_dir)

    if not source_path.exists():
        print(f"    âš ï¸  æºç›®å½•ä¸å­˜åœ¨: {source_dir}")
        return False

    # åˆ›å»ºç›®æ ‡ç›®å½•
    dest_path.mkdir(parents=True, exist_ok=True)

    # éœ€è¦å¤åˆ¶çš„æ–‡ä»¶å’Œæ–‡ä»¶å¤¹
    items_to_copy = [
        'pruned_model.bin',      # å‰ªæåçš„æ¨¡å‹
        # 'config.json',           # æ¨¡å‹é…ç½®
        'evaluation',            # è¯„ä¼°ç»“æœ
        'analysis',              # åˆ†ææ•°æ®
        'visualization',         # å¯è§†åŒ–
        'logs'                   # æ—¥å¿—
    ]

    copied_count = 0
    for item in items_to_copy:
        src_item = source_path / item
        dst_item = dest_path / item

        if src_item.exists():
            # å¦‚æœç›®æ ‡å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
            if dst_item.exists():
                if dst_item.is_dir():
                    shutil.rmtree(dst_item)
                else:
                    dst_item.unlink()

            # å¤åˆ¶
            if src_item.is_dir():
                shutil.copytree(src_item, dst_item)
            else:
                shutil.copy2(src_item, dst_item)
            copied_count += 1
        else:
            print(f"    âš ï¸  é¡¹ç›®ä¸å­˜åœ¨: {src_item}")

    # ä¿å­˜é€‰æ‹©ä¿¡æ¯
    info_file = dest_path / 'selection_info.json'
    with open(info_file, 'w') as f:
        json.dump(selection_info, f, indent=2)

    return copied_count > 0


def process_model(model):
    """å¤„ç†å•ä¸ªæ¨¡å‹ï¼šé€‰æ‹©æœ€ä½³é…ç½®å¹¶å¤åˆ¶"""
    print(f"\n{'='*80}")
    print(f"å¤„ç†æ¨¡å‹: {model}")
    print(f"{'='*80}")

    best_acc, best_ppl = load_and_select_best(model)

    if not best_acc or not best_ppl:
        print(f"  âœ— è·³è¿‡ï¼ˆæ— æœ‰æ•ˆç»“æœï¼‰")
        return

    # å‡†å¤‡ç›®å½•
    base_dir = Path('results') / 'for_finetuning' / model

    # å¤„ç†ACCæœ€é«˜çš„é…ç½®
    print(f"\nğŸ“Š ACCæœ€é«˜çš„é…ç½®:")
    print(f"  ACC: {best_acc['acc_mean']:.4f}")
    print(f"  PPL: {best_acc['ppl']:.2f}")
    print(f"  æ–¹æ³•: {best_acc.get('pruning_method', 'N/A').upper()}")
    print(f"  æºç›®å½•: {best_acc['output_dir']}")

    acc_info = {
        'selection_criterion': 'best_acc',
        'acc_mean': best_acc['acc_mean'],
        'ppl': best_acc['ppl'],
        'pruning_method': best_acc.get('pruning_method', 'N/A'),
        'taylor_seq_len': best_acc.get('taylor_seq_len', 'N/A'),
        'taylor_num_samples': best_acc.get('taylor_num_samples', 'N/A'),
        'source_dir': best_acc['output_dir'],
        'model': model,
        'task_accuracies': {}
    }

    # æå–7ä¸ªä»»åŠ¡çš„ACC
    tasks = ['boolq', 'piqa', 'hellaswag', 'winogrande', 'arc_easy', 'arc_challenge', 'openbookqa']
    for task in tasks:
        col_name = f'acc_{task}'
        if col_name in best_acc and best_acc[col_name]:
            try:
                acc_info['task_accuracies'][task] = float(best_acc[col_name])
            except:
                pass

    acc_dest = base_dir / 'best_acc'
    if copy_model_for_finetuning(best_acc['output_dir'], acc_dest, acc_info):
        print(f"  âœ“ å·²å¤åˆ¶åˆ°: {acc_dest}")
    else:
        print(f"  âœ— å¤åˆ¶å¤±è´¥")

    # å¤„ç†PPLæœ€ä½çš„é…ç½®
    print(f"\nğŸ“Š PPLæœ€ä½çš„é…ç½®:")
    print(f"  PPL: {best_ppl['ppl']:.2f}")
    print(f"  ACC: {best_ppl['acc_mean']:.4f}")
    print(f"  æ–¹æ³•: {best_ppl.get('pruning_method', 'N/A').upper()}")
    print(f"  æºç›®å½•: {best_ppl['output_dir']}")

    ppl_info = {
        'selection_criterion': 'best_ppl',
        'ppl': best_ppl['ppl'],
        'acc_mean': best_ppl['acc_mean'],
        'pruning_method': best_ppl.get('pruning_method', 'N/A'),
        'taylor_seq_len': best_ppl.get('taylor_seq_len', 'N/A'),
        'taylor_num_samples': best_ppl.get('taylor_num_samples', 'N/A'),
        'source_dir': best_ppl['output_dir'],
        'model': model,
        'task_accuracies': {}
    }

    for task in tasks:
        col_name = f'acc_{task}'
        if col_name in best_ppl and best_ppl[col_name]:
            try:
                ppl_info['task_accuracies'][task] = float(best_ppl[col_name])
            except:
                pass

    ppl_dest = base_dir / 'best_ppl'
    if copy_model_for_finetuning(best_ppl['output_dir'], ppl_dest, ppl_info):
        print(f"  âœ“ å·²å¤åˆ¶åˆ°: {ppl_dest}")
    else:
        print(f"  âœ— å¤åˆ¶å¤±è´¥")

    # æ£€æŸ¥æ˜¯å¦æ˜¯åŒä¸€ä¸ªé…ç½®
    if best_acc['output_dir'] == best_ppl['output_dir']:
        print(f"\nğŸ’¡ æ³¨æ„ï¼šACCæœ€é«˜å’ŒPPLæœ€ä½æ˜¯åŒä¸€ä¸ªé…ç½®ï¼")


def main():
    models = [
        'Llama',
        'Llama-Instruct',
        'Qwen',
        'Qwen-Instruct',
        'Mistral',
        'Mistral-Instruct'
    ]

    print("\n" + "="*80)
    print("ä¸ºå¾®è°ƒé€‰æ‹©æœ€ä½³é…ç½®")
    print("="*80)
    print("\né€‰æ‹©æ ‡å‡†:")
    print("  1. ACCæœ€é«˜: ç”¨äºè¯„ä¼°å‰ªæåæ€§èƒ½æ¢å¤")
    print("  2. PPLæœ€ä½: ç”¨äºè¯„ä¼°å›°æƒ‘åº¦æ¢å¤")
    print(f"\nå°†ä¸ºæ¯ä¸ªæ¨¡å‹å‡†å¤‡2ä¸ªé…ç½®ï¼Œå…± {len(models)} Ã— 2 = {len(models)*2} ä¸ªæ¨¡å‹")

    for model in models:
        process_model(model)

    print("\n" + "="*80)
    print("é€‰æ‹©å®Œæˆ")
    print("="*80)
    print(f"\nç»“æœä¿å­˜åœ¨: results/for_finetuning/")
    print(f"\næ¯ä¸ªæ¨¡å‹åŒ…å«:")
    print(f"  - best_acc/: ACCæœ€é«˜çš„é…ç½®")
    print(f"  - best_ppl/: PPLæœ€ä½çš„é…ç½®")
    print(f"\næ¯ä¸ªé…ç½®åŒ…å«:")
    print(f"  - pruned_model.bin: å‰ªæåçš„æ¨¡å‹æƒé‡")
    print(f"  - config.json: æ¨¡å‹é…ç½®")
    print(f"  - selection_info.json: é€‰æ‹©ä¿¡æ¯å’ŒåŸºå‡†æŒ‡æ ‡")
    print(f"  - evaluation/: è¯„ä¼°ç»“æœ")
    print(f"  - analysis/: åˆ†ææ•°æ®")

    # ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
    summary_file = Path('results') / 'for_finetuning' / 'SUMMARY.md'
    summary_file.parent.mkdir(parents=True, exist_ok=True)

    with open(summary_file, 'w') as f:
        f.write("# å¾®è°ƒå‰çš„æ¨¡å‹é€‰æ‹©æ‘˜è¦\n\n")
        f.write("æœ¬ç›®å½•åŒ…å«ä¸ºLoRAå¾®è°ƒå‡†å¤‡çš„å‰ªææ¨¡å‹ã€‚\n\n")
        f.write("## é€‰æ‹©æ ‡å‡†\n\n")
        f.write("- **best_acc**: ACCæœ€é«˜çš„é…ç½®ï¼ˆè¯„ä¼°zero-shotä»»åŠ¡æ€§èƒ½æ¢å¤ï¼‰\n")
        f.write("- **best_ppl**: PPLæœ€ä½çš„é…ç½®ï¼ˆè¯„ä¼°è¯­è¨€å»ºæ¨¡èƒ½åŠ›æ¢å¤ï¼‰\n\n")
        f.write("## æ¨¡å‹åˆ—è¡¨\n\n")
        f.write("| æ¨¡å‹ | ç±»å‹ | best_acc | best_ppl | æ˜¯å¦ç›¸åŒ |\n")
        f.write("|------|------|----------|----------|----------|\n")

        for model in models:
            acc_file = Path('results') / 'for_finetuning' / model / 'best_acc' / 'selection_info.json'
            ppl_file = Path('results') / 'for_finetuning' / model / 'best_ppl' / 'selection_info.json'

            if acc_file.exists() and ppl_file.exists():
                with open(acc_file, 'r') as af:
                    acc_info = json.load(af)
                with open(ppl_file, 'r') as pf:
                    ppl_info = json.load(pf)

                is_same = "âœ“" if acc_info['source_dir'] == ppl_info['source_dir'] else ""
                model_type = "Instruct" if "Instruct" in model else "Base"

                f.write(f"| {model} | {model_type} | ACC:{acc_info['acc_mean']:.4f} | PPL:{ppl_info['ppl']:.2f} | {is_same} |\n")

        f.write(f"\n## ä¸‹ä¸€æ­¥\n\n")
        f.write(f"1. å¯¹æ¯ä¸ªé…ç½®è¿è¡ŒLoRAå¾®è°ƒ\n")
        f.write(f"2. è¯„ä¼°å¾®è°ƒåçš„æ¨¡å‹\n")
        f.write(f"3. å¯¹æ¯”å¾®è°ƒå‰åçš„æ€§èƒ½\n\n")
        f.write(f"è¯¦ç»†ä¿¡æ¯å‚è§å„æ¨¡å‹ç›®å½•ä¸‹çš„ `selection_info.json` æ–‡ä»¶ã€‚\n")

    print(f"\nâœ“ æ‘˜è¦æŠ¥å‘Šå·²ä¿å­˜åˆ°: {summary_file}")
    print(f"\nâœ“ å®Œæˆï¼\n")


if __name__ == '__main__':
    main()
